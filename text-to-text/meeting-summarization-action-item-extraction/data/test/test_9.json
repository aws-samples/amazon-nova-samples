{"segmentation": {"metadata": {}, "segment_timestamps": [114000, 540000, 1188000, 2778000, 3570000], "source": "source"}, "video_metadata": {"description": "Integrating Data Components, Optimizing Feature Storage, and Evaluating NIST ATLAS for Annotation Management", "dur_minutes": 76.0, "has_chapters": true, "n_chapters": 5, "org_id": "9", "recording_date": "NA", "share_id": "9", "title": "Data Integration and Storage Solutions"}, "chapters": [{"chapter": 1, "start_ms": 114000, "topic": "Current XML format to link up different components in data", "transcript_text": "phd f: I was gonna try to get out of here , like , in half an hour , um , cuz I really appreciate people coming , and {vocalsound} the main thing that I was gonna ask people to help with today is {pause} to give input on what kinds of database format we should {pause} use in starting to link up things like word transcripts and annotations of word transcripts , so anything that transcribers or discourse coders or whatever put in the signal , {vocalsound} with time - marks for , like , words and phone boundaries and all the stuff we get out of the forced alignments and the recognizer . So , we have this , um {disfmarker} I think a starting point is clearly the {disfmarker} the channelized {pause} output of Dave Gelbart 's program , which Don brought a copy of ,\ngrad c: Yeah . Yeah , I 'm {disfmarker} I 'm familiar with that . I mean , we {disfmarker} I sort of already have developed an XML format for this sort of stuff .\nphd f: um , which {disfmarker}\nphd d: Can I see it ?\ngrad c: And so the only question {disfmarker} is it the sort of thing that you want to use or not ? Have you looked at that ? I mean , I had a web page up .\nphd f: Right . So ,\ngrad c: So {disfmarker}\nphd f: I actually mostly need to be able to link up , or {disfmarker} I it 's {disfmarker} it 's a question both of what the representation is and {disfmarker}\ngrad c: You mean , this {disfmarker} I guess I am gonna be standing up and drawing on the board .\nphd f: OK , yeah . So you should , definitely .\ngrad c: Um , so {disfmarker} so it definitely had that as a concept . So tha it has a single time - line ,\nphd f: Mm - hmm .\ngrad c: and then you can have lots of different sections , each of which have I Ds attached to it , and then you can refer from other sections to those I Ds , if you want to . So that , um {disfmarker} so that you start with {disfmarker} with a time - line tag . \" Time - line \" . And then you have a bunch of times . I don't e I don't remember exactly what my notation was ,\nphd a: Oh , I remember seeing an example of this .\ngrad c: but it {disfmarker}\nphd f: Right , right .\nphd a: Yeah .\ngrad c: Yeah , \" T equals one point three two \" , uh {disfmarker} And then I {disfmarker} I also had optional things like accuracy , and then \" ID equals T one , uh , one seven \" . And then , {nonvocalsound} I also wanted to {disfmarker} to be i to be able to not specify specifically what the time was and just have a stamp .\nphd f: Right .\ngrad c: Yeah , so these are arbitrary , assigned by a program , not {disfmarker} not by a user . So you have a whole bunch of those . And then somewhere la further down you might have something like an utterance tag which has \" start equals T - seventeen , end equals T - eighteen \" . So what that 's saying is , we know it starts at this particular time . We don't know when it ends .\nphd f: OK .\ngrad c: Right ? But it ends at this T - eighteen , which may be somewhere else . We say there 's another utterance . We don't know what the t time actually is but we know that it 's the same time as this end time .\nphd a: Mmm .\ngrad c: You know , thirty - eight , whatever you want .\nphd a: So you 're essentially defining a lattice .\ngrad c: OK . Yes , exactly .\nphd a: Yeah .\ngrad c: And then , uh {disfmarker} and then these also have I Ds . Right ? So you could {disfmarker} you could have some sort of other {disfmarker} other tag later in the file that would be something like , um , oh , I don't know , {comment} uh , {nonvocalsound} \" noise - type equals {nonvocalsound} door - slam \" . You know ? And then , uh , {nonvocalsound} you could either say \" time equals a particular time - mark \" or you could do other sorts of references . So {disfmarker} or {disfmarker} or you might have a prosody {disfmarker} \" Prosody \" right ? D ? T ? D ? T ? T ?\nphd f: It 's an O instead of an I , but the D is good .\ngrad c: You like the D ? That 's a good D .\nphd f: Yeah .\ngrad c: Um , you know , so you could have some sort of type here , and then you could have , um {disfmarker} the utterance that it 's referring to could be U - seventeen or something like that .\nphd f: OK . So , I mean , that seems {disfmarker} that seems g great for all of the encoding of things with time and ,\ngrad c: Oh , well .\nphd f: um {disfmarker} I {disfmarker} I guess my question is more , uh , what d what do you do with , say , a forced alignment ?\nphd a: How - how\nphd f: I mean you 've got all these phone labels , and what do you do if you {disfmarker} just conceptually , if you get , um , transcriptions where the words are staying but the time boundaries are changing , cuz you 've got a new recognition output , or s sort of {disfmarker} what 's the , um , sequence of going from the waveforms that stay the same , the transcripts that may or may not change , and then the utterance which {disfmarker} where the time boundaries that may or may not change {disfmarker} ?\nphd a: Oh , that 's {disfmarker} That 's actually very nicely handled here because you could {disfmarker} you could {disfmarker} all you 'd have to change is the , {vocalsound} um , time - stamps in the time - line without {disfmarker} without , uh , changing the I Ds .\nphd f: Um . And you 'd be able to propagate all of the {disfmarker} the information ?\ngrad c: Right . That 's , the who that 's why you do that extra level of indirection . So that you can just change the time - line .\nphd a: Except the time - line is gonna be huge . If you say {disfmarker}\ngrad c: Yes .\nphd f: Yeah ,\nphd a: suppose you have a phone - level alignment .\nphd f: yeah , especially at the phone - level .\nphd a: You 'd have {disfmarker} you 'd have {disfmarker}\nphd f: The {disfmarker} we {disfmarker} we have phone - level backtraces .\ngrad c: Yeah , this {disfmarker} I don't think I would do this for phone - level . I think for phone - level you want to use some sort of binary representation\nphd f: Um {disfmarker}\ngrad c: because it 'll be too dense otherwise .\nphd f: OK . So , if you were doing that and you had this sort of companion , uh , thing that gets called up for phone - level , uh , what would that look like ?\nphd a: Why\ngrad c: I would use just an existing {disfmarker} an existing way of doing it .\nphd f: How would you {disfmarker} ?\nphd a: Mmm . But {disfmarker} but why not use it for phone - level ?\nphd f: H h\nphd a: It 's just a matter of {disfmarker} it 's just a matter of it being bigger . But if you have {disfmarker} you know , barring memory limitations , or uh {disfmarker} I w I mean this is still the m\ngrad c: It 's parsing limitations . I don't want to have this text file that you have to read in the whole thing to do something very simple for .\nphd a: Oh , no . You would use it only {pause} for {pause} purposes where you actually want the phone - level information , I 'd imagine .\nphd f: So you could have some file that configures how much information you want in your {disfmarker} in your XML or something .\ngrad c: Right . I mean , you 'd {disfmarker} y\nphd f: Um ,\nphd a: You {disfmarker}\ngrad c: I {disfmarker} I am imagining you 'd have multiple versions of this depending on the information that you want .\nphd f: cuz th it does get very bush with {disfmarker} Right .\ngrad c: Um , I 'm just {disfmarker} what I 'm wondering is whether {disfmarker} I think for word - level , this would be OK .\nphd f: Yeah .\ngrad c: For word - level , it 's alright .\nphd f: Yeah . Definitely .\nphd a: Mm - hmm .\ngrad c: For lower than word - level , you 're talking about so much data that I just {disfmarker} I don't know . I don't know if that {disfmarker}"}, {"chapter": 2, "start_ms": 540000, "topic": "Best way to store features", "transcript_text": "phd f: I mean , we actually have {disfmarker} So , one thing that Don is doing , is we 're {disfmarker} we 're running {disfmarker} For every frame , you get a pitch value ,\nphd d: Lattices are big , too .\nphd f: and not only one pitch value but different kinds of pitch values\ngrad c: Yeah , I mean , for something like that I would use P - file\nphd f: depending on {disfmarker}\ngrad c: or {disfmarker} or any frame - level stuff I would use P - file .\nphd f: Meaning {disfmarker} ?\ngrad c: Uh , that 's a {disfmarker} well , or something like it . It 's ICS uh , ICSI has a format for frame - level representation of features . Um .\nphd f: OK . That you could call {disfmarker} that you would tie into this representation with like an ID .\ngrad c: Right . Right . Or {disfmarker} or there 's a {disfmarker} there 's a particular way in XML to refer to external resources .\nphd f: And {disfmarker} OK .\ngrad c: So you would say \" refer to this external file \" . Um , so that external file wouldn't be in {disfmarker}\nphd f: So that might {disfmarker} that might work .\nphd d: But what {disfmarker} what 's the advantage of doing that versus just putting it into this format ?\ngrad c: More compact , which I think is {disfmarker} is better .\nphd d: Uh - huh .\ngrad c: I mean , if you did it at this {disfmarker}\nphd f: I mean these are long meetings and with {disfmarker} for every frame ,\ngrad c: You don't want to do it with that {disfmarker} Anything at frame - level you had better encode binary\nphd f: um {disfmarker}\ngrad c: or it 's gonna be really painful .\nphd a: Or you just compre I mean , I like text formats . Um , b you can always , uh , G - zip them , and , um , you know , c decompress them on the fly if y if space is really a concern .\nphd d: Yeah , I was thi I was thinking the advantage is that we can share this with other people .\ngrad c: Well , but if you 're talking about one per frame , you 're talking about gigabyte - size files . You 're gonna actually run out of space in your filesystem for one file .\nphd f: These are big files . These are really {disfmarker} I mean {disfmarker}\ngrad c: Right ? Because you have a two - gigabyte limit on most O Ss .\nphd a: Right , OK . I would say {disfmarker} OK , so frame - level is probably not a good idea . But for phone - level stuff it 's perfectly {disfmarker}\nphd f: And th it 's {disfmarker}\nphd a: Like phones , or syllables , or anything like that .\nphd f: Phones are every five frames though , so . Or something like that .\nphd a: But {disfmarker} but {disfmarker} but most of the frames are actually not speech . So , you know , people don't {disfmarker} v Look at it , words times the average {disfmarker} The average number of phones in an English word is , I don't know , {comment} five maybe ?\nphd f: Yeah , but we actually {disfmarker}\nphd a: So , look at it , t number of words times five . That 's not {disfmarker} that not {disfmarker}\nphd f: Oh , so you mean pause phones take up a lot of the {disfmarker} long pause phones .\nphd a: Exactly .\ngrad c: Yep .\nphd a: Yeah .\nphd f: Yeah . OK . That 's true . But you do have to keep them in there . Y yeah .\ngrad c: So I think it {disfmarker} it 's debatable whether you want to do phone - level in the same thing .\nphd f: OK .\ngrad c: But I think , a anything at frame - level , even P - file , is too verbose .\nphd f: OK . So {disfmarker}\ngrad c: I would use something tighter than P - files .\nphd f: Do you {disfmarker} Are you familiar with it ?\ngrad c: So .\nphd f: I haven't seen this particular format ,\nphd a: I mean , I 've {disfmarker} I 've used them .\nphd f: but {disfmarker}\nphd a: I don't know what their structure is .\nphd f: OK .\nphd a: I 've forgot what the str\nphd d: But , wait a minute , P - file for each frame is storing a vector of cepstral or PLP values ,\ngrad c: It 's whatever you want , actually .\nphd d: right ? Right .\ngrad c: So that {disfmarker} what 's nice about the P - file {disfmarker} It {disfmarker} i Built into it is the concept of {pause} frames , utterances , sentences , that sort of thing , that structure . And then also attached to it is an arbitrary vector of values . And it can take different types .\nphd f: Oh .\ngrad c: So it {disfmarker} th they don't all have to be floats . You know , you can have integers and you can have doubles , and all that sort of stuff .\nphd f: So that {disfmarker} that sounds {disfmarker} that sounds about what I w\ngrad c: Um . Right ? And it has a header {disfmarker} it has a header format that {pause} describes it {pause} to some extent . So , the only problem with it is it 's actually storing the {pause} utterance numbers and the {pause} frame numbers in the file , even though they 're always sequential . And so it does waste a lot of space .\nphd a: Hmm .\ngrad c: But it 's still a lot tighter than {disfmarker} than ASCII . And we have a lot of tools already to deal with it .\nphd f: You do ? OK . Is there some documentation on this somewhere ?\ngrad c: Yeah , there 's a ton of it . Man - pages and , uh , source code , and me .\nphd f: OK , great . So , I mean , that sounds good . I {disfmarker} I was just looking for something {disfmarker} I 'm not a database person , but something sort of standard enough that , you know , if we start using this we can give it out , other people can work on it ,\ngrad c: Yeah , it 's not standard .\nphd f: or {disfmarker} {comment} Is it {disfmarker} ?\ngrad c: I mean , it 's something that we developed at ICSI . But , uh {disfmarker}\nphd f: But it 's {pause} been used here\ngrad c: But it 's been used here\nphd f: and people 've {disfmarker}\ngrad c: and {disfmarker} and , you know , we have a {pause} well - configured system that you can distribute for free , and {disfmarker}\nphd d: I mean , it must be the equivalent of whatever you guys used to store feat your computed features in , right ?\nphd f: OK .\nphd a: Yeah , th we have {disfmarker} Actually , we {disfmarker} we use a generalization of the {disfmarker} the Sphere format .\nphd d: Mmm .\nphd a: Um , but {disfmarker} Yeah , so there is something like that but it 's , um , probably not as sophist\ngrad c: Well , what does H T K do for features ?\nphd d: And I think there 's {disfmarker}\ngrad c: Or does it even have a concept of features ?\nphd a: They ha it has its own {disfmarker} I mean , Entropic has their own feature format that 's called , like , S - SD or some so SF or something like that .\nphd f: Yeah .\ngrad c: I 'm just wondering , would it be worth while to use that instead ?\nphd d: Yeah .\nphd a: Hmm ?\nphd f: Yeah . Th - this is exactly the kind of decision {disfmarker} It 's just whatever {disfmarker}\nphd d: But , I mean , people don't typically share this kind of stuff , right ?\nphd a: Right .\ngrad c: They generate their own .\nphd d: I mean {disfmarker} Yeah .\nphd f: Actually , I {disfmarker} I just {disfmarker} you know , we {disfmarker} we 've done this stuff on prosodics and three or four places have asked for those prosodic files , and we just have an ASCII , uh , output of frame - by - frame .\ngrad c: Ah , right .\nphd f: Which is fine , but it gets unwieldy to go in and {disfmarker} and query these files with really huge files .\ngrad c: Right .\nphd f: I mean , we could do it . I was just thinking if there 's something that {disfmarker} where all the frame values are {disfmarker}\ngrad c: And a and again , if you have a {disfmarker} if you have a two - hour - long meeting , that 's gonna {disfmarker}\nphd f: Hmm ? They 're {disfmarker} they 're fair they 're quite large .\ngrad c: Yeah , I mean , they 'd be emo enormous .\nphd f: And these are for ten - minute Switchboard conversations ,\ngrad c: Right .\nphd f: and {disfmarker} So it 's doable , it 's just that you can only store a feature vector at frame - by - frame and it doesn't have any kind of ,\nphd d: Is {disfmarker} is the sharing part of this a pretty important {pause} consideration\nphd f: um {disfmarker}\nphd d: or does that just sort of , uh {disfmarker} a nice thing to have ?\nphd f: I {disfmarker} I don't know enough about what we 're gonna do with the data . But I thought it would be good to get something that we can {disfmarker} that other people can use or adopt for their own kinds of encoding . And just , I mean we have to use some we have to make some decision about what to do .\ngrad c: Yeah .\nphd f: And especially for the prosody work , what {disfmarker} what it ends up being is you get features from the signal , and of course those change every time your alignments change . So you re - run a recognizer , you want to recompute your features , um , and then keep the database up to date .\ngrad c: Right .\nphd f: Or you change a word , or you change a {vocalsound} utterance boundary segment , which is gonna happen a lot . And so I wanted something where {pause} all of this can be done in a elegant way and that if somebody wants to try something or compute something else , that it can be done flexibly . Um , it doesn't have to be pretty , it just has to be , you know , easy to use , and {disfmarker}"}, {"chapter": 3, "start_ms": 1188000, "topic": "Exploring NIST's ATLAS as a potential storage format", "transcript_text": "grad c: Yeah , the other thing {disfmarker} We should look at ATLAS , the NIST thing ,\nphd f: Oh .\nphd a: Mmm .\ngrad c: and see if they have anything at that level .\nphd f: Uh {disfmarker}\ngrad c: I mean , I 'm not sure what to do about this with ATLAS , because they chose a different route . I chose something that {disfmarker} Th - there are sort of two choices . Your {disfmarker} your file format can know about {disfmarker} know that you 're talking about language {pause} and speech , which is what I chose , and time , or your file format can just be a graph representation . And then the application has to impose the structure on top . So what it looked like ATLAS chose is , they chose the other way , which was their file format is just nodes and links , and you have to interpret what they mean yourself .\nphd f: And why did you not choose that type of approach ?\ngrad c: Uh , because I knew that we were doing speech , and I thought it was better if you 're looking at a raw file to be {disfmarker} t for the tags to say \" it 's an utterance \" , as opposed to the tag to say \" it 's a link \" .\nphd f: OK . OK .\ngrad c: So , but {disfmarker}\nphd f: But other than that , are they compatible ? I mean , you could sort of {disfmarker}\ngrad c: Yeah , they 're reasonably compatible .\nphd f: I mean , you {disfmarker} you could {disfmarker}\nphd d: You could probably translate between them .\ngrad c: Yep .\nphd f: Yeah , that 's w So ,\ngrad c: So , well , the other thing is if we choose to use ATLAS , which maybe we should just do , we should just throw this out before we invest a lot of time in it .\nphd f: OK . I don't {disfmarker} So this is what the meeting 's about ,\ngrad c: Yeah .\nphd f: just sort of how to {disfmarker} Um , cuz we need to come up with a database like this just to do our work . And I actually don't care , as long as it 's something useful to other people , what we choose .\ngrad c: Yeah .\nphd f: So maybe it 's {disfmarker} maybe oth you know , if {disfmarker} if you have any idea of how to choose , cuz I don't .\ngrad c: The only thing {disfmarker} Yeah .\nphd a: Do they already have tools ?\ngrad c: I mean , I {disfmarker} I chose this for a couple reasons . One of them is that it 's easy to parse . You don't need a full XML parser . It 's very easy to just write a Perl script {pause} to parse it .\nphd a: As long as uh each tag is on one line .\ngrad c: Exactly . Exactly . Which I always do .\nphd f: And you can have as much information in the tag as you want , right ?\ngrad c: Well , I have it structured . Right ? So each type tag has only particular items that it can take .\nphd f: Can you {disfmarker} But you can add to those structures if you {disfmarker}\ngrad c: Sure . If you have more information . So what {disfmarker} What NIST would say is that instead of doing this , you would say something like \" link {nonvocalsound} start equals , um , you know , some node ID ,\nphd f: Yeah . So {disfmarker}\ngrad c: end equals some other node ID \" , and then \" type \" would be \" utterance \" .\nphd a: Hmm .\ngrad c: You know , so it 's very similar .\nphd f: So why would it be a {disfmarker} a waste to do it this way if it 's similar enough that we can always translate it ?\nphd d: It probably wouldn't be a waste . It would mean that at some point if we wanted to switch , we 'd just have to translate everything .\ngrad c: Write a translator . But it se Since they are developing a big {disfmarker}\nphd f: But it {disfmarker} but that sounds {disfmarker}\nphd d: But that 's {disfmarker} I don't think that 's a big deal .\nphd f: As long as it is {disfmarker}\ngrad c: they 're developing a big infrastructure . And so it seems to me that if {disfmarker} if we want to use that , we might as well go directly to what they 're doing , rather than {disfmarker}\nphd a: If we want to {disfmarker} Do they already have something that 's {disfmarker} that would be useful for us in place ?\nphd d: Yeah . See , that 's the question . I mean , how stable is their {disfmarker} Are they ready to go ,\ngrad c: The {disfmarker} I looked at it {disfmarker}\nphd d: or {disfmarker} ?\ngrad c: The last time I looked at it was a while ago , probably a year ago , uh , when we first started talking about this .\nphd d: Hmm .\ngrad c: And at that time at least {vocalsound} it was still not very {pause} complete . And so , specifically they didn't have any external format representation at that time . They just had the sort of conceptual {pause} node {disfmarker} uh , annotated transcription graph , which I really liked . And that 's exactly what this stuff is based on . Since then , they 've developed their own external file format , which is , uh , you know , this sort of s this sort of thing . Um , and apparently they 've also developed a lot of tools , but I haven't looked at them . Maybe I should .\nphd a: We should {disfmarker} we should find out .\nphd f: I mean , would the tools {disfmarker} would the tools run on something like this , if you can translate them anyway ?\ngrad c: Um , th what would {disfmarker} would {disfmarker} would {disfmarker} what would worry me is that maybe we might miss a little detail\nphd a: It 's a hassle\nphd f: I mean , that {disfmarker} I guess it 's a question that {disfmarker}\nphd a: if {disfmarker}\nphd f: uh , yeah .\ngrad c: that would make it very difficult to translate from one to the other .\nphd f: OK .\nphd a: I {disfmarker} I think if it 's conceptually close , and they already have or will have tools that everybody else will be using , I mean , {vocalsound} it would be crazy to do something s you know , separate that {disfmarker}\nphd f: OK .\ngrad c: Yeah , we might as well . Yep .\nphd f: Yeah .\ngrad c: So I 'll {disfmarker} I 'll take a closer look at it .\nphd f: Actually , so it 's {disfmarker} that {disfmarker} that would really be the question , is just what you would feel is in the long run the best thing .\ngrad c: And {disfmarker} Right .\nphd f: Cuz {vocalsound} once we start , sort of , doing this I don't {disfmarker} we don't actually have enough time to probably have to rehash it out again\ngrad c: The {disfmarker} Yep . The other thing {disfmarker} the other way that I sort of established this was as easy translation to and from the Transcriber format .\nphd f: and {disfmarker} s Right .\ngrad c: Um ,\nphd f: Right .\ngrad c: but {disfmarker}\nphd f: I mean , I like this . This is sort of intuitively easy to actually r read ,\ngrad c: Yep .\nphd f: as easy it could {disfmarker} as it could be . But , I suppose that {pause} as long as they have a type here that specifies \" utt \" , um ,\ngrad c: It 's almost the same .\nphd f: it 's {disfmarker} yeah , close enough that {disfmarker}\ngrad c: The {disfmarker} the {disfmarker} the {disfmarker} the point is {disfmarker} with this , though , is that you can't really add any supplementary information . Right ? So if you suddenly decide that you want {disfmarker}\nphd f: You have to make a different type .\ngrad c: Yeah . You 'd have to make a different type .\nphd f: So {disfmarker} Well , if you look at it and {disfmarker} Um , I guess in my mind I don't know enough {disfmarker} Jane would know better , {comment} about the {pause} types of annotations and {disfmarker} and {disfmarker} But I imagine that those are things that would {disfmarker} well , you guys mentioned this , {comment} that could span any {disfmarker} it could be in its own channel , it could span time boundaries of any type ,\ngrad c: Right .\nphd f: it could be instantaneous , things like that . Um , and then from the recognition side we have backtraces at the phone - level .\ngrad c: Right .\nphd f: If {disfmarker} if it can handle that , it could handle states or whatever . And then at the prosody - level we have frame {disfmarker} sort of like cepstral feature files ,\ngrad c: Yep .\nphd f: uh , like these P - files or anything like that . And that 's sort of the world of things that I {disfmarker} And then we have the aligned channels , of course ,\ngrad c: Right .\nphd a: It seems to me you want to keep the frame - level stuff separate .\nphd f: and {disfmarker} Yeah .\nphd a: And then {disfmarker}\nphd f: I {disfmarker} I definitely agree and I wanted to find actually a f a nicer format or a {disfmarker} maybe a more compact format than what we used before .\ngrad c: Right .\nphd f: Just cuz you 've got {vocalsound} ten channels or whatever and two hours of a meeting . It 's {disfmarker} it 's a lot of {disfmarker}\ngrad c: Huge .\nphd a: Now {disfmarker} now how would you {disfmarker} how would you represent , um , multiple speakers in this framework ? Were {disfmarker} You would just represent them as {disfmarker}\ngrad c: Um ,\nphd a: You would have like a speaker tag or something ?\ngrad c: there 's a spea speaker tag up at the top which identifies them and then each utt the way I had it is each turn or each utterance , {comment} I don't even remember now , had a speaker ID tag attached to it .\nphd a: Mm - hmm . OK .\ngrad c: And in this format you would have a different tag , which {disfmarker} which would , uh , be linked to the link . So {disfmarker} so somewhere else you would have another thing {pause} that would be ,\nphd f: Yeah .\ngrad c: um {disfmarker} Let 's see , would it be a node or a link ? Um {disfmarker} And so {disfmarker} so this one would have , um , an ID is link {disfmarker} {comment} link seventy - four or something like that .\nphd a: Mm - hmm .\ngrad c: And then somewhere up here you would have a link that {disfmarker} that , uh , you know , was referencing L - seventy - four and had speaker Adam .\nphd a: Is i ?\ngrad c: You know , or something like that .\nphd f: Actually , it 's the channel , I think , that {disfmarker}\nphd a: Well , channel or speaker or whatever .\nphd f: I mean , w yeah , channel is what the channelized output out\nphd a: It doesn't {disfmarker}\ngrad c: This isn't quite right .\nphd a: Right .\ngrad c: I have to look at it again .\nphd f: Yeah , but {disfmarker}\nphd a: But {disfmarker} but {disfmarker} so how in the NIST format do we express {vocalsound} a hierarchical relationship between , um , say , an utterance and the words within it ? So how do you {pause} tell {pause} that {pause} these are the words that belong to that utterance ?\ngrad c: Um , you would have another structure lower down than this that would be saying they 're all belonging to this ID .\nphd a: Mm - hmm .\nphd d: So each thing refers to the {pause} utterance that it belongs to .\ngrad c: Right . And then each utterance could refer to a turn ,\nphd d: So it 's {disfmarker} it 's not hi it 's sort of bottom - up .\ngrad c: and each turn could refer to something higher up .\nphd f: And what if you actually have {disfmarker} So right now what you have as utterance , um , the closest thing that comes out of the channelized is the stuff between the segment boundaries that the transcribers put in or that Thilo put in , which may or may not actually be , like , a s it 's usually not {disfmarker} um , the beginning and end of a sentence , say .\ngrad c: Well , that 's why I didn't call it \" sentence \" .\nphd f: So , right . Um , so it 's like a segment or something .\ngrad c: Yeah .\nphd f: So , I mean , I assume this is possible , that if you have {disfmarker} someone annotates the punctuation or whatever when they transcribe , you can say , you know , from {disfmarker} for {disfmarker} from the c beginning of the sentence to the end of the sentence , from the annotations , this is a unit , even though it never actually {disfmarker} i It 's only a unit by virtue of the annotations {pause} at the word - level .\ngrad c: Sure . I mean , so you would {disfmarker} you would have yet another tag .\nphd f: And then that would get a tag somehow .\ngrad c: You 'd have another tag which says this is of type \" sentence \" .\nphd f: OK . OK .\ngrad c: And , what {disfmarker}\nphd f: But it 's just not overtly in the {disfmarker}\nphd a: OK .\nphd f: Um , cuz this is exactly the kind of {disfmarker}\nphd a: So {disfmarker}\nphd f: I think that should be {pause} possible as long as the {disfmarker} But , uh , what I don't understand is where the {disfmarker} where in this type of file {pause} that would be expressed .\ngrad c: Right . You would have another tag somewhere . It 's {disfmarker} well , there 're two ways of doing it .\nphd f: S so it would just be floating before the sentence or floating after the sentence without a time - mark .\ngrad c: You could have some sort of link type {disfmarker} type equals \" sentence \" , and ID is \" S - whatever \" . And then lower down you could have an utterance . So the type is \" utterance \" {disfmarker} equals \" utt \" . And you could either say that {disfmarker} No . I don't know {disfmarker}\nphd a: So here 's the thing .\ngrad c: I take that back .\nphd a: Um {disfmarker}\ngrad c: Can you {disfmarker} can you say that this is part of this ,\nphd f: See , cuz it 's {disfmarker}\nphd a: Hhh .\nphd f: it 's {disfmarker}\nphd d: You would just have a r\nphd f: S\ngrad c: or do you say this is part of this ? I think {disfmarker}\nphd d: You would refer up to the sentence .\nphd f: But they 're {disfmarker}\nphd a: Well , the thing {disfmarker}\nphd f: they 're actually overlapping each other , sort of .\ngrad c: So {disfmarker}\nphd a: the thing is that some something may be a part of one thing for one purpose and another thing of another purpose .\ngrad c: Right .\nphd a: So f\nphd f: You have to have another type then , I guess .\nphd a: s Um , well , s let 's {disfmarker} let 's ta so let 's {disfmarker}\ngrad c: Well , I think I 'm {disfmarker} I think w I had better look at it again\nphd f: Yeah .\nphd a: so {disfmarker}\ngrad c: because I {disfmarker} I 'm {disfmarker}\nphd f: OK . OK .\nphd a: y So for instance @ @ {comment} sup\ngrad c: There 's one level {disfmarker} there 's one more level of indirection that I 'm forgetting .\nphd a: Suppose you have a word sequence and you have two different segmentations of that same word sequence . f Say , one segmentation is in terms of , um , you know , uh , sentences . And another segmentation is in terms of , um , {vocalsound} I don't know , {comment} prosodic phrases . And let 's say that they don't {pause} nest . So , you know , a prosodic phrase may cross two sentences or something .\ngrad c: Right .\nphd a: I don't know if that 's true or not but {vocalsound} let 's as\nphd f: Well , it 's definitely true with the segment .\nphd a: Right .\nphd f: That 's what I {disfmarker} exactly what I meant by the utterances versus the sentence could be sort of {disfmarker}\nphd a: Yeah . So , you want to be s you want to say this {disfmarker} this word is part of that sentence and this prosodic phrase .\nphd f: Yeah .\nphd a: But the phrase is not part of the sentence\nphd f: Yeah .\nphd a: and neither is the sentence part of the phrase .\nphd f: Right .\ngrad c: I I 'm pretty sure that you can do that , but I 'm forgetting the exact level of nesting .\nphd a: So , you would have to have {vocalsound} two different pointers from the word up {disfmarker} one level up , one to the sent\ngrad c: So {disfmarker} so what you would end up having is a tag saying \" here 's a word , and it starts here and it ends here \" .\nphd a: Right .\ngrad c: And then lower down you would say \" here 's a prosodic boundary and it has these words in it \" . And lower down you 'd have \" here 's a sentence ,\nphd a: Right .\nphd f: An - Right .\ngrad c: and it has these words in it \" .\nphd f: So you would be able to go in and say , you know , \" give me all the words in the bound in the prosodic phrase\ngrad c: Yep .\nphd f: and give me all the words in the {disfmarker} \" Yeah .\ngrad c: So I think that 's {disfmarker} that would wor\nphd f: Um , OK .\ngrad c: Let me look at it again .\nphd a: Mm - hmm . The {disfmarker} the o the other issue that you had was , how do you actually efficiently extract , um {disfmarker} find and extract information in a structure of this type ?\nphd f: OK .\ngrad c: So .\nphd f: That 's good .\nphd a: So you gave some examples like {disfmarker}\nphd f: Well , uh , and , I mean , you guys might {disfmarker} I don't know if this is premature because I suppose once you get the representation you can do this , but the kinds of things I was worried about is ,\nphd a: No , that 's not clear .\nphd f: uh {disfmarker}\nphd a: I mean , yeah , you c sure you can do it ,\nphd f: Well , OK . So i if it {disfmarker}\nphd a: but can you do it sort of l l you know , it {disfmarker}\nphd f: I I mean , I can't do it , but I can {disfmarker} um ,\nphd a: y y you gotta {disfmarker} you gotta do this {disfmarker} you {disfmarker} you 're gonna want to do this very quickly\ngrad c: Well {disfmarker}\nphd a: or else you 'll spend all your time sort of searching through very {vocalsound} complex data structures {disfmarker}\nphd f: Right . You 'd need a p sort of a paradigm for how to do it . But an example would be \" find all the cases in which Adam started to talk while Andreas was talking and his pitch was rising , Andreas 's pitch \" . That kind of thing .\ngrad c: Right . I mean , that 's gonna be {disfmarker} Is the rising pitch a {pause} feature , or is it gonna be in the same file ?\nphd f: Well , the rising pitch will never be {pause} hand - annotated . So the {disfmarker} all the prosodic features are going to be automatically {disfmarker}\ngrad c: But the {disfmarker} I mean , that 's gonna be hard regardless ,\nphd f: So they 're gonna be in those {disfmarker}\ngrad c: right ? Because you 're gonna have to write a program that goes through your feature file and looks for rising pitches .\nphd a: Yeah .\nphd f: So {disfmarker} Right . So normally what we would do is we would say \" what do we wanna assign rising pitch to ? \" Are we gonna assign it to words ? Are we gonna just assign it to sort of {disfmarker} when it 's rising we have a begin - end rise representation ? But suppose we dump out this file and we say , uh , for every word we just classify it as , w you know , rise or fall or neither ?\ngrad c: OK . Well , in that case you would add that to this {pause} format\nphd f: OK .\ngrad c: r\nphd f: So we would basically be sort of , um , taking the format and enriching it with things that we wanna query in relation to the words that are already in the file ,\ngrad c: Right .\nphd f: and then querying it .\nphd a: You want sort of a grep that 's {disfmarker} that works at the structural {disfmarker} on the structural representation .\nphd f: OK .\ngrad c: You have that . There 's a {pause} standard again in XML , specifically for searching XML documents {disfmarker} structured X - XML documents , where you can specify both the content and the structural position .\nphd a: Yeah , but it 's {disfmarker} it 's not clear that that 's {disfmarker} That 's relative to the structure of the XML document ,\nphd f: If {disfmarker}\nphd a: not to the structure of what you 're representing in the document .\ngrad c: You use it as a tool . You use it as a tool , not an end - user . It 's not an end - user thing .\nphd a: Right .\ngrad c: It 's {disfmarker} it 's {disfmarker} you would use that to build your tool to do that sort of search .\nphd a: Right . Be Because here you 're specifying a lattice .\nphd f: Uh {disfmarker}\nphd a: So the underlying {disfmarker} that 's the underlying data structure . And you want to be able to search in that lattice .\nphd f: But as long as the {disfmarker}\ngrad c: It 's a graph , but {disfmarker}\nphd a: That 's different from searching through the text .\nphd f: But it seems like as long as the features that {disfmarker}\ngrad c: Well , no , no , no . The whole point is that the text and the lattice are isomorphic . They {pause} represent each other {pause} completely .\nphd a: Um {disfmarker}\ngrad c: So that {disfmarker} I mean th\nphd f: That 's true if the features from your acoustics or whatever that are not explicitly in this are at the level of these types .\nphd a: Hhh .\nphd f: That {disfmarker} that if you can do that {disfmarker}\ngrad c: Yeah , but that 's gonna be the trouble no matter what . Right ? No matter what format you choose , you 're gonna have the trou you 're gonna have the difficulty of relating the {disfmarker} the frame - level features {disfmarker}\nphd f: That 's right . That 's true . That 's why I was trying to figure out what 's the best format for this representation .\ngrad c: Yep .\nphd f: And it 's still gonna be {disfmarker}\nphd a: Hmm .\nphd f: it 's still gonna be , uh , not direct .\ngrad c: Right .\nphd f: You know , it {disfmarker} Or another example was , you know , uh , where in the language {disfmarker} where in the word sequence are people interrupting ? So , I guess that one 's actually easier .\nphd d: What about {disfmarker} what about , um , the idea of using a relational database to , uh , store the information from the XML ? So you would have {disfmarker} XML basically would {disfmarker} Uh , you {disfmarker} you could use the XML to put the data in , and then when you get data out , you put it back in XML . So use XML as sort of the {disfmarker} the transfer format ,\ngrad c: Transfer .\nphd d: uh , but then you store the data in the database , which allows you to do all kinds of {pause} good search things in there .\ngrad c: The , uh {disfmarker} One of the things that ATLAS is doing is they 're trying to define an API which is independent of the back store ,\nphd f: Huh .\ngrad c: so that , uh , you could define a single API and the {disfmarker} the storage could be flat XML files or a database .\nphd d: Mm - hmm .\ngrad c: My opinion on that is for the s sort of stuff that we 're doing , {comment} I suspect it 's overkill to do a full relational database , that , um , just a flat file and , uh , search tools I bet will be enough .\nphd a: But {disfmarker}\ngrad c: But that 's the advantage of ATLAS , is that if we actually take {disfmarker} decide to go that route completely and we program to their API , then if we wanted to add a database later it would be pretty easy .\nphd d: Mm - hmm . Mm - hmm .\nphd f: It seems like the kind of thing you 'd do if {disfmarker} I don't know , if people start adding all kinds of s bells and whistles to the data . And so that might be {disfmarker} I mean , it 'd be good for us to know {disfmarker} to use a format where we know we can easily , um , input that to some database if other people are using it ."}, {"chapter": 4, "start_ms": 2778000, "topic": "Disadvantages of ATLAS and other options", "transcript_text": "grad c: I guess I 'm just a little hesitant to try to go whole hog on sort of the {disfmarker} the whole framework that {disfmarker} that NIST is talking about , with ATLAS and a database and all that sort of stuff ,\nphd f: So {disfmarker}\ngrad c: cuz it 's a big learning curve , just to get going .\nphd d: Hmm .\nphd a: Hmm .\ngrad c: Whereas if we just do a flat file format , sure , it may not be as efficient but everyone can program in Perl and {disfmarker} and use it .\nphd f: OK .\ngrad c: Right ?\nphd a: But this is {disfmarker}\ngrad c: So , as opposed to {disfmarker}\nphd a: I {disfmarker} I 'm still , um , {vocalsound} not convinced that you can do much at all on the text {disfmarker} on the flat file that {disfmarker} that {disfmarker} you know , the text representation . e Because the text representation is gonna be , uh , not reflecting the structure of {disfmarker} of your words and annotations . It 's just {disfmarker} it 's {disfmarker}\ngrad c: Well , if it 's not representing it , then how do you recover it ? Of course it 's representing it .\nphd a: No . You {disfmarker} you have to {disfmarker} what you have to do is you have to basically {disfmarker}\ngrad c: That 's the whole point .\nphd a: Y yeah . You can use Perl to read it in and construct a internal representation that is essentially a lattice . But , the {disfmarker} and then {disfmarker}\ngrad c: OK .\nphd d: Yeah .\ngrad c: Well , that was a different point .\nphd a: Right .\ngrad c: Right ? So what I was saying is that {disfmarker}\nphd a: But that 's what you 'll have to do . Bec - be\ngrad c: For Perl {disfmarker} if you want to just do Perl . If you wanted to use the structured XML query language , that 's a different thing . And it 's a set of tools {vocalsound} that let you specify given the D - DDT {disfmarker} DTD of the document , um , what sorts of structural searches you want to do . So you want to say that , you know , you 're looking for , um , a tag within a tag within a particular tag that has this particular text in it , um , and , uh , refers to a particular value . And so the point isn't that an end - user , who is looking for a query like you specified , wouldn't program it in this language . What you would do is , someone would build a tool that used that as a library . So that they {disfmarker} so that you wouldn't have to construct the internal representations yourself .\nphd f: Is a {disfmarker} See , I think the kinds of questions , at least in the next {disfmarker} to the end of this year , are {disfmarker} there may be a lot of different ones , but they 'll all have a similar nature . They 'll be looking at either a word - level prosodic , uh , an {disfmarker} a value ,\ngrad c: Mm - hmm .\nphd f: like a continuous value , like the slope of something . But you know , we 'll do something where we {disfmarker} some kind of data reduction where the prosodic features are sort o uh , either at the word - level or at the segment - level ,\ngrad c: Right .\nphd f: or {disfmarker} or something like that . They 're not gonna be at the phone - level and they 're no not gonna be at the frame - level when we get done with sort of giving them simpler shapes and things . And so the main thing is just being able {disfmarker} Well , I guess , the two goals . Um , one that Chuck mentioned is starting out with something that we don't have to start over , that we don't have to throw away if other people want to extend it for other kinds of questions ,\ngrad c: Right .\nphd f: and being able to at least get enough , uh , information out on {disfmarker} where we condition the location of features on information that 's in the kind of file that you {pause} put up there . And that would {disfmarker} that would do it ,\ngrad c: Yeah . I think that there are quick and dirty solutions ,\nphd f: I mean , for me .\ngrad c: and then there are long - term , big - infrastructure solutions . And so {vocalsound} we want to try to pick something that lets us do a little bit of both .\nphd f: In the between , right . And especially that the representation doesn't have to be thrown away ,\ngrad c: Um {disfmarker} Right .\nphd f: even if your tools change .\ngrad c: And so it seems to me that {disfmarker} I mean , I have to look at it again to see whether it can really do what we want , but if we use the ATLAS external file representation , um , it seems like it 's rich enough that you could do quick tools just as I said in Perl , and then later on if we choose to go up the learning curve , we can use the whole ATLAS inter infrastructure ,\nphd f: Yeah . I mean , that sounds good to me .\ngrad c: which has all that built in .\nphd f: I {disfmarker} I don't {disfmarker} So if {disfmarker} if you would l look at that and let us know what you think .\ngrad c: Sure .\nphd f: I mean , I think we 're sort of guinea pigs , cuz I {disfmarker} I want to get the prosody work done but I don't want to waste time , you know , getting the {disfmarker}\nphd a: Oh , maybe {disfmarker}\nphd f: Yeah ?\nphd a: um {disfmarker}\ngrad c: Well , I wouldn't wait for the formats , because anything you pick we 'll be able to translate to another form .\nphd a: Well {disfmarker} Ma well , maybe you should actually look at it yourself too to get a sense of what it is you 'll {disfmarker} you 'll be dealing with ,\nphd f: OK .\nphd a: because , um , you know , Adam might have one opinion but you might have another , so\ngrad b: Yeah .\nphd f: Yeah , definitely .\nphd a: I think the more eyes look at this the better .\nphd f: Especially if there 's , e um {disfmarker} you know , if someone can help with at least the {disfmarker} the setup of the right {disfmarker}\ngrad c: Hi , Jane .\nphd f: Oh , hi .\nphd a: Mmm .\nphd f: the right representation , then , i you know , I hope it won't {disfmarker} We don't actually need the whole full - blown thing to be ready ,\ngrad c: Can you {disfmarker} Oh , well .\nphd f: so . Um , so maybe if you guys can look at it and sort of see what ,\ngrad b: Yeah .\ngrad c: Sure .\nphd f: um {disfmarker} I think we 're {disfmarker} we 're {disfmarker} {vocalsound} we 're actually just {disfmarker}\ngrad c: We 're about done .\nphd f: yeah ,\ngrad b: Hmm .\nphd f: wrapping up , but , um {disfmarker} Yeah , sorry , it 's a uh short meeting , but , um {disfmarker} Well , I don't know . Is there anything else , like {disfmarker} I mean that helps me a lot ,\ngrad c: Well , I think the other thing we might want to look at is alternatives to P - file .\nphd f: but {disfmarker}\ngrad c: I mean , th the reason I like P - file is I 'm already familiar with it , we have expertise here , and so if we pick something else , there 's the learning - curve problem . But , I mean , it is just something we developed at ICSI .\nphd a: Is there an {disfmarker} is there an IP - API ?\ngrad c: And so {disfmarker} Yeah .\nphd a: OK .\ngrad c: There 's an API for it . And , uh ,\nphd a: There used to be a problem that they get too large ,\ngrad c: a bunch of libraries , P - file utilities .\nphd a: and so {pause} basically the {disfmarker} uh the filesystem wouldn't {disfmarker}\ngrad c: Well , that 's gonna be a problem no matter what . You have the two - gigabyte limit on the filesystem size . And we definitely hit that with Broadcast News .\nphd a: Maybe you could extend the API to , uh , support , uh , like splitting up , you know , conceptually one file into smaller files on disk so that you can essentially , you know , have arbitrarily long f\ngrad c: Yep . Most of the tools can handle that .\nphd a: Yeah .\ngrad c: So that we didn't do it at the API - level . We did it at the t tool - level . That {disfmarker} that {disfmarker} most {disfmarker} many of them can s you can specify several P - files and they 'll just be done sequentially .\nphd a: OK .\ngrad c: So .\nphd f: So , I guess , yeah , if {disfmarker} if you and Don can {disfmarker} if you can show him the P - file stuff and see .\ngrad c: Sure .\nphd f: So this would be like for the F - zero {disfmarker}\ngrad b: True .\ngrad c: I mean , if you do \" man P - file \" or \" apropos P - file \" , you 'll see a lot .\ngrad b: I 've used the P - file , I think . I 've looked at it at least , briefly , I think when we were doing s something .\nphd a: What does the P stand for anyway ?\ngrad c: I have no idea .\ngrad b: Oh , in there .\ngrad c: I didn't de I didn't develop it . You know , it was {disfmarker} I think it was Dave Johnson . So it 's all part of the Quicknet library . It has all the utilities for it .\nphd a: No , P - files were around way before Quicknet . P - files were {disfmarker} were around when {disfmarker} w with , um , {vocalsound} RAP .\ngrad c: Oh , were they ?\nphd d: Mm - hmm .\nphd a: Right ?\nphd f: It 's like the history of ICSI .\nphd a: You worked with P - files .\ngrad c: Mm - hmm .\nphd f: Like {disfmarker}\nphd d: No .\nphd a: I worked with P - files .\nphd f: Yeah ?\nphd d: I don't remember what the \" P \" is , though .\nphd a: No .\ngrad c: But there are ni they 're {disfmarker} The {pause} Quicknet library has a bunch of things in it to handle P - files ,\nphd a: Yeah .\ngrad c: so it works pretty well .\nphd a: \nphd f: And that isn't really , I guess , as important as the {disfmarker} the main {disfmarker} I don't know what you call it , the {disfmarker} the main sort of word - level {disfmarker}\ngrad c: Neither do I .\nphd d: Probably stands for \" Phil \" . Phil Kohn .\ngrad c: It 's a Phil file ?\nphd d: Yeah . That 's my guess .\nphd f: Huh . OK . Well , that 's really useful . I mean , this is exactly the kind of thing that I wanted to settle . Um , so {disfmarker}\ngrad c: Yeah , I 've been meaning to look at the ATLAS stuff again anyway .\nphd f: Great .\ngrad c: So , just keep {disfmarker}\nphd f: Yeah . I guess it 's also sort of a political deci I mean , if {disfmarker} if you feel like that 's a community that would be good to tie into anyway , then it 's {disfmarker} sounds like it 's worth doing .\ngrad c: Yeah , I think it {disfmarker} it w\nphd a: j I think there 's {disfmarker}\ngrad c: And , w uh , as I said , I {disfmarker} what I did with this stuff {disfmarker} I based it on theirs . It 's just they hadn't actually come up with an external format yet . So now that they have come up with a format , it doesn't {disfmarker} it seems pretty reasonable to use it .\nphd a: Mmm .\ngrad c: But let me look at it again .\nphd f: OK , great .\ngrad c: As I said , that {disfmarker}\nphd f: Cuz we actually can start {disfmarker}\ngrad c: There 's one level {disfmarker} there 's one more level of indirection and I 'm just blanking on exactly how it works . I gotta look at it again .\nphd f: I mean , we can start with , um , I guess , this input from Dave 's , which you had printed out , the channelized input . Cuz he has all of the channels , you know , with the channels in the tag and stuff like that .\ngrad c: Yeah , I 've seen it .\nphd f: So that would be i directly ,\ngrad c: Yep . Easy {disfmarker} easy to map ."}, {"chapter": 5, "start_ms": 3570000, "topic": "Handling annotations", "transcript_text": "phd f: um {disfmarker} Yeah . And so then it would just be a matter of getting {disfmarker} making sure to handle the annotations that are , you know , not at the word - level and , um , t to import the\ngrad b: Where are those annotations coming from ?\nphd f: Well , right now , I g Jane would {disfmarker} {vocalsound} would {disfmarker}\ngrad c: Mm - hmm .\nphd f: Yeah .\npostdoc e: Are you talking about the overlap a annotations ?\nphd f: Yeah , any kind of annotation {pause} that , like , isn't already there . Uh , you know , anything you can envision .\npostdoc e: Yeah . So what I was imagining was {disfmarker} um , so Dave says we can have unlimited numbers of green ribbons . And so put , uh , a {disfmarker} a green ribbon on for an overlap code . And since we w we {disfmarker} I {disfmarker} I think it 's important to remain flexible regarding the time bins for now . And so it 's nice to have {disfmarker} However , you know , you want to have it , uh , time time uh , located in the discourse . So , um , if we {disfmarker} if we tie the overlap code to the first word in the overlap , then you 'll have a time - marking . It won't {disfmarker} it 'll be independent of the time bins , however these e evolve , shrink , or whatever , increase , or {disfmarker} Also , you could have different time bins for different purposes . And having it tied to the first word in an overlap segment is unique , uh , you know , anchored , clear . And it would just end up on a separate ribbon .\ngrad c: Right .\npostdoc e: So the overlap coding is gonna be easy with respect to that . You look puzzled .\nphd d: I {disfmarker} I just {disfmarker} I don't quite understand what these things are .\npostdoc e: OK .\nphd d: Uh .\npostdoc e: What , the codes themselves ?\nphd d: Well , th overlap codes .\npostdoc e: Or the {disfmarker} ?\nphd d: I 'm not sure what that @ @ {disfmarker}\ngrad c: Well , I mean , is that {disfmarker}\nphd d: It probably doesn't matter .\npostdoc e: Well , we don't have to go into the codes .\ngrad c: I mean , it doesn't .\nphd d: No , I d\npostdoc e: We don't have to go into the codes .\ngrad c: I mean , that {disfmarker} not for the topic of this meeting .\npostdoc e: But let me just {disfmarker} No . W the idea is just to have a separate green ribbon , you know , and {disfmarker} and {disfmarker} and let 's say that this is a time bin . There 's a word here . This is the first word of an overlapping segment of any length , overlapping with any other , uh , word {disfmarker} uh , i segment of any length . And , um , then you can indicate that this here was perhaps a ch a backchannel , or you can say that it was , um , a usurping of the turn , or you can {disfmarker} you know , any {disfmarker} any number of categories . But the fact is , you have it time - tagged in a way that 's independent of the , uh , sp particular time bin that the word ends up in . If it 's a large unit or a small unit , or\nphd a: Mm - hmm .\npostdoc e: we sh change the boundaries of the units , it 's still unique and {disfmarker} and , uh , fits with the format ,\nphd f: Right .\npostdoc e: flexible , all that .\nphd a: Um , it would be nice {disfmarker} um , eh , gr this is sort of r regarding {disfmarker} uh , uh it 's related but not directly germane to the topic of discussion , but , when it comes to annotations , um , you often find yourself in the situation where you have {pause} different annotations {pause} of the same , say , word sequence . OK ?\npostdoc e: Yeah .\nphd a: And sometimes the word sequences even differ slightly because they were edited s at one place but not the other .\npostdoc e: Yeah .\nphd a: So , once this data gets out there , some people might start annotating this for , I don't know , dialogue acts or , um , you know , topics or what the heck . You know , there 's a zillion things that people might annotate this for . And the only thing that is really sort of common among all the versi the various versions of this data is the word sequence , or approximately .\npostdoc e: Yep .\nphd f: Or the time .\nphd a: Or the times . But , see , if you 'd annotate dialogue acts , you don't necessarily want to {disfmarker} or topics {disfmarker} you don't really want to be dealing with time - marks .\nphd f: I guess .\nphd a: You 'd {disfmarker} it 's much more efficient for them to just see the word sequence , right ?\nphd f: Mm - hmm .\nphd a: I mean , most people aren't as sophisticated as {disfmarker} as we are here with , you know , uh , time alignments and stuff . So {disfmarker} So the {disfmarker} the {disfmarker} the point is {disfmarker}\ngrad c: Should {disfmarker} should we mention some names on the people who are n ?\nphd a: Right . So , um , the p my point is that {pause} you 're gonna end up with , uh , word sequences that are differently annotated . And {pause} you want some tool , uh , that is able to sort of merge these different annotations back into a single , uh , version . OK ? Um , and we had this problem very massively , uh , at SRI when we worked , uh , a while back on , {vocalsound} uh {disfmarker} well , on dialogue acts as well as , uh , you know , um , what was it ? uh ,\nphd f: Well , all the Switchboard in it .\nphd a: utterance types . There 's , uh , automatic , uh , punctuation and stuff like that .\nphd f: Yeah .\nphd a: Because we had one set of {pause} annotations that were based on , uh , one version of the transcripts with a particular segmentation , and then we had another version that was based on , uh , a different s slightly edited version of the transcripts with a different segmentation . So , {vocalsound} we had these two different versions which were {disfmarker} you know , you could tell they were from the same source but they weren't identical . So it was extremely hard {vocalsound} to reliably merge these two back together to correlate the information from the different annotations .\ngrad c: Yep . I {disfmarker} I don't see any way that file formats are gonna help us with that .\nphd a: No .\ngrad c: It 's {disfmarker} it 's all a question of semantic .\nphd a: No . But once you have a file format , I can imagine writing {disfmarker} not personally , but someone writing a tool that is essentially an alignment tool , um , that mediates between various versions ,\nphd f: Mm - hmm .\ngrad c: Yeah .\nphd a: and {disfmarker} uh , sort of like th uh , you know , you have this thing in UNIX where you have , uh , diff .\ngrad c: Diff .\nphd f: W - diff or diff .\nphd a: There 's the , uh , diff that actually tries to reconcile different {disfmarker} two diffs f {comment} based on the same original .\nphd f: Yeah .\npostdoc e: Is it S - diff ?\ngrad c: Yep .\npostdoc e: Mmm .\nphd a: Something like that , um , but operating on these lattices that are really what 's behind this {disfmarker} uh , this annotation format .\ngrad c: Yep .\nphd a: So {disfmarker}\ngrad c: There 's actually a diff library you can use {pause} to do things like that that {disfmarker} so you have different formats .\nphd f: You could definitely do that with the {disfmarker}\nphd a: So somewhere in the API you would like to have like a merge or some {disfmarker} some function that merges two {disfmarker} two versions .\ngrad c: Yeah , I think it 's gonna be very hard . Any sort of structured anything when you try to merge is really , really hard\nphd a: Right .\ngrad c: because you ha i The hard part isn't the file format . The hard part is specifying what you mean by \" merge \" .\nphd a: Is {disfmarker} Exactly .\ngrad c: And that 's very difficult .\nphd f: But the one thing that would work here actually for i that is more reliable than the utterances is the {disfmarker} the speaker ons and offs . So if you have a good ,\ngrad c: But this is exactly what I mean , is that {disfmarker} that the problem i\nphd f: um {disfmarker} Yeah . You just have to know wha what to tie it to .\ngrad c: Yeah , exactly . The problem is saying \" what are the semantics ,\nphd f: And {disfmarker}\ngrad c: what do you mean by \" merge \" ? \"\nphd f: Right , right .\nphd a: Right . So {disfmarker} so just to let you know what we {disfmarker} where we kluged it by , uh , doing {disfmarker} uh , by doing {disfmarker} Hhh .\ngrad c: So .\nphd a: Both were based on words , so , bo we have two versions of the same words intersp you know , sprinkled with {disfmarker} with different tags for annotations .\ngrad c: And then you did diff .\nphd a: And we did diff . Exactly !\ngrad c: Yeah , that 's just what I thought .\nphd a: And that 's how {disfmarker}\ngrad c: That 's just wh how I would have done it .\nphd a: Yeah . But , you know , it had lots of errors and things would end up in the wrong order , and so forth . Uh , so , um , if you had a more {disfmarker}\ngrad c: Yep .\nphd a: Uh , it {disfmarker} it was a kluge because it was basically reducing everything to {disfmarker} uh , to {disfmarker} uh , uh , to textual alignment .\ngrad c: A textual {disfmarker}\nphd a: Um , so {disfmarker}\nphd f: But , d isn't that something where whoever {disfmarker} if {vocalsound} {disfmarker} if the people who are making changes , say in the transcripts , cuz this all happened when the transcripts were different {disfmarker} ye um , if they tie it to something , like if they tied it to the acoustic segment {disfmarker} if they {disfmarker} You know what I mean ? Then {disfmarker} Or if they tied it to an acoustic segment and we had the time - marks , that would help .\ngrad c: Yep .\nphd f: But the problem is exactly as Adam said , that you get , you know , y you don't have that information or it 's lost in the merge somehow ,\npostdoc e: Well , can I ask one question ?\nphd f: so {disfmarker}\npostdoc e: It {disfmarker} it seems to me that , um , we will have o an official version of the corpus , which will be only one {disfmarker} one version in terms of the words {disfmarker} where the words are concerned . We 'd still have the {disfmarker} the merging issue maybe if coding were done independently of the {disfmarker}\nphd a: And you 're gonna get that\npostdoc e: But {disfmarker} but {disfmarker}\nphd a: because if the data gets out , people will do all kinds of things to it . And , uh , s you know , several years from now you might want to look into , um , the prosody of referring expressions . And someone at the university of who knows where has annotated the referring expressions . So you want to get that annotation and bring it back in line with your data .\ngrad c: Right .\nphd a: OK ?\ngrad c: But unfortunately they 've also hand - edited it .\npostdoc e: OK , then {disfmarker}\nphd f: But they 've also {disfmarker} Exactly . And so that 's exactly what we should {disfmarker} somehow when you distribute the data , say that {disfmarker} you know , that {disfmarker} have some way of knowing how to merge it back in and asking people to try to do that .\nphd a: Yeah .\ngrad c: Yep .\nphd a: Right .\npostdoc e: Well , then the {disfmarker}\nphd d: What 's {disfmarker} what 's wrong with {pause} doing times ? I {disfmarker}\npostdoc e: I agree . That was what I was wondering .\nphd f: Uh , yeah , time is the {disfmarker}\ngrad c: Well ,\npostdoc e: Time is unique . You were saying that you didn't think we should {disfmarker}\nphd f: Time is passing !\nphd a: Time {disfmarker} time {disfmarker} times are ephemeral .\npostdoc e: Andreas was saying {disfmarker} Yeah .\ngrad c: what if they haven't notated with them , times ?\nphd f: Yeah . He {disfmarker} he 's a language modeling person , though .\nphd a: Um {disfmarker}\ngrad c: So {disfmarker} so imagine {disfmarker} I think his {disfmarker} his example is a good one . Imagine that this person who developed the corpus of the referring expressions didn't include time .\nphd a: Mm - hmm . Yeah .\ngrad c: He included references to words .\npostdoc e: Ach !\nphd a: Yeah .\ngrad c: He said that at this word is when {disfmarker} when it happened .\npostdoc e: Well , then {disfmarker}\nphd a: Or she .\ngrad c: Or she .\npostdoc e: But then couldn't you just indirectly figure out the time {pause} tied to the word ?\nphd f: But still they {disfmarker} Exactly .\ngrad c: Sure . But what if {disfmarker} what if they change the words ?\nphd f: Yeah .\npostdoc e: Not {disfmarker} Well , but you 'd have some anchoring point . He couldn't have changed all the words .\nphd d: But can they change the words without changing the time of the word ?\ngrad c: Sure . But they could have changed it a little . The {disfmarker} the point is , that {disfmarker} that they may have annotated it off a word transcript that isn't the same as our word transcript , so how do you merge it back in ? I understand what you 're saying .\nphd a: Mmm . Mm - hmm .\ngrad c: And I {disfmarker} I guess the answer is , um , it 's gonna be different every time . It 's j it 's just gonna be {disfmarker}\npostdoc e: Yeah .\nphd f: Yeah .\ngrad c: I it 's exactly what I said before ,\nphd f: You only know the boundaries of the {disfmarker}\ngrad c: which is that \" what do you mean by \" merge \" ? \" So in this case where you have the words and you don't have the times , well , what do you mean by \" merge \" ? If you tell me what you mean , I can write a program to do it .\nphd f: Right . Right . You can merge at the level of the representation that the other person preserved and that 's it .\ngrad c: Right . And that 's about all you can do .\nphd f: And beyond that , all you know is {disfmarker} is relative ordering and sometimes even that is wrong .\ngrad c: So {disfmarker} so in {disfmarker} so in this one you would have to do a best match between the word sequences ,\nphd f: So .\nphd a: Mm - hmm .\ngrad c: extract the times f from the best match of theirs to yours , and use that .\nphd f: And then infer that their time - marks are somewhere in between .\ngrad c: Right .\nphd f: Yeah , exactly .\npostdoc e: But it could be that they just {disfmarker} uh , I mean , it could be that they chunked {disfmarker} they {disfmarker} they lost certain utterances and all that stuff ,\ngrad c: Right , exactly . So it could get very , very ugly .\npostdoc e: or {disfmarker}\nphd f: Definitely .\npostdoc e: Yeah .\nphd f: Definitely . Alright .\npostdoc e: That 's interesting .\nphd f: Well , I guess , w I {disfmarker} I didn't want to keep people too long and Adam wanted t people {disfmarker} I 'll read the digits . If anyone else offers to , that 'd be great . And\nphd a: Ah , well .\ngrad c: Yeah .\nphd f: if not , I guess {disfmarker}\nphd a: For th for the {disfmarker} {nonvocalsound} for the benefit of science we 'll read the digits ."}]}