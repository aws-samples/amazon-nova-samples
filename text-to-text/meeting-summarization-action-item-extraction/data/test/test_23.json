{"segmentation": {"metadata": {}, "segment_timestamps": [0, 1986000, 2724000, 5646000], "source": "source"}, "video_metadata": {"description": "Meeting on Corpus Testing, Forced Alignments, and Evaluation", "dur_minutes": 132.4, "has_chapters": true, "n_chapters": 4, "org_id": "23", "recording_date": "NA", "share_id": "23", "title": "Data Corpus and Alignment Evaluation"}, "chapters": [{"chapter": 1, "start_ms": 0, "topic": "Testing data corpus", "transcript_text": "grad e: OK , we 're on .\nprofessor b: OK .\ngrad e: So , I mean , everyone who 's on the wireless check that they 're on .\nphd f: C we {disfmarker}\ngrad g: Alright .\npostdoc c: I see . Yeah .\nphd f: Yeah .\ngrad e: OK , our agenda was quite short .\nprofessor b: Oh , could you {pause} close the door , maybe ? Yeah .\ngrad e: Sure . Two items , which was , uh , digits and possibly stuff on {disfmarker} on , uh , forced alignment , which Jane said that Liz and Andreas had in information on ,\nprofessor b: \ngrad e: but they didn't ,\nphd f: Mm - hmm .\nprofessor b: I guess the only other thing , uh , for which I {disfmarker}\ngrad e: so .\nphd f: We should do that second , because Liz might join us in time for that .\ngrad e: OK .\nprofessor b: Um . OK , so there 's digits , alignments , and , um , I guess the other thing , {vocalsound} which I came unprepared for , uh , {vocalsound} is , uh , to dis s s see if there 's anything anybody wants to discuss about the Saturday meeting .\ngrad e: Right .\nprofessor b: So . Any {disfmarker} I mean , maybe not .\ngrad e: Digits and alignments . But {disfmarker}\nprofessor b: Uh .\nphd f: Talk about aligning people 's schedules .\nprofessor b: Yeah .\ngrad e: Yeah .\npostdoc c: Mm - hmm .\nprofessor b: Yeah . I mean {disfmarker} Right . Yeah , I mean , it was {disfmarker}\ngrad e: Yeah , it 's forced alignment of people 's schedules .\nphd f: Yeah .\nphd d: Forced align .\nphd f: If we 're very {disfmarker}\nprofessor b: Yeah .\nphd f: Yeah .\nprofessor b: With {disfmarker} with {disfmarker} whatever it was , a month and a half or something ahead of time , the only time we could find in common {disfmarker} roughly in common , was on a Saturday .\nphd d: Yeah .\nprofessor b: Ugh .\ngrad e: Yep .\nphd f: It 's pretty sad .\nprofessor b: Yeah .\nphd f: Yeah .\npostdoc c: Have {disfmarker} Have we thought about having a conference call to include him in more of {disfmarker} {vocalsound} in more of the meeting ? I {disfmarker} I mean , I don't know , if we had the {disfmarker} if we had the telephone on the table {disfmarker}\nprofessor b: No . But , h I mean , he probably has to go do something .\nphd f: No , actually I {disfmarker} I have to {disfmarker} I have to shuttle {pause} kids from various places to various other places .\nprofessor b: Right ?\npostdoc c: I see . OK .\nprofessor b: Yeah .\nphd f: So . And I don't have {disfmarker} and I don't , um , have a cell phone\nphd d: A cell phone ?\nphd f: so I can't be having a conference call while driving .\nprofessor b: R r right .\npostdoc c: No . {comment} It 's not good .\nprofessor b: So we have to {disfmarker} we {disfmarker}\npostdoc c: That 's not good .\nphd f: Plus , it would make for interesting noise {disfmarker} background noise .\nprofessor b: \ngrad e: Yep .\nphd f: Uh {disfmarker}\nprofessor b: So we have to equip him with a {disfmarker} with a {disfmarker} {vocalsound} with a head - mounted , uh , cell phone\ngrad e: Ye - we and we 'd have to force you to read lots and lots of digits ,\nprofessor b: and {disfmarker}\ngrad e: so it could get real {disfmarker} {vocalsound} real car noise .\nphd f: Oh , yeah .\nphd d: Yeah .\nphd f: Oh , yeah .\ngrad g: Take advantage .\nphd d: And with the kids in the background .\nphd f: I 'll let {disfmarker} I 'd let {disfmarker}\nphd d: Yeah .\nphd f: I let , uh , my five - year - old have a try at the digits , eh .\nprofessor b: Yeah .\ngrad e: So , anyway , I can talk about digits . Um , did everyone get the results or shall I go over them again ? I mean that it was basically {disfmarker} the only thing that was even slightly surprising was that the lapel did so well . Um , and in retrospect that 's not as surprising as maybe i it shouldn't have been as surprising as I {disfmarker} as {disfmarker} as I felt it was . The lapel mike is a very high - quality microphone . And as Morgan pointed out , that there are actually some advantages to it in terms of breath noises and clothes rustling {pause} if no one else is talking .\nphd d: Yeah .\nphd f: Exactly .\ngrad e: Um , so , uh {disfmarker}\ngrad g: Mm - hmm .\nprofessor b: Well , it 's {disfmarker} Yeah , sort of the bre the breath noises and the mouth clicks and so forth like that , the lapel 's gonna be better on .\ngrad g: It 's g it {disfmarker}\nphd d: Or the cross - talk . Yeah .\nprofessor b: The lapel is typically worse on the {disfmarker} on clothes rustling , but if no one 's rustling their clothes ,\ngrad e: Right . I mean , a lot of people are just sort of leaning over and reading the digits ,\nprofessor b: it 's {disfmarker} it 's {disfmarker}\ngrad e: so it 's {disfmarker} it 's a very different task than sort of the natural .\nphd d: Yeah . You don't move much during reading digits , I think .\nprofessor b: Yeah .\ngrad e: So .\nprofessor b: Yeah .\ngrad e: Right .\ngrad g: Probably the fact that it picks up other people 's speakers {disfmarker} other people 's talking is an indication of that it {disfmarker} the fact it is a good microphone .\nphd d: Yeah .\nprofessor b: Right . So in the digits , in most {disfmarker} most cases , there weren't other people talking .\ngrad e: Right . Right .\ngrad g: So .\nprofessor b: So .\nphd f: D do the lapel mikes have any directionality to them ?\nprofessor b: There typically don't , no .\nphd f: Because I {disfmarker} I suppose you could make some that have sort of {disfmarker} that you have to orient towards your mouth ,\ngrad e: They have a little bit ,\nphd f: and then it would {disfmarker}\ngrad e: but they 're not noise - cancelling . So , uh {disfmarker}\nprofessor b: They 're {disfmarker} they 're intended to be omni - directional .\ngrad e: Right .\nprofessor b: And th it 's {disfmarker} and because you don't know how people are gonna put them on , you know .\nphd f: Mm - hmm .\ngrad e: Right . So , also , Andreas , on that one the {disfmarker} the back part of it should be right against your head . And that will he keep it from flopping aro up and down as much .\nphd f: It is against my head .\ngrad e: OK .\nprofessor b: Yeah . Um . Yeah , we actually talked about this in the , uh , front - end meeting this morning , too . Much the same thing ,\ngrad e: Uh - huh .\nprofessor b: and {disfmarker} and it was {disfmarker} uh , I mean , there the point of interest to the group was primarily that , um , {vocalsound} the , uh {disfmarker} the system that we had that was based on H T K , that 's used by , you know , {pause} all the participants in Aurora , {vocalsound} was so much worse {vocalsound} than the {disfmarker} than the S R\ngrad e: Everybody .\nprofessor b: And the interesting thing is that even though , {vocalsound} yes , it 's a digits task and that 's a relatively small number of words and there 's a bunch of digits that you train on , {vocalsound} it 's just not as good as having a {disfmarker} a l very large amount of data and training up a {disfmarker} a {disfmarker} a nice good big {vocalsound} HMM . Um , also you had the adaptation in the SRI system , which we didn't have in this . Um . So . Um .\nphd f: And we know {disfmarker} Di - did I send you some results without adaptation ?\ngrad e: No .\nprofessor b: I s I think Stephane , uh , had seen them .\ngrad e: Or if you did , I didn't include them , cuz it was {disfmarker}\nprofessor b: So {disfmarker}\nphd f: Yeah , I think I did , actually . So there was a significant loss from not doing the adaptation .\nprofessor b: Yeah .\nphd f: Um . A {disfmarker} a {disfmarker} a couple percent or some I mean {disfmarker} Well , I don't know it {disfmarker} Overall {disfmarker} Uh , I {disfmarker} I don't remember , but there was {disfmarker} {nonvocalsound} there was a significant , um , loss or win {comment} from adaptation {disfmarker} with {disfmarker} with adaptation . And , um , that was the phone - loop adaptation . And then there was a very small {disfmarker} like point one percent on the natives {disfmarker} uh , win from doing , um , you know , adaptation to {pause} the recognition hypotheses . And {pause} I tried both means adaptation and means and variances , and the variances added another {disfmarker} or subtracted another point one percent . So , {vocalsound} it 's , um {disfmarker} that 's the number there . Point six , I believe , is what you get with both , uh , means and variance adaptation .\ngrad e: Right .\nprofessor b: But I think one thing is that , uh , I would presume {disfmarker} Hav - Have you ever t {vocalsound} Have you ever tried this exact same recognizer out on the actual TI - digits test set ?\nphd f: This exact same recognizer ? No .\nprofessor b: It might be interesting to do that . Cuz my {disfmarker} my {disfmarker} cuz my sense , um {disfmarker}\nphd f: But {disfmarker} but , I have {disfmarker} I mean , people {disfmarker} people at SRI are actually working on digits .\ngrad e: I bet it would do even slightly better .\nphd f: I could {disfmarker} and they are using a system that 's , um {disfmarker} you know , h is actually trained on digits , um , but h h otherwise uses the same , you know , decoder , the same , uh , training methods , and so forth ,\nprofessor b: Mm - hmm .\nphd f: and I could ask them what they get {pause} on TI - digits .\nprofessor b: Yeah , bu although I 'd be {disfmarker} I think it 'd be interesting to just take this exact actual system so that these numbers were comparable\nphd f: Mm - hmm .\nprofessor b: and try it out on TI - digits .\nphd f: Well , Adam knows how to run it ,\nprofessor b: Yeah .\ngrad e: Yeah . No problem .\nphd f: so you just make a f\nprofessor b: Yeah . Yeah . Cuz our sense from the other {disfmarker} from the Aurora , uh , task is that {disfmarker}\ngrad e: And try it with TI - digits ?\nphd f: Mm - hmm .\nprofessor b: I mean , cuz we were getting sub one percent {vocalsound} numbers on TI - digits also with the tandem thing .\nphd f: Mm - hmm .\nprofessor b: So , {vocalsound} one {disfmarker} so there were a number of things we noted from this .\nphd f: Mmm .\nprofessor b: One is , yeah , the SRI system is a lot better than the HTK {disfmarker}\nphd f: Hmm .\nprofessor b: this , you know , very limited training HTK system .\nphd f: Mm - hmm .\nprofessor b: Uh , but the other is that , um , the digits {vocalsound} recorded here in this room with these close mikes , i uh , are actually a lot harder than the {pause} studio - recording TI - digits . I think , you know , one reason for that , uh , might be that there 's still {disfmarker} even though it 's close - talking , there still is some noise and some room acoustics .\nphd f: Mm - hmm . Mm - hmm .\nprofessor b: And another might be that , uh , I 'd {disfmarker} I would presume that in the studio , uh , uh , situation recording read speech that if somebody did something a little funny or n pronounced something a little funny or made a little {disfmarker} that they didn't include it ,\ngrad e: They didn't include it .\nprofessor b: they made them do it again .\ngrad e: Whereas , I took out {pause} the ones that I noticed that were blatant {disfmarker} that were correctable .\nprofessor b: Mmm . Yeah .\ngrad e: So that , if someone just read the wrong digit , I corrected it .\nprofessor b: Yeah .\ngrad e: And then there was another one where Jose couldn't tell whether {disfmarker} I couldn't tell whether he was saying zero or six . And I asked him and he couldn't tell either .\ngrad i: Hmm .\ngrad e: So I just cut it out .\nprofessor b: Yeah .\ngrad e: You know , so I just e edited out the first , i uh , word of the utterance . Um , so there 's a little bit of correction but it 's definitely not as clean as TI - digits . So my expectations is TI - digits would , especially {disfmarker} I think TI - digits is all {pause} American English .\nprofessor b: Mm - hmm .\ngrad e: Right ? So it would probably do even a little better still on the SRI system , but we could give it a try .\nphd f: Well . But {pause} remember , we 're using a telephone bandwidth front - end here , uh , on this , uh {disfmarker} on this SRI system , so , {vocalsound} um , I was {disfmarker} I thought that maybe that 's actually a good thing because it {disfmarker} it gets rid of some of the {disfmarker} uh , the noises , um , you know , in the {disfmarker} the {disfmarker} below and above the {disfmarker} um , the , you know , speech bandwidth\nprofessor b: Mm - hmm . Mm - hmm .\nphd f: and , um , I suspect that to get sort of the last bit out of these higher - quality recordings you would have to in fact , uh , use models that , uh , were trained on wider - band data . And of course we can't do that or {disfmarker}\ngrad e: Wha - what 's TI - digits ? I thought t\nprofessor b: It 's wide - band , yeah . It 's {disfmarker} in {disfmarker} in fact , we looked it up\ngrad e: It is wide - band . OK .\nprofessor b: and it was actually twenty kilohertz sampling .\ngrad e: Oh , that 's right . I {disfmarker} I did look that up .\nphd f: Mm - hmm .\ngrad e: I couldn't remember whether that was TI - digits or one of the other digit tasks .\nprofessor b: Yeah .\nphd f: Right . But {disfmarker} but , I would {disfmarker} Yeah . It 's {disfmarker} it 's easy enough to try , just run it on {disfmarker}\nprofessor b: Yeah .\ngrad e: Mm - hmm .\nprofessor b: See w\ngrad e: So , Morgan , you 're getting a little breath noise .\nphd f: Now , eh , does {disfmarker}\ngrad e: You might wanna move the mike down a little bit .\nphd f: one {disfmarker} one issue {disfmarker} one issue with {disfmarker} with that is that {vocalsound} um , the system has this , uh , notion of a speaker to {disfmarker} which is used in adaptation , variance norm uh , you know , both in , uh , mean and variance normalization and also in the VTL {pause} estimation .\nprofessor b: Mm - hmm .\nphd f: So {disfmarker}\ngrad e: Yeah , I noticed the script that extracted it .\nphd f: Do y ? Is {disfmarker} ? So does {disfmarker} so th so does {disfmarker} does , um , {vocalsound} the TI - digits database have speakers that are known ?\ngrad e: Yep . Yep .\nphd f: And is there {disfmarker} is there enough data or a comparable {disfmarker} comparable amount of data to {disfmarker} to what we have in our recordings here ?\ngrad e: That I don't know . I don't know . I don't know how many speakers there are ,\nprofessor b: Yeah .\ngrad e: and {disfmarker} and how many speakers per utterance .\nphd f: OK .\nprofessor b: Well , the other thing would be to do it without the adaptation and compare to these numbers without the adaptation . That would {disfmarker}\nphd f: Right . Uh , but I 'm not so much worried about the adaptation , actually , than {disfmarker} than the , um , {vocalsound} um {disfmarker} the , uh , VTL estimation .\ngrad e: Right .\nphd f: If you have only one utterance per speaker you might actually screw up on estimating the {disfmarker} the warping , uh , factor . So , um {disfmarker}\ngrad e: I strongly suspect that they have more speakers than we do . So , uh {disfmarker}\nphd f: Right . But it 's not the amount of speakers , it 's the num it 's the amount of data per speaker .\ngrad e: Right . So we {disfmarker} we could probably do an extraction that was roughly equivalent .\nphd f: Right . Right .\ngrad e: Um .\nphd f: So {disfmarker}\ngrad e: So , although I {disfmarker} I sort of know how to run it , there are a little {disfmarker} a f few details here and there that I 'll have to {pause} dig out .\nphd f: OK . The key {disfmarker} So th the system actually extracts the speaker ID from the waveform names .\ngrad e: Right . I saw that .\nphd f: And there 's a {disfmarker} there 's a script {disfmarker} and that is actually all in one script . So there 's this one script that parses waveform names and extracts things like the , um , speaker , uh , ID or something that can stand in as a speaker ID . So , we might have to modify that script to recognize the , um , speakers , {vocalsound} um , in the {disfmarker} in the , uh , um , {vocalsound} TI - digits {pause} database .\ngrad e: Right . Right . And that , uh {disfmarker}\nphd f: Or you can fake {disfmarker} you can fake {pause} names for these waveforms that resemble the names that we use here for the {disfmarker} for the meetings .\ngrad e: Right .\nphd f: That would be the , sort of {disfmarker} probably the safest way to do {disfmarker}\ngrad e: I might have to do that anyway to {disfmarker} to do {disfmarker} because we may have to do an extract to get the {pause} amount of data per speaker about right .\nphd f: Uh - huh .\ngrad e: The other thing is , isn't TI - digits isolated digits ?\nphd f: Right .\ngrad e: Or is that another one ? I 'm {disfmarker} I looked through a bunch of the digits t corp corpora , and now they 're all blurring .\nprofessor b: Mm - hmm .\ngrad e: Cuz one of them was literally people reading a single digit . And then others were connected digits .\nprofessor b: Yeah . Most of TI - digits is connected digits , I think .\ngrad e: OK .\nprofessor b: The {disfmarker} I mean , we had a Bellcore corpus that we were using . It was {disfmarker} {vocalsound} that 's {disfmarker} that was isolated digits .\ngrad e: Maybe it 's the Bell Gram . Bell Digits . Alright .\nprofessor b: Um .\nphd f: By the way , I think we can improve these numbers if we care to compr improve them {vocalsound} by , um , {vocalsound} not starting with the Switchboard models but by taking the Switchboard models and doing supervised adaptation on a small amount of digit data collected in this setting .\ngrad e: Yep .\nphd f: Because that would adapt your models to the room acoustics and f for the far - field microphones , you know , to the noise . And that should really improve things , um , further . And then you use those adapted models , which are not speaker adapted but sort of acous you know , channel adapted {disfmarker}\ngrad e: Channel adapted .\nphd f: use that as the starting models for your speaker adaptation .\nprofessor b: Yeah . {vocalsound} But the thing is , uh {disfmarker} I mean , w when you {disfmarker} it depends whether you 're ju were just using this as a {disfmarker} {vocalsound} a starter task for {disfmarker} you know , to get things going for conversational or if we 're really interested i in connected digits . And I {disfmarker} I think the answer is both . And for {disfmarker} for connected digits over the telephone you don't actually want to put a whole lot of effort into adaptation\nphd f: Well , I don't know .\nprofessor b: because {vocalsound} somebody {pause} gets on the phone and says a number and then you just want it . You don't {disfmarker} don't , uh {disfmarker}\npostdoc c: This is {disfmarker} this {disfmarker} that one 's better .\nphd f: Right .\npostdoc c: Mm - hmm .\nphd f: Um , but , you know , I {disfmarker} uh , my impression was that you were actually interested in the far - field microphone , uh , problem , I mean . So , you want to {disfmarker} you want to {disfmarker} That 's the obvious thing to try .\npostdoc c: Oh . Oh .\nprofessor b: Right .\nphd f: Right ? Then , eh {disfmarker} because you {disfmarker} you don't have any {disfmarker}\npostdoc c: Yeah .\nphd f: That 's where the most m acoustic mismatch is between the currently used models and the {disfmarker} the r the set up here .\nprofessor b: Right .\nphd f: So .\nprofessor b: Yeah . So that 'd be anoth another interesting data point .\nphd f: Mm - hmm .\nprofessor b: I mean , I {disfmarker} I guess I 'm saying I don't know if we 'd want to do that as the {disfmarker} as {disfmarker}\nphd d: Other way .\ngrad e: Other way . Liz {disfmarker}\nphd a: Now you 're all watching me .\ngrad e: It f it clips over your ears .\nphd a: Alright . This way .\ngrad e: There you go .\npostdoc c: If you have a strong fe if you have a strong preference , you could use this .\nphd a: You 're all watching . This is terrible .\npostdoc c: It 's just we {disfmarker} we think it has some spikes . So , uh , we {disfmarker} we didn't use that one .\nphd a: I 'll get it .\npostdoc c: But you could if you want .\nprofessor b: Yeah . At any rate , I don't know if w\npostdoc c: I don't know . And Andre - Andreas , your {disfmarker} your microphone 's a little bit low .\nprofessor b: Yeah .\nphd f: It is ?\nprofessor b: I don't know if we wanna use that as the {disfmarker}\npostdoc c: Yeah .\ngrad e: Uh , it pivots .\nphd f: Uh .\npostdoc c: So if you see the picture\ngrad e: It {disfmarker} it {disfmarker} like this .\nphd f: I I {disfmarker}\npostdoc c: and then you have to scr\nphd f: I {disfmarker} I already adjusted this a number of times .\ngrad e: Eh .\nphd f: I {disfmarker} I\ngrad e: Yeah , I think these mikes are not working as well as I would like .\nphd f: can't quite seem to {disfmarker} Yeah , I think this contraption around your head is not {pause} working so well .\nprofessor b: Too many adju too many adjustments . Yeah . Anyway , what I was saying is that I {disfmarker} I think I probably wouldn't want to see that as sort of like the norm , that we compared all things to .\npostdoc c: That looks good . Yeah .\nprofessor b: To , uh , the {disfmarker} to have {disfmarker} have all this ad all this , uh , adaptation . But I think it 's an important data point , if you 're {disfmarker} if {disfmarker} Yeah .\nphd f: Right .\nprofessor b: Um . The other thing that {disfmarker} that , uh {disfmarker} of course , what Barry was looking at was {disfmarker} was just that , the near versus far . And , yeah , the adaptation would get {vocalsound} th some of that .\nphd f: Mm - hmm .\nprofessor b: But , I think even {disfmarker} even if there was , uh , only a factor of two or something , like I was saying in the email , I think that 's {disfmarker} {vocalsound} that 's a big factor . So {disfmarker}\nphd f: Mm - hmm .\nprofessor b: N\ngrad e: Liz , you could also just use the other mike if you 're having problems with that one .\npostdoc c: Well .\nphd a: OK .\npostdoc c: Yeah . This would be OK . We {disfmarker} we {disfmarker} we think that this has spikes on it ,\nphd a: It 's this thing 's {disfmarker} This is too big for my head .\npostdoc c: so it 's not as good acoustically ,\nphd f: Yeah , basically your ears are too big .\npostdoc c: but {disfmarker}\nphd f: I mean , mine are too . E th everybody 's ears are too big for these things .\nphd a: No , my {disfmarker} my {disfmarker} But this is too big for my head . So , I mean , {comment} {comment} it doesn't {disfmarker} you know , it 's sit\nphd f: Uh {disfmarker}\npostdoc c: Well , if you 'd rather have this one then it 's {disfmarker}\nphd a: OK .\nprofessor b: Yeah .\ngrad e: Oh , well .\nprofessor b: It 's {pause} great .\ngrad e: So the {disfmarker} To get that , uh , pivoted this way , it pivots like this .\nphd a: No this way . Yeah .\ngrad e: Yeah . There you go .\npostdoc c: And there 's a screw that you can tighten .\ngrad e: And then it {disfmarker}\nphd a: Right .\ngrad e: Right .\nphd a: I already {pause} tried to get it close .\npostdoc c: Good .\ngrad e: So if it doesn't bounce around too much , that 's actually good placement .\nphd a: OK .\npostdoc c: That looks good .\ngrad e: But it looks like it 's gonna bounce a lot .\nprofessor b: So , where were we ? Uh {disfmarker} {vocalsound} Yeah .\npostdoc c: Yeah .\ngrad e: Digits . Adaptation .\nprofessor b: Uh , adaptation , non - adaptation , um , factor of two , um {disfmarker} Oh , yeah . I know what I was go w\nphd f: What k u By the way , wh what factor of two did you {disfmarker} ?\nprofessor b: Oh , no , no .\nphd f: I mean {disfmarker}\nprofessor b: It 's tha that {disfmarker} that we were saying , you know , well is {disfmarker} how much worse is far than near , you know .\nphd f: Oh , th OK .\nprofessor b: And I mean it depends on which one you 're looking at ,\nphd f: That factor of two .\nprofessor b: but for the everybody , it 's {vocalsound} little under a factor or two .\nphd f: Mm - hmm .\nprofessor b: Yeah . I {disfmarker} I know what I was thinking was that maybe , uh , i i we could actually t t try at least looking at , uh , some of the {disfmarker} the large vocabulary speech from a far microphone , at least from the good one .\nphd f: Mm - hmm .\nprofessor b: I mean , before I thought we 'd get , you know , a hundred and fifty percent error or something , but if {disfmarker} {vocalsound} if , uh {disfmarker} if we 're getting thirty - five , forty percent or something , {vocalsound} u um {disfmarker}\nphd f: Mm - hmm .\nphd a: Actually if you run , though , on a close - talking mike over the whole meeting , during all those silences , you get , like , four hundred percent word error .\nprofessor b: Mm - hmm . Right . I understand . But doing the same kind of limited thing {disfmarker}\nphd a: Or {disfmarker} or some high number .\nprofessor b: Yeah , sure . Get all these insertions . But I 'm saying if you do the same kind of limited thing {vocalsound} as people have done in Switchboard evaluations or as {disfmarker} a\nphd a: Yeah . Where you know who the speaker is and there 's no overlap ? And you do just the far - field for those regions ?"}, {"chapter": 2, "start_ms": 1986000, "topic": "Forced alignments", "transcript_text": "professor b: Yeah . Yeah . The same sort of numbers that we got those graphs from . Right ?\ngrad e: Could we do exactly the same thing that we 're doing now , but do it with a far - field mike ?\nprofessor b: Yeah , do it with one of {disfmarker} on\ngrad e: Cuz we extract the times from the near - field mike , but you use the acoustics from the far - field mike .\nphd a: Right . I understand that . I just meant that {disfmarker} so you have {pause} three choices . There 's , um {disfmarker} You can use times where that person is talking only from the transcripts but the segmentations were {disfmarker} were synchronized . Or you can do a forced alignment on the close - talking to determine that , the you know , within this segment , these really were the times that this person was talking and elsewhere in the segment other people are overlapping and just front - end those pieces . Or you can run it on the whole data , which is {disfmarker} which is , you know , a {disfmarker}\nprofessor b: But {disfmarker} but {disfmarker} but how did we get the {disfmarker} how did we determine the links , uh , that we 're testing on in the stuff we reported ?\nphd a: In the H L T paper we took {pause} segments that are channel {disfmarker} time - aligned , which is now h being changed in the transcription process , which is good , and we took cases where the transcribers said there was only one person talking here , because no one else had time {disfmarker} any words in that segment and called that \" non - overlap \" .\nprofessor b: And tha And that 's what we were getting those numbers from .\nphd a: Yes . Tho - good {disfmarker} the good numbers .\nprofessor b: Right .\nphd a: The bad numbers were from {pause} the segments where there was overlap .\nprofessor b: Well , we could start with the good ones .\nphd a: Yeah .\nprofessor b: But anyway {disfmarker} so I think that we should try it once with {vocalsound} the same conditions that were used to create those , and in those same segments just use one of the P Z\nphd a: Right . So we {disfmarker} we can do that . Yeah .\nprofessor b: And then , you know , I mean , the thing is if we were getting , uh {disfmarker} what , thirty - five , forty percent , something like that on {disfmarker} on that particular set , uh , does it go to seventy or eighty ?\nphd a: Right .\nprofessor b: Or , does it use up so much memory we can't decode it ?\nphd a: It might also depend on which speaker th it is and how close they are to the PZM ?\nprofessor b: Uh {disfmarker}\nphd a: I don't know how different they are from each other .\nphd f: You want to probably choose the PZM channel that is closest to the speaker .\nphd a: To be best {disfmarker}\nphd d: Yeah .\ngrad e: For this particular digit ones , I just picked that one .\nphd a: f\nprofessor b: Well {disfmarker}\nphd a: OK . So we would then use that one , too ,\ngrad e: So {disfmarker}\nphd f: Oh , OK .\nprofessor b: This is kind of central .\nphd a: or {disfmarker} ?\nprofessor b: You know , it 's {disfmarker} so i but I would {disfmarker} I 'd pick that one . It 'll be less good for some people than for other , but I {disfmarker} I 'd like to see it on the same {disfmarker} exact same data set that {disfmarker} that we did the other thing on .\ngrad e: Actually {disfmarker} I sh actually should 've picked a different one ,\nprofessor b: Right ?\ngrad e: because {pause} that could be why the PDA is worse . Because it 's further away from most of the people reading digits .\nphd d: It 's further away . Yeah . Yeah .\nprofessor b: That 's probably one of the reasons .\npostdoc c: Hmm . Mm - hmm .\nphd a: Well , yeah . You could look at , I guess , that PZM or something .\ngrad e: Yep .\nprofessor b: But the other is , it 's very , uh {disfmarker} I mean , even though there 's {disfmarker} I 'm sure the f f the {disfmarker} the SRI , uh , front - end has some kind of pre - emphasis , it 's {disfmarker} it 's , uh {disfmarker} {vocalsound} still , th it 's picking up lots of low - frequency energy .\nphd f: Mm - hmm .\nprofessor b: So , even discriminating against it , I 'm sure some of it 's getting through . Um . But , yeah , you 're right . Prob - a part of it is just the distance .\nphd a: And aren't these pretty bad microphones ?\ngrad e: Yep .\nphd a: I mean {disfmarker}\nprofessor b: Well , they 're bad . But , I mean , if you listen to it , it sounds OK . You know ? u Yeah .\ngrad e: Yeah . When you listen to it , uh , the PZM and the PDA {disfmarker} Yeah , th the PDA has higher sound floor but not by a lot . It 's really pretty {disfmarker} uh , pretty much the same .\nphd a: I just remember you saying you got them to be cheap on purpose . Cheap in terms of their quality . So .\nprofessor b: Well , they 're {pause} twenty - five cents or so .\ngrad e: Th - we wanted them to be {disfmarker} to be typical of what would be in a PDA .\nprofessor b: Yeah .\nphd a: Mm - hmm .\ngrad e: So they are {disfmarker} they 're not the PZM three hundred dollar type . They 're the twenty - five cent ,\nprofessor b: Yeah .\ngrad e: buy them in packs of thousand type .\nphd a: I see .\nprofessor b: But , I mean , the thing is people use those little mikes for everything because they 're really not bad .\ngrad e: Everything .\nphd a: Mm - hmm .\nprofessor b: I mean , if you 're not {vocalsound} doing something ridiculous like feeding it to a speech recognizer , they {disfmarker} they {disfmarker} {vocalsound} they {disfmarker} you know , you can hear the sou hear the sounds just fine .\nphd a: Right .\nprofessor b: You know , it 's {disfmarker} They {disfmarker} I mean , i it 's more or less the same principles as these other mikes are built under , it 's just that {pause} there 's less quality control . They just , you know , churn them out and don't check them . Um . So . So that was {disfmarker} Yeah . So that was i interesting result . So like I said , the front - end guys are very much interested in {disfmarker} in this is as {disfmarker} as well and\nphd f: So {disfmarker} so , but where is this now ? I mean , what 's {disfmarker} where do we go from here ?\ngrad e: Yeah . That was gonna be my question .\nphd f: I mean , we {disfmarker} so we have a {disfmarker} we have a {disfmarker} a system that works pretty well but it 's not , you know , the system that people here are used to using {disfmarker} to working with .\nprofessor b: Well , I think what we wanna do is we want to {disfmarker} eh ,\nphd f: So what {disfmarker} what do we do now ?\nprofessor b: and we 've talked about this in other {pause} contexts {disfmarker} we want to {vocalsound} have the ability to feed it different features .\nphd f: Mm - hmm .\nprofessor b: And then , um , {vocalsound} from the point of view of the front - end research , it would be s uh , substituting for HTK .\nphd f: OK . OK .\nprofessor b: I think that 's the key thing . And then if we can feed it different features , then we can try all the different things that we 're trying there .\nphd f: OK . Alright .\nprofessor b: And then , um , uh , also Dave is {disfmarker} is thinking about using the data in different ways , uh , to {vocalsound} um , uh , explicitly work on reverberation\nphd f: Mm - hmm .\nprofessor b: starting with some techniques that some other people have {pause} found somewhat useful , and {disfmarker} Yeah .\nphd f: OK . So {disfmarker} so the key {pause} thing that 's missing here is basically the ability to feed , you know , other features {vocalsound} i into the recognizer\nprofessor b: Right .\nphd f: and also then to train the system .\nprofessor b: Right .\nphd f: OK . And , uh , es I don't know when Chuck will be back but that 's exactly what he {disfmarker} he 's gonna {disfmarker}\nprofessor b: H h He 's {disfmarker} he 's sort of back , but he drove for fourteen hours an and wasn't gonna make it in today .\nphd f: Oh , OK . So , I think that 's one of the things that he said he would be working on . Um .\ngrad e: Yeah .\nphd f: Just sort of t to make sure that {pause} we can do that\nprofessor b: Yeah .\nphd f: and {disfmarker} Um .\nprofessor b: Right .\nphd f: It 's {disfmarker} uh , I mean , the {disfmarker} the front - end is f i tha that 's in the SRI recognizer is very nice in that it does a lot of things on the fly but it unfortunately {pause} is not {pause} designed and , um {disfmarker} {vocalsound} like the , uh , ICSI system is , where you can feed it from a pipeline of {disfmarker} of the command . So , the {disfmarker} what that means probably for the foreseeable future is that you have to , uh , dump out , um {disfmarker} you know , if you want to use some new features , you have to dump them into individual files and {pause} give those files to the recognizer .\ngrad e: We do {disfmarker} we tend to do that anyway .\nphd f: OK .\ngrad e: Oh . So , although you {disfmarker} you can pipe it as well , we tend to do it that way because that way you can concentrate on one block and not keep re - doing it over and over .\nphd f: Oh , OK .\nprofessor b: Yeah .\nphd f: Alright .\nprofessor b: Yeah . So I 've {disfmarker} I {disfmarker}\ngrad e: So tha that 's exactly what the P - file {pause} is for .\nprofessor b: Yeah .\nphd f: Yeah , the {disfmarker} the {disfmarker} the cumbersome thing is {disfmarker} is , um {disfmarker} is that you actually have to dump out little {disfmarker} little files .\nphd a: Uh {disfmarker}\nphd f: So for each segment that you want to recognize {vocalsound} you have to {pause} dump out {pause} a separate file .\ngrad e: Uh - huh .\nphd f: Just like i th like th as if there were these waveform segments , but instead you have sort of feature file segments . But , you know {disfmarker} So .\nprofessor b: Cool . OK . So the s the {disfmarker} the next thing we had on the agenda was something about alignments ?\nphd a: Oh . Yes , we have {disfmarker} I don't know , did you wanna talk about it , or {disfmarker} ? I can give a {disfmarker} I was just telling this to Jane and {disfmarker} and {disfmarker} W we {disfmarker} we were able to get some definite improvement on the forced alignments by looking at them first and then realizing the kinds of errors {pause} that were occurring and um , some of the errors occurring very frequently are just things like the first word being moved to as early as possible in the recognition , which is a um , I think was both a {disfmarker} a pruning {pause} problem and possibly a problem with needing constraints on word locations . And so we tried both of these st things . We tried saying {disfmarker} I don't know , I got this {vocalsound} whacky idea that {disfmarker} just from looking at the data , that when people talk {pause} their words are usually chunked together . It 's not that they say one word and then there 's a bunch of words together . They 're {comment} might say one word and then another word far away if they were doing just backchannels ? But in general , if there 's , like , five or six words and one word 's far away from it , that 's probably wrong on average . So , um {disfmarker} And then also , ca the pruning , of course , was too {disfmarker} too severe .\nphd f: So that 's actually interesting . The pruning was the same value that we used for recognition . And we had lowered that {disfmarker} we had used tighter pruning after Liz ran some experiments showing that , you know , it runs slower and there 's no real difference in {disfmarker}\nphd a: Actually it was better with {disfmarker} slightly better or about th\ngrad e: No gain .\nphd a: it was the same with tighter pruning .\nphd f: Right . So for free recognition , this {disfmarker} the lower pruning value is better .\nphd a: It 's probably cuz the recognition 's just bad en at a point where it 's bad enough that {disfmarker} that you don't lose anything .\nphd f: You {disfmarker} Correct . Right . Um , but it turned out for {disfmarker} for {disfmarker} to get accurate alignments it was really important to open up the pruning significantly .\nphd a: Right .\nprofessor b: Hmm .\nphd f: Um {pause} because otherwise it would sort of do greedy alignment , um , in regions where there was no real speech yet from the foreground speaker .\nprofessor b: Mm - hmm .\nphd f: Um , {vocalsound} so that was one big factor that helped improve things and then the other thing was that , you know , as Liz said the {disfmarker} we f enforce the fact that , uh , the foreground speech has to be continuous . It cannot be {disfmarker} you cannot have a background speech hypothesis in the middle of the foreground speech . You can only have background speech at the beginning and the end .\nphd a: Yeah . I mean , yeah , it isn't always true , and I think what we really want is some clever way to do this , where , um , you know , from the data or from maybe some hand - corrected alignments from transcribers that things like words that do occur just by themselves {pause} a alone , like backchannels or something that we did allow to have background speech around it {disfmarker}\nphd d: Yeah .\nphd a: those would be able to do that ,\npostdoc c: Sorry ."}, {"chapter": 3, "start_ms": 2724000, "topic": "Evaluation of results", "transcript_text": "phd a: but the rest would be constrained . So , I think we have a version that 's pretty good for the native speakers . I don't know yet about the non - native speakers . And , um , we basically also made noise models for the different {disfmarker} sort of grouped some of the {pause} mouth noises together . Um , so , and then there 's a background speech model . And we also {disfmarker} There was some neat {disfmarker} or , interesting cases , like there 's one meeting where , {vocalsound} um , Jose 's giving a presentation and he 's talking about , um , the word \" mixed {pause} signal \" and someone didn't understand , uh , that you were saying \" mixed \" {disfmarker} I think , Morgan . And so your speech - ch was s saying something about mixed signal .\nphd h: Yeah , yeah .\nphd a: And the next turn was a lot of people saying \" mixed \" , like \" he means mixed signal \" or \" I think it 's mixed \" . And the word \" mixed \" in this segment occurs , like , a bunch of times .\nphd h: Sh\nphd a: And Chuck 's on the lapel here , and he also says \" mixed \" but it 's at the last one , and of course the aligner th aligns it everywhere else to everybody else 's \" mixed \" ,\nphd h: Yeah .\nphd a: cuz there 's no adaptation yet . So there 's {disfmarker} {vocalsound} I think there 's some issues about {disfmarker} u We probably want to adapt at least the foreground speaker . But , I guess Andreas tried adapting both the foreground and a background generic speaker , and that 's actually a little bit of a f funky model . Like , it gives you some weird alignments , just because often the background speakers match better to the foreground than the foreground speaker .\nphd f: Oh {disfmarker}\nphd d: Yeah .\nphd a: So there 's some things there ,\nphd h: Oh .\nphd a: especially when you get lots of the same words , uh , occurring in the {disfmarker}\nphd f: Well , the {disfmarker} I {disfmarker} I think you can do better by {vocalsound} uh , cloning {disfmarker} so we have a reject phone . And you {disfmarker} and what we wanted to try with {disfmarker} you know , once we have this paper written and have a little more time , {vocalsound} uh , t cloning that reject model and then one copy of it would be adapted to the foreground speaker to capture the rejects in the foreground , like fragments and stuff , and the other copy would be adapted to the background speaker .\nphd a: Right . I mean , in general we actually {disfmarker}\nphd f: And {disfmarker}\nphd a: Right now the words like {pause} partial words are {pause} reject models and you normally allow those to match to any word .\nphd f: Mm - hmm .\nphd a: But then the background speech was also a reject model , and so this constraint of not allowing rejects in between {disfmarker} you know , it needs to differentiate between the two . So just sort of working through a bunch of debugging kinds of issues .\nphd f: Right .\nphd a: And another one is turns , like people starting with {vocalsound} \" well I think \" and someone else is {pause} \" well how about \" . So the word \" well \" is in this {disfmarker} in this {pause} segment multiple times , and as soon as it occurs usually the aligner will try to align it to the first person who says it . But then that constraint of sort of {disfmarker} uh , proximity constraint will push it over to the person who really said it in general .\ngrad e: Is the proximity constraint a hard constraint , or did you do some sort of probabilistic weighting distance , or {disfmarker} ?\nphd f: We {disfmarker} we didn't {disfmarker}\nphd a: Right now it 's a kluge .\nphd f: No . We {disfmarker} w OK . We {disfmarker} it 's straightforward to actually just have a {disfmarker} a penalty that doesn't completely disallows it but discourages it . But , um , we just didn't have time to play with , you know , tuning yet another {disfmarker} yet another parameter .\ngrad e: The ve level . Yeah .\nphd a: Yeah .\nphd f: And really the reason we can't do it is just that we don't have a {disfmarker} we don't have ground truth for these . So , {vocalsound} we would need a hand - marked , um , {vocalsound} word - level alignments or at least sort of the boundaries of the speech betw you know , between the speakers . Um , and then use that as a reference and tune the parameters of the {disfmarker} of the model , uh , to op to get the best {pause} performance .\nphd a: Yeah .\nprofessor b: G given {disfmarker} I {disfmarker} I mean , I wa I wa I was gonna ask you anyway , uh , how you assessed that things were better .\nphd f: Mm - hmm .\nphd a: I looked at them . I spent two days {disfmarker} um , in Waves {disfmarker}\nprofessor b: OK .\nphd a: Oh , it was painful because {vocalsound} the thing is , you know the alignments share a lot in common , so {disfmarker} And you 're {disfmarker} yo you 're looking at these segments where there 's a lot of speech . I mean , a lot of them have a lot of words . Not by every speaker\nprofessor b: Yeah .\nphd a: but by some speaker there 's a lot of words . No , not {disfmarker}\nprofessor b: Yeah .\nphd a: I mean that if you look at the individual segments from just one person you don't see a lot of words ,\nphd h: Ju\nprofessor b: Yeah .\nphd a: but altogether you 'll see a lot of words up there .\nprofessor b: Yeah .\nphd f: Mm - hmm .\nphd d: Yeah .\nphd a: And so the reject is also mapping and pauses {disfmarker} So I looked at them all in Waves and just lined up all the alignments , and , at first it sort of looked like a mess and then the more I looked at it , I thought \" OK , well it 's moving these words leftward and {disfmarker} \" You know , it wasn't that bad . It was just doing certain things wrong . So {disfmarker} But , I don't , you know , have time to l {comment} to look at all of them and it would be really useful to have , like , a {disfmarker} a transcriber who could use Waves , um , just mark , like , the beginning and end of the foreground speaker 's real words {disfmarker} like , the beginning of the first word , the end of the last word {disfmarker} and then we could , you know , do some adjustments .\npostdoc c: Yeah . I {disfmarker} OK . I have to ask you something , is i does it have to be Waves ? Because if we could benefit from what you did , incorporate that into the present transcripts , {comment} that would help .\nphd f: No .\npostdoc c: And then , um , the other thing is , I believe that I did hand So . One of these transcripts was gone over by a transcriber and then I hand - marked it myself so that we do have , uh , the beginning and ending of individual utterances . Um , I didn't do it word level ,\nphd f: Mm - hmm .\npostdoc c: but {disfmarker} but in terms {disfmarker}\nphd a: Mm - hmm .\npostdoc c: So I {disfmarker} so for {disfmarker} for one of the N S A groups . And also I went back to the original one that I first transcribed and {disfmarker} and did it w uh , w uh , utterance by utterance for that particular one . So I think you do have {disfmarker} if that 's a sufficient unit , I think that you do have hand - marking for that . But it 'd be wonderful to be able to {vocalsound} benefit from your Waves stuff .\nphd a: Mm - hmm .\nphd f: We don't care what {disfmarker} what tool you use .\nphd a: Yeah . I mean , if {disfmarker} if you can , um {disfmarker} if you wanna {disfmarker}\npostdoc c: OK . I used it in Transcriber\nphd f: U uh {disfmarker}\npostdoc c: and it 's {disfmarker} it 's in the {disfmarker}\nphd a: well , Jane and I were {disfmarker} just in terms of the tool , talking about this . I guess Sue had had some {pause} reactions . You know , interface - wise if you 're looking at speech , you wanna be able to know really where the words are . And so , {vocalsound} we can give you some examples of sort of what this output looks like ,\npostdoc c: Yeah , that 's right . Middle of the word , or {disfmarker}\nphd a: um , and see if you can in maybe incorporate it into the Transcriber tool some way , or {disfmarker}\npostdoc c: Well , I th I 'm thinking just ch e e incorporating it into the representation .\nphd a: Um .\npostdoc c: I mean , if it 's {disfmarker} if it 's {disfmarker}\nphd a: You mean like {disfmarker} Yeah , word start insights .\npostdoc c: if you have start points , if you have , like , time tags ,\nphd a: Right .\npostdoc c: which is what I assume . Isn't that what {disfmarker} what you {disfmarker} ? Well , see , Adam would be {disfmarker}\nphd f: Yeah , whatever you use .\nphd a: Yeah .\nphd f: I mean , we convert it to this format that the , um , NIST scoring tool unders uh , CTM . Conversation Time - Marked file . And {disfmarker} and then that 's the {disfmarker} that 's what the {disfmarker}\ngrad e: I think Transcriber , uh , outputs CTM .\npostdoc c: If it {disfmarker} ? OK .\nphd a: Yeah .\npostdoc c: So you would know this more than I would .\ngrad e: I think so .\nphd a: So , I mean {disfmarker}\npostdoc c: It seems like she {disfmarker} if she 's g if she 's moving time marks around ,\nphd f: Right .\npostdoc c: since our representation in Transcriber uses time marks , it seems like there should be some way of {disfmarker} of using that {disfmarker} benefitting from that .\ngrad e: Right .\nphd a: Yeah , it wou the advantage would just be that when you brought up a bin you would be able {disfmarker} if you were zoomed in enough in Transcriber to see all the words ,\nprofessor b: Mm - hmm .\nphd a: you would be able to , like , have the words sort of located in time , if you wanted to do that .\nprofessor b: So {disfmarker} so if we e e even just had a {disfmarker} a {disfmarker} It sounds like w we {disfmarker} {vocalsound} we almost do .\nphd a: So .\nprofessor b: Uh , if we {disfmarker} We have two .\npostdoc c: We have two .\nprofessor b: Yeah . Just ha uh , trying out {pause} the alignment {vocalsound} procedure that you have on that\nphd a: Mm - hmm .\nprofessor b: you could actually get something , um {disfmarker} uh , uh , get an objective measure . Uh {disfmarker}\nphd f: Mm - hmm .\nphd a: You mean on {disfmarker} on the hand - marked , um {disfmarker} So we {disfmarker} we only r hav I only looked at actually alignments from one meeting that we chose ,\nprofessor b: Yeah .\nphd a: I think MR four , just randomly , um {disfmarker} And {disfmarker}\nphd f: Actually , not randomly .\nphd a: Not randomly {disfmarker}\nphd f: We knew {disfmarker} we knew that it had these insertion errors from {disfmarker}\nphd a: It had sort of {pause} average recognition performance in a bunch of speakers\nphd f: Yeah . Yeah .\nphd a: and it was a Meeting Recorder meeting . Um . But , yeah , we should try to use what you have . I did re - run recognition on your new version of MR one .\npostdoc c: Oh , good .\nphd a: I {disfmarker} I mean the {disfmarker} the one with Dan {pause} Ellis in it {vocalsound} and Eric .\npostdoc c: Good ! Uh - huh . Yeah , exactly . Yeah . Yeah .\ngrad g: I don't think that was the new version .\nphd a: Um {disfmarker} That {disfmarker} Yeah , actually it wasn't the new new , it was the medium new .\npostdoc c: OK .\nphd a: But {disfmarker} but we would {disfmarker} we should do the {disfmarker} the latest version .\npostdoc c: OK .\ngrad g: Yeah .\nphd a: It was the one from last week .\ngrad g: You {disfmarker} did you adjust the {disfmarker} the utterance times , um , for each channel ?\npostdoc c: Yes . Yes , I did . And furthermore , I found that there were a certain number where {disfmarker} {vocalsound} not {disfmarker} not a lot , but several times I actually {vocalsound} moved an utterance from {vocalsound} Adam 's channel to Dan 's or from Dan 's to Adam 's . So there was some speaker identif And the reason was because {vocalsound} I transcribed that at a point before {disfmarker} {vocalsound} uh , before we had the multiple audio available f so I couldn't switch between the audio . I {disfmarker} I transcribed it off of the mixed channel entirely , which meant in overlaps , I was at a {disfmarker} at a terrific disadvantage .\nphd a: Right . Right .\npostdoc c: In addition it was before the channelized , uh , possibility was there . And finally I did it using the speakers of my , um {disfmarker} {vocalsound} of {disfmarker} you know , off the CPU on my {disfmarker} on my machine cuz I didn't have a headphone .\nphd a: Right .\npostdoc c: So it @ @ , like , I mean {disfmarker} Yeah , I {disfmarker} I mean , i in retrospect {vocalsound} it would 've been good to ha {vocalsound} have got I should 've gotten a headphone . But in any case , um , thi this is {disfmarker} this was transcribed in a {disfmarker} in a , {vocalsound} uh , less optimal way than {disfmarker} than the ones that came after it , and I was able to {disfmarker} you know , an and this meant that there were some speaker identif identifications which were changes .\ngrad g: Well , I know there were some speaker labelling problems , um , after interruptions .\npostdoc c: Yeah . Fixed that .\ngrad g: Is that what you 're referring to ? I mean , cuz there 's this one instance when , for example , you 're running down the stairs .\npostdoc c: Oh , well {disfmarker}\ngrad g: I remember this meeting really well .\nphd d: Yeah .\nphd a: Don {disfmarker} Don has had {disfmarker} {vocalsound} He knows {disfmarker} he can just read it like a play .\ngrad g: Right . It 's a {disfmarker} Yeah , I 've {disfmarker} I 've {disfmarker} I 'm very well acquainted with this meeting .\nphd d: Yeah .\ngrad g: Yeah , I can s\nphd a: \" And then she said , and then he said . \"\ngrad g: Yeah , I know it by heart . So , um , {vocalsound} there 's one point when you 're running down the stairs .\npostdoc c: Uh - oh .\ngrad g: Right ? And , like , there 's an interruption . You interrupt somebody , but then there 's no line after that . For example , there 's no speaker identification after that line .\npostdoc c: Uh - huh .\ngrad g: Is that what you 're talking about ? Or were there mislabellings as far as , like , the a Adam was {disfmarker} ?\npostdoc c: That was fixed , um , before {disfmarker} i i i I think I I think I understood that pretty {disfmarker}\ngrad g: Yeah . Cuz I thought I let you know about that .\npostdoc c: Thank you for mentioning . Yeah , no , tha that {disfmarker} That I think went away a couple of versions ago ,\ngrad g: Yeah . OK .\npostdoc c: but it 's good to know .\ngrad g: But you 're actually saying that certain , uh , speakers were mis mis - identified .\npostdoc c: Yeah . So , with {disfmarker} under {disfmarker} um , uh , listening to the mixed channel , there were times when , as surprising as that is , I got Adam 's voice confused with Dan 's and vice versa {disfmarker}\ngrad g: OK .\npostdoc c: not for long utterances ,\ngrad g: OK .\nphd a: Yeah .\npostdoc c: but jus just a couple of places ,\nprofessor b: Mm - hmm .\npostdoc c: and embedde embedded in overlaps . The other thing that was w interesting to me was that I picked up a lot of , um , backchannels which were hidden in the mixed signal ,\nphd a: Right .\npostdoc c: which , you know , I mean , you c not {disfmarker} not too surprising . But the other thing that {disfmarker} I {disfmarker} I hadn't thought about this , but I thou I wanted to raise this when you were {disfmarker} uh , with respect to also a strategy which might help with the alignments potentially , but that 's {disfmarker} When I was looking at these backchannels , they were turning up usually {disfmarker} {vocalsound} very often in {disfmarker} w well , I won't say \" usually \" {disfmarker} but anyway , very often , I picked them up in a channel {vocalsound} w which was the person who had asked a question . S so , like , someone says \" an and have you done the so - and - so ? \" And then there would be backchannels , but it would be the person who asked the question . Other people weren't really doing much backchannelling . And , you know , sometimes you have the {disfmarker} Yeah , uh - huh .\nphd a: Well , that 's interesting . Yeah .\npostdoc c: I mean , i it wouldn't be perfect , but {disfmarker} but it does seem more natural to give a backchannel when {disfmarker} when you 're somehow involved in the topic ,\nphd a: No , that 's really interesting .\nprofessor b: Mm - hmm .\npostdoc c: and the most natural way is for you to have initiated the topic by asking a question .\nphd f: Well ,\nphd a: That 's interesting .\nphd f: I think {disfmarker} No . I think it 's {disfmarker} actually I think what 's going on is backchannelling is something that happens in two - party conversations .\npostdoc c: Mm - hmm .\nphd f: And if you ask someone a question , you essentially initiating a little two - party conversation .\npostdoc c: Yeah .\nphd a: Well , actu Yeah , when we looked at this {disfmarker}\npostdoc c: Exactly .\nphd f: So then you 're {disfmarker} so and then you 're expected to backchannel because the person is addressing you directly and not everybody .\npostdoc c: Exactly . Exactly my point . An - and so this is the expectation thing that {disfmarker} uh , uh ,\nphd f: Yeah . Yeah .\nphd a: Mm - hmm .\nphd f: Right .\npostdoc c: just the dyadic {disfmarker}\nphd f: Right .\npostdoc c: But in addition , you know , if someone has done this analysis himself and isn't involved in the dyad , but they might also give backchannels to verify what {disfmarker} what the answer is that this {disfmarker} that the {disfmarker} the answerer 's given {disfmarker}\nprofessor b: H\nphd a: Right .\nprofessor b: I tell you , I say {disfmarker} I say \" uh - huh \" a lot ,\nphd a: It 's {disfmarker}\npostdoc c: There you go .\nphd a: Well , but it 's interesting cuz , uh {disfmarker}\nprofessor b: while people are talking to each other .\nphd a: But there are fewer {disfmarker} I think there are fewer \" uh - huhs \" .\npostdoc c: There you go . Yeah . Yeah .\nphd a: I mean , just from {disfmarker} We were looking at word frequency lists to try to find the cases that we would allow to have the reject words in between in doing the alignment . You know the ones we wouldn't constrain to be next to the other words .\npostdoc c: Oh , yeah .\nphd a: And \" uh - huh \" is not as frequent as it sort of would be in Switchboard , if you looked at just a word frequency list of one - word short utterances . And \" yeah \" is way up there , but not \" uh - huh \" . And so I was thinking thi it 's not like {pause} you 're being encouraged by everybody else to keep {pause} talking in the meeting . And uh , that 's all , I I 'll stop there , cuz I I think what you say makes a lot of sense .\npostdoc c: Well , that 's right . And that would {disfmarker}\nphd a: But it was sort of {disfmarker}\npostdoc c: Well , an And what you say is the {disfmarker} is the re uh , o other side of this , which is that , you know , so th there are lots of channels where you don't have these backchannels , w when a question has been asked and {disfmarker} and these {disfmarker}\nphd a: Right . There 's just probably less backchannelling in general ,\npostdoc c: Mm - hmm . So that 's good news , really .\nphd a: even if you consider every other person altogether one person in the meeting , but we 'll find out anyway . We were {disfmarker} I guess the other thing we 're {disfmarker} we 're {disfmarker} I should say is that we 're gonna , um try {disfmarker} compare this type of overlap analysis to Switchboard , where {disfmarker}\nphd f: And\nphd a: and CallHome , where we have both sides , so that we can try to answer this question of , you know , {vocalsound} is there really more overlap in meetings or is it just because we don't have the other channel in Switchboard\nprofessor b: Mm - hmm .\ngrad e: Mm - hmm .\nphd a: and we don't know what people are doing . Try to create a paper out of that .\nprofessor b: Yeah . I mean , y y you folks have probably {pause} already told me , but were {disfmarker} were you intending to do a Eurospeech submission , or {disfmarker} ?\nphd a: Um , you mean the one due tomorrow ?\nprofessor b: Yeah .\nphd a: Yeah . Well , we 're still , like , writing the scripts for doing the research , and we will {disfmarker} Yes , we 're gonna try .\npostdoc c: Mm - hmm .\nphd a: And I was telling Don , do not {pause} take this as an example of how people should work .\nprofessor b: Do as I say ,\ngrad g: That 's r\nphd a: So , {comment} we will try .\nprofessor b: don't do as I do . Yeah .\nphd a: It 'll probably be a little late ,\ngrad e: Well {disfmarker}\nphd a: but I 'm gonna try it .\ngrad e: It is different . In previous years , Eurospeech only had the abstract due by now , not the full paper .\nphd a: Right .\ngrad g: Right .\ngrad e: And so all our timing was off . I 've given up on trying to do digits . I just don't think that what I have so far makes a Eurospeech paper .\nphd a: Well , I 'm no We may be in the same position , and I figured {vocalsound} we 'll try , because that 'll at least get us to the point where we have {disfmarker} We have this really nice database format that Andreas and I were working out that {disfmarker} It {disfmarker} it 's not very fancy . It 's just a ASCII line by line format , but it does give you information {disfmarker}\nphd f: It 's the {disfmarker} it 's the spurt format .\nphd a: It {disfmarker} Yeah , we 're calling these \" spurts \" after Chafe . I was trying to find what 's a word for {pause} a continuous region with {pause} pauses around it ?\npostdoc c: Hmm .\nprofessor b: Yeah . I know that th the Telecom people use {disfmarker} use \" spurt \" for that .\npostdoc c: Good .\nphd a: They do ? Oh !\nprofessor b: Yes .\nphd f: Oh .\nphd a: Oh .\nprofessor b: And that 's {disfmarker} I mean , I {disfmarker} I was using that for a while when I was doing the rate of speech stuff ,\nphd a: I would jus\nprofessor b: because I {disfmarker} because I looked up in some books and I found {disfmarker} OK , I wanna find a spurt {vocalsound} in which {disfmarker}\nphd a: Ah , right ! It 's just , like , defined by the acoustics .\nprofessor b: and {disfmarker} an because {disfmarker} cuz it 's another question about how {pause} many pauses they put in between them .\ngrad e: Horrible .\nphd a: Right .\nprofessor b: But how fast do they do {pause} the words within the spurt ?\nphd a: Right .\nprofessor b: Yeah .\nphd a: Well , that 's what we were calling spurt ,\ngrad e: It 's gonna {disfmarker}\ngrad g: you know \" Burst \" also ?\ngrad e: Burst .\ngrad g: Isn't \" burst \" is used also ?\nphd a: so {disfmarker}\ngrad e: Spurt has the horrible name overloading with other {disfmarker} with hardware at ICSI .\nprofessor b: Here . Just very locally , yeah .\nphd a: Well , well , Chafe had this wor I think it was Chafe , or somebody had a {disfmarker} the word \" spurt \" originally ,\nprofessor b: But {disfmarker} but that just {disfmarker}\nphd h: Here @ @ {disfmarker}\nphd a: and so I {disfmarker} But tha that 's good to know .\npostdoc c: Actually {disfmarker}\nphd a: Was thi it 's Chafe ?\npostdoc c: Well , see , I know S Sue wrote about spurts of development .\nphd f: So maybe we should talk {disfmarker}\nphd a: Maybe it was Sue {disfmarker} ? Y\npostdoc c: But , in any case , I think it 's a good term ,\nphd a: So we have spurts and we have spurt - ify dot shell and spurt - ify\nprofessor b: Yeah .\npostdoc c: and , uh {disfmarker}\ngrad e: Hmm !\nprofessor b: Yeah .\npostdoc c: And ma maybe {disfmarker} maybe Chafe did .\nphd f: Uh .\nphd a: And then it 's got all {disfmarker} it 's a verb now .\npostdoc c: I know {disfmarker} I know Ch - Chafe dealt with {disfmarker}\nphd f: So s\ngrad g: That 's cool .\nphd f: W uh , w\npostdoc c: Chafe speaks about intonation units .\nphd a: Yes . Right .\npostdoc c: But maybe he speaks about spurts as well\nphd f: We\npostdoc c: and I just don't know . Yeah , go ahead .\ngrad e: I 've heard \" burst \" also .\nphd f: So what we 're doing {disfmarker} uh , this {disfmarker} this is just {disfmarker} maybe someone has s some {disfmarker} some ideas about how to do it better ,\ngrad g: Mmm .\nphd f: but we {disfmarker} So we 're taking these , uh , alignments from the individual channels . We 're {disfmarker} from each alignment we 're producing , uh , one of these CTM files ,\npostdoc c: Great .\nphd f: which essentially has {disfmarker} it 's just a linear sequence of words with the begin times for every word and the duration .\nphd a: It looks like a Waves label file almost . Right ?\nphd f: And {disfmarker} and {disfmarker} and of course {disfmarker}\nphd a: It 's just {disfmarker}\nphd f: Right . But it has {disfmarker} one {disfmarker} the first column has the meeting name , so it could actually contain several meetings . Um . And the second column is the channel . Third column is the , um , start times of the words and the fourth column is the duration of the words . And then we 're , um {disfmarker} OK . Then we have a messy alignment process where we actually insert into the sequence of words the , uh , tags for , like , where {disfmarker} where sentence {disfmarker} ends of sentence , question marks , um , {vocalsound} various other things .\nphd a: Yeah . These are things that we had Don {disfmarker}\nphd f: Uh .\nphd a: So , Don sort of , um , propagated the punctuation from the original transcriber {disfmarker}\nphd f: Right .\nphd a: so whether it was , like , question mark or period or , {vocalsound} um , you know , comma and things like that , and we kept the {disfmarker} and disfluency dashes {disfmarker} uh , kept those in because we sort of wanna know where those are relative to the spurt overlaps {disfmarker}\nphd f: Mm - hmm . Right .\nphd a: sp overlaps ,\nphd f: So {disfmarker} so those are actually sort of retro - fitted into the time alignment .\nphd a: or {disfmarker}\nphd f: And then we merge all the alignments from the various channels and we sort them by time . And then there 's a {disfmarker} then there 's a process where you now determine the spurts . That is {disfmarker} Actually , no , you do that before you merge the various channels . So you {disfmarker} you id identify by some criterion , which is pause length {disfmarker} you identify the beginnings and ends of these spurts , and you put another set of tags in there to keep those straight .\nprofessor b: Mm - hmm .\nphd f: And then you merge everything in terms of , you know , linearizing the sequence based on the time marks . And then {vocalsound} you extract the individual channels again , but this time you know where the other people start and end talking {disfmarker} you know , where their spurts start and end . And so you extract the individual channels , uh , one sp spurt by spurt as it were . Um , and inside the words or between the words you now have begin and end {pause} tags for overlaps . So , you {disfmarker} you basically have everything sort of lined up and in a form where you can look at the individual speakers and how their speech relates to the other speakers ' speech .\ngrad e: Right .\nphd a: Uh , I mean , I think that 's actually really u useful also\nphd f: And {disfmarker}\nphd a: because even if you weren't studying overlaps , if you wanna get a transcription for the far - field mikes , how are you gonna know which words from which speakers occurred at which times relative to each other ? You have to be able to {pause} get a transcript like {disfmarker} like this anyway , just for doing far - field recognition . So , you know , it 's {disfmarker} it 's sort of {disfmarker}\nphd f: Yeah .\nphd a: I thi it 's just an issue we haven't dealt with before , how you time - align things that are overlapping anyway .\npostdoc c: That 's wonderful .\nphd f: So {disfmarker}\nphd a: I mean , i I never thought about it before ,\ngrad e: Well {disfmarker}\nphd f: And {disfmarker} and we {disfmarker}\nphd a: but {disfmarker}\ngrad e: Y yes .\nphd f: In {disfmarker}\ngrad e: I mean , s when I came up with the original data {disfmarker} suggested data format based on the transcription graph , there 's capability of doing that sort of thing in there .\nphd a: Right . But you can't get it directly from the transcription .\npostdoc c: Mm - hmm . Yeah , that 's right .\nphd f: Right . Well , this is {disfmarker} this is just {disfmarker}\nphd a: Yeah , this is like a poor man 's ver formatting version . But it 's , you know {disfmarker} It 's clean , it 's just not fancy .\ngrad e: Right .\nphd a: Um .\nphd f: Well , there 's lots of little things . It 's like there 're twelve different scripts which you run and then at the end you have what you want . But , um , at the very last stage we throw away the actual time information . All we care about is whether {disfmarker} that there 's a certain word was overlapped by someone else 's word . So you sort of {disfmarker} at that point , you discretize things into just having overlap or no overlap . Because we figure that 's about the level of analysis that we want to do for this paper .\ngrad e: Mm - hmm .\nphd f: But if you wanted to do a more fine - grained analysis and say , you know , how far into the word is the overlap , you could do that .\nphd a: Yeah .\nphd f: It 's just {disfmarker} it 'll just require more {disfmarker}\nphd a: Just {pause} sort of huge .\nphd f: you know , slightly different {disfmarker}\npostdoc c: What 's interesting is it 's exactly what , um , i in discussing with , um , Sue about this ,\nphd a: Yeah .\npostdoc c: um , she , um , i i i indicated that that {disfmarker} you know , that 's very important for overlap analysis .\nphd a: Yeah . It 's {disfmarker} it 's nice to know ,\nphd f: Right .\nphd a: and also I think as a human , like , I don't always hear these in the actual order that they occur . So I can have two foreground speakers , you know , Morgan an and {vocalsound} um , Adam and Jane could all be talking , and I could align each of them to be starting their utterance at the correct time , and then look where they are relative to each other , and that 's not really what I heard .\npostdoc c: And that 's another thing she said .\nphd a: Cuz it 's just hard to do .\npostdoc c: This is {disfmarker} This is Bever 's {disfmarker} Bever 's effect ,\nphd a: Y Yeah .\npostdoc c: when {disfmarker} where {disfmarker} In psy ps psycho - linguistics you have these experiments where people have perceptual biases a as to what they hear ,\nphd a: It 's sort of {disfmarker} Yeah , you sort of move things around until you get to a {pause} low information point\npostdoc c: that {disfmarker} that {disfmarker} Not the best {disfmarker}\nphd a: and yo then you can bring in the other person . So it 's {vocalsound} actually not even possible , I think , for any person to listen to a mixed signal , even equalize , and make sure that they have all the words in the right order . So , I guess , we 'll try to write this Eurospeech paper .\npostdoc c: Mm - hmm . Superb .\nphd a: I mean , we will write it . Whether they accept it {pause} late or not , I don't know . Um , and the good thing is that we have {disfmarker} It 's sort of a beginning of what Don can use to link the prosodic features from each file to each other .\nphd f: Yeah .\nprofessor b: Yeah . That 's the good thing about these pape\nphd a: So . i You know , might as well .\nphd f: Plus , mayb\nphd h: Hmm ?\nphd a: We - I ju Otherwise we won't get the work done {comment} {vocalsound} on our deadline .\nphd f: I don't know , m\nprofessor b: Yeah .\nphd f: I mean , u u Jane likes to look at data . Maybe , you know , you could {disfmarker} you could look at this format and see if you find anything interesting .\nprofessor b: Yeah .\nphd f: I don't know .\nphd a: Yeah .\nprofessor b: No , it 's {disfmarker} that 's the good thing about these pape paper deadlines and , uh , you know , class projects , and {disfmarker} {vocalsound} and things like that ,\npostdoc c: Well , what I 'm thinking is {disfmarker}\nphd f: Yeah .\npostdoc c: Yeah .\nphd a: Right .\nphd f: Mm - hmm .\npostdoc c: Well , my {disfmarker}\nphd f: Well th th the other thing that {disfmarker} that {disfmarker} that yo that you usually don't tell your graduate students is that these deadlines are actually not that , um , you know , strictly enforced ,\nprofessor b: because you {disfmarker} you really get g\nphd a: Forces you to do the work .\npostdoc c: Yeah .\nprofessor b: Yeah .\nphd a: Exactly .\ngrad e: Strict .\nphd f: because {pause} the {disfmarker}\nprofessor b: Oh , now it 's out in the public , this {disfmarker} this {disfmarker} this secret information .\nphd f: because {disfmarker}\nphd a: Right .\nprofessor b: Yeah .\npostdoc c: I think we can ha\nphd f: bec b {vocalsound} Nah {disfmarker}\nphd a: So {disfmarker}\ngrad e: No .\nprofessor b: No .\npostdoc c: Nah .\nphd f: i Because these {disfmarker} the conference organizers actually have an interest in getting lots of submissions .\nphd a: Right .\ngrad e: Right .\nphd f: I mean , a {disfmarker} a monetary interest .\nprofessor b: Yeah .\nphd f: So {disfmarker} {vocalsound} Um .\nprofessor b: Th - that 's {disfmarker} that 's true .\npostdoc c: And good ones , good ones , which sometimes means {pause} a little extra time .\nphd f: And good submission\nprofessor b: That 's {disfmarker}\nphd f: Right .\nprofessor b: That 's true .\nphd f: Well {disfmarker} That 's another issue ,\nprofessor b: By th by the way , this is totally unfair , you may {disfmarker} you may feel ,\nphd f: but {disfmarker}\nprofessor b: but the {disfmarker} the , uh {disfmarker} the morning meeting folks actually have an {disfmarker} an extra month or so .\nphd f: Mm - hmm .\nphd d: Yep .\ngrad e: Yep . The Aurora {disfmarker} there 's a special Aurora {disfmarker}\nphd a: Uh {disfmarker}\nphd f: When {disfmarker}\nprofessor b: There 's a special Aurora session\nphd a: Oh .\nprofessor b: and the Aurora pe people involved in Aurora have till Ma - uh , early May {pause} or something to turn in their paper .\nphd f: Mmm .\nphd a: Oh .\nphd f: Mmm .\nphd a: Oh , well maybe we 'll submit to s {comment} {vocalsound} Actually {disfmarker}\nphd f: Well , then you can just {disfmarker} Maybe you can submit the digits paper on e for the Aurora session .\nphd h: Yeah .\nphd a: Yeah .\nphd d: Yeah .\ngrad e: Oh , I could !\nphd a: Yeah .\nprofessor b: I if it w\ngrad e: I could submit that to Aurora .\nprofessor b: Well {disfmarker}\ngrad e: That would be pretty {disfmarker} pretty {disfmarker}\nphd f: Yeah .\nprofessor b: i it has {disfmarker}\nphd a: Yeah .\nprofessor b: \ngrad e: S That wouldn't work .\nprofessor b: No , it wouldn't work .\ngrad e: It 's not Aurora .\nprofessor b: It 's {disfmarker} it 's not the Aurora {disfmarker} I mean , it {disfmarker} it 's {disfmarker} it 's actually the Aurora task .\nphd a: Maybe they 'll get s\ngrad e: Aurora 's very specific .\nprofessor b: It\nphd a: Well , maybe it won't be after this {vocalsound} deadline {pause} extension .\nphd f: But {disfmarker} but the people {disfmarker} I mean , a {disfmarker} a paper that is not on Aurora would probably be more interesting at that point\nphd a: Maybe they 'll {disfmarker}\nphd f: because everybody 's so sick and tired of the Aurora task .\nphd d: Yeah .\ngrad e: Oh , I thought you meant this was just the digits section . I didn't know you meant it was Aurora digits .\nprofessor b: Yeah .\nphd f: Well , no . If you {disfmarker} if you have {disfmarker} it 's to {disfmarker} if you discuss some relation to the Aurora task , like if you use the same {disfmarker}\nprofessor b: This is not the Aurora task . So they just do a little grep for {disfmarker}\nphd a: Do {disfmarker} uh , d d Do not {disfmarker} do not {disfmarker} we are not setting a good example .\nphd f: Um . Well , a relation other than negation , maybe ,\nphd a: This is not a {disfmarker}\nphd f: um . So .\nphd a: Anyway .\nphd f: I don't know .\nphd a: But the good thing is this does {disfmarker}\ngrad e: Well , I I don't know . I mean , you could {disfmarker} you could do a paper on {pause} what 's wrong with the Aurora task by comparing it to {pause} other ways of doing it .\nphd f: How well does an Aurora system do on {disfmarker} on {disfmarker} you know , on digits collected in a {disfmarker} in this environment ?\nphd h: \ngrad e: Different way . Yeah .\nphd f: Yeah .\nprofessor b: Maybe .\nphd f: Maybe .\ngrad e: Pretty hokey .\nprofessor b: I think it 's a littl little far - fetched . Nah , I mean , the thing is Aurora 's pretty closed community .\ngrad e: Yep .\nprofessor b: I mean , you know , the people who were involved in the {disfmarker} {vocalsound} the only people who are allowed to test on that are people who {disfmarker} who made it above a certain threshold in the first round ,\nphd f: Mm - hmm .\ngrad e: It 's very specific .\nprofessor b: uh {vocalsound} w in ninety - nine and it 's {disfmarker} it 's sort of a {disfmarker} it 's {disfmarker} not like a {disfmarker}\nphd f: Well , that 's maybe why they don't f know that they have a crummy system . I mean , a crummy back - end . No , I mean {disfmarker} I mean , seriously , if you {disfmarker} if you have a very {disfmarker} No , I 'm sorry .\nphd a: Uh , {comment} \" beep \" {vocalsound} \" bee \"\ngrad e: I mean , th\nphd f: No . I didn't mean anybody {disfmarker} any particular system . I meant this H T K back - end .\nprofessor b: Oh , you don't like HTK ?\nphd f: If they {disfmarker}\nphd h: Yeah .\nphd f: I don't h I don't have any stock in HTK or Entropic or anything .\nprofessor b: No . I mean , this {disfmarker} it it 's the HTK {pause} that is trained on a very limited amount of data .\ngrad e: It 's d it 's very specific .\nphd f: Right .\nprofessor b: Yeah .\nphd f: But so , if you {disfmarker} But maybe you should , you know , consider more {disfmarker} using more data , or {disfmarker} I mean {disfmarker}\nprofessor b: Oh , yeah . I {disfmarker} I really think that that 's true . And they i i\nphd f: If yo if you sort of hermetically stay within one task and don't look left and right , then you 're gonna {disfmarker}\ngrad e: But they {disfmarker} they had {disfmarker}\nprofessor b: i But {disfmarker}\ngrad e: They had something very specific in mind when they designed it . Right ?\nprofessor b: Well , u i\nphd f: Right .\ngrad e: And so {disfmarker} so you can {disfmarker} you can argue about maybe that wasn't the right thing to do , but , you know , they {disfmarker} they {disfmarker} they had something specific .\nprofessor b: But , one of the reasons I have Chuck 's messing around with {disfmarker} with the back - end that you 're not supposed to touch {disfmarker} I mean , for the evaluations , yes , we 'll run a version that hasn't been touched .\nphd f: Mm - hmm . Mm - hmm .\nprofessor b: But , uh , one of the reasons I have him messing around with that , because I think it 's sort of an open question that we don't know the answer to . People always say very glibly {vocalsound} that i if you s show improvement on a bad system , that doesn't mean anything , cuz it may not be {disfmarker} {vocalsound} show {disfmarker} uh , because , you know , it doesn't tell you anything about the good system .\nphd f: Mm - hmm .\nprofessor b: And I {disfmarker} I 've always sort of felt that that depends . You know , that if some peopl If you 're actually are getting at something that has some {pause} conceptual substance to it , it will port .\nphd f: Mm - hmm .\nprofessor b: And in fact , most methods that people now use were originally tried with something that was not their absolute {pause} best system at some level . But of course , sometimes it doesn't , uh , port . So I think that 's {disfmarker} that 's an interesting question . If we 're getting {pause} three percent error on , uh , u uh , English , uh , nati native speakers , {vocalsound} um , using the Aurora system , and we do some improvements and bring it from three to two , {vocalsound} do those same improvements bring , uh , th you know , the SRI system from one point three to {disfmarker} you know , to {vocalsound} point eight ?\nphd f: Hmm . Mm - hmm .\ngrad e: Zero .\nprofessor b: Well . You know , so that 's {disfmarker} that 's something we can test .\nphd f: Mmm . Right .\nprofessor b: So . Anyway .\nphd f: OK .\nprofessor b: I think we 've {disfmarker} {vocalsound} we 've covered that one up extremely well .\npostdoc c: Mm - hmm .\nphd f: Whew !\nprofessor b: OK . So , um {disfmarker} Yeah . So tha so we 'll {disfmarker} you know , maybe you guys 'll have {disfmarker} have one . Uh , you {disfmarker} you and , uh {disfmarker} and Dan have {disfmarker} have a paper that {disfmarker} that 's going in .\nphd d: Yeah .\nprofessor b: You know , that 's {disfmarker} that 's pretty solid , on the segmentation {pause} stuff .\nphd d: Yeah . Yeah . I will send you the {disfmarker} the final version ,"}, {"chapter": 4, "start_ms": 5646000, "topic": "Future work", "transcript_text": "professor b: Yeah . And the Aurora folks here will {disfmarker} will definitely get something in on Aurora ,\nphd d: which is not {disfmarker}\nphd f: Actually this {disfmarker} this , um {disfmarker} So , there 's another paper .\nprofessor b: so .\nphd f: It 's a Eurospeech paper but not related to meetings . But it 's on digits . So , um , uh , a colleague at SRI developed a improved version of MMIE training .\nprofessor b: Uh - huh .\nphd f: And he tested it mostly on digits because it 's sort of a {disfmarker} you know , it doesn't take weeks to train it .\nprofessor b: Right .\nphd f: Um . And got some very impressive results , um , with , you know , discriminative , uh , Gaussian training . Um , you know , like , um , error rates {pause} go from {disfmarker} I don't know , in very noisy environment , like from , uh , uh {disfmarker} I for now I {disfmarker} OK , now I have the order of magnit I 'm not sure about the order of magnitude . Was it like from ten percent to {vocalsound} eight percent or from e e you know , point {disfmarker} you know , from one percent to point eight percent ?\nprofessor b: H i it got {disfmarker} it got better .\nphd f: I mean , it 's a {disfmarker}\nprofessor b: Yeah , yeah .\nphd d: Yeah .\nphd f: It got better . That 's the important thing .\ngrad e: Hey , that 's the same percent relative ,\nphd f: Yeah . But it 's {disfmarker}\ngrad e: so {disfmarker}\nphd f: Yeah . Right .\nprofessor b: Yeah .\nphd f: It 's , uh , something in {disfmarker}\nprofessor b: Yeah .\ngrad e: Twenty percent relative gain .\nphd f: Right .\nprofessor b: Yeah .\nphd f: Yeah .\nprofessor b: Yeah . Um , {vocalsound} let 's see . I think the only thing we had left was {disfmarker} unless somebody else {disfmarker} Well , there 's a couple things . Uh , one is {pause} anything that , um , {vocalsound} anybody has to say about Saturday ? Anything we should do in prep for Saturday ? Um {disfmarker} I guess everybody knows about {disfmarker} I mean , u um , Mari was asking {disfmarker} was trying to come up with something like an agenda and we 're sort of fitting around people 's times a bit . But , um , {vocalsound} clearly when we actually get here we 'll {pause} move things around this , as we need to , but {disfmarker} so you can't absolutely count on it .\nphd d: OK .\nprofessor b: But {disfmarker} but , uh {disfmarker}\nphd d: Yeah .\nphd a: Are we meeting in here probably or {disfmarker} ? OK .\nprofessor b: Yeah . That was my thought .\nphd a: Yeah .\nprofessor b: I think this is {disfmarker}\nphd f: Are we recording it ?\nphd a: We won't have enough microphones ,\nprofessor b: \nphd a: but {disfmarker}\nprofessor b: u No . I {disfmarker} I hadn't in intended to .\nphd a: There 's no way .\nprofessor b: We won we wanna {disfmarker} I mean , they 're {disfmarker} there 's gonna be , uh , Jeff , Katrin , Mari and two students .\nphd f: OK .\nprofessor b: So there 's five {pause} from there .\ngrad e: And Brian .\nprofessor b: And Brian 's coming ,\nphd f: But you know th\nprofessor b: so that 's six .\ngrad e: And plus all of us .\nphd f: Mm - hmm .\nprofessor b: Uh {disfmarker}\nphd f: Can use the Oprah mike .\nphd a: Depends how fast you can {pause} throw it .\ngrad e: It seems like too many {disfmarker} too much coming and going .\nphd a: It 's just {disfmarker} Yeah .\nphd f: Mm - hmm .\nphd a: We don't even have enough channel {disfmarker}\nprofessor b: Well {disfmarker}\nphd f: Because it would be a different kind of meeting ,\nphd d: Yeah .\nphd f: that 's what I 'm {disfmarker}\nprofessor b: Well {disfmarker}\nphd f: But {disfmarker}\nphd h: Yeah .\nprofessor b: I hadn't {pause} really thought of it ,\nphd f: Maybe just {disfmarker} maybe not the whole day\nprofessor b: but {disfmarker}\nphd f: but just , you know , maybe some {disfmarker} I mean ,\nprofessor b: Maybe part of it .\nphd f: part of it ?\nprofessor b: Maybe part of it .\ngrad e: Make everyone read digits .\nprofessor b: At the same time .\nphd a: At the same time .\ngrad e: At the same time .\nphd f: Please .\nphd h: \nprofessor b: Yeah .\nphd a: We c\nprofessor b: I don't know .\nphd a: That 's their initiation into our\nprofessor b: Any\nphd a: w\ngrad e: Into our {disfmarker} our {disfmarker} our cult .\nphd a: Yeah , our {disfmarker} Yeah , our {disfmarker}\nphd f: Maybe the sections that are not right afte you know , after lunch when everybody 's still munching and {disfmarker}\nphd a: So can you send out a schedule once you know it , jus ?\nprofessor b: OK . Well {disfmarker}\nphd a: Is {disfmarker} is there a r ?\nprofessor b: OK . Yeah . I guess I sent it around a little bit .\nphd a: There 's a res Is it changed now , or {disfmarker} ?\nprofessor b: But {disfmarker} I hadn't heard back from Mari after I {disfmarker} I u u uh , brought up the point abou about Andreas 's schedule . So , {vocalsound} um , maybe when I get back there 'll be {pause} some {disfmarker} some mail from her .\nphd a: OK .\nprofessor b: So , I 'll make a {disfmarker}\npostdoc c: I 'm looking forward to seeing your representation . That 'd be , uh {disfmarker}\nphd a: And w we should get {pause} the two meetings from y\npostdoc c: I 'd like to see that . Yeah .\nphd a: I mean , I know about the first meeting , um , but the other one that you did , the NSA one , which we {pause} hadn't done cuz we weren't running recognition on it , because the non - native speaker {disfmarker}\npostdoc c: Mm - hmm .\nphd a: there were five non - native speakers .\npostdoc c: Mm - hmm . I see . Mm - hmm .\nphd a: But , it would be useful for the {disfmarker} to see what we get {pause} with that one . So .\npostdoc c: Great . OK . It 's , uh , two thousand eleven twenty - one one thousand .\nphd a: Yeah , three . Right . So {disfmarker}\npostdoc c: Great . I sent email when I finished the {disfmarker} that one .\nphd a: N S A three , I think .\npostdoc c: That was sort of son Yeah , that 's right . That 's right . That 's much simpler .\nphd a: I don't know what they said but I know the number .\nprofessor b: Th - that part 's definitely gonna confuse somebody who looks at these later .\nphd f: Right .\nprofessor b: I mean , this is {disfmarker} we we 're recording secret NSA meetings ?\nphd f: Um . Not the {disfmarker}\nprofessor b: I mean , it 's {disfmarker}\nphd f: Yeah .\npostdoc c: Yeah . Not that NSA .\nphd f: Uh . The {disfmarker} th the {disfmarker}\nphd a: They are hard to understand .\nprofessor b: It 's network services and applications .\nphd f: Wait .\nphd a: They 're very , uh , out there .\nphd f: The {disfmarker}\nphd a: I have no idea what they 're talking about .\nprofessor b: Yeah .\nphd f: The , um {disfmarker} th the other good thing about the alignments is that , um , it 's not always the machine 's fault if it doesn't work . So , you can actually find , um ,\nphd a: It 's the person 's fault .\nphd f: problem {disfmarker} uh , proble\nphd a: It 's Morgan 's fault .\nphd f: You can find {disfmarker}\nprofessor b: It 's always Morgan 's fault .\nphd f: You can find , uh , problems with {disfmarker} with the transcripts , um , you know ,\ngrad e: Oh .\nphd a: Yeah .\nphd f: and go back and fix them .\nphd a: Tha - There are some cases like where the {disfmarker} the wrong speaker {disfmarker} uh , these ca Not a lot , but where the {disfmarker} the wrong person {disfmarker} the {disfmarker} the speech is addre attached to the wrong speaker\nphd f: But {disfmarker}\nphd a: and you can tell that when you run it . Or at least you can get {pause} clues to it .\npostdoc c: Interesting .\nphd a: So these are from the early transcriptions that people did on the mixed signals , like what you have .\npostdoc c: I guess it does w Mm - hmm . It also raises the possibility of , um , using that kind of representation {disfmarker} I mean , I don't know , this 'd be something we 'd wanna check , {comment} but maybe using that representation for data entry and then displaying it on the channelized , uh , representation , cuz it {disfmarker} I think that the {disfmarker} I mean , my {disfmarker} my preference in terms of , like , looking at the data is to see it {pause} in this kind of musical score format .\nphd a: Mm - hmm .\npostdoc c: And also , s you know , Sue 's preference as well .\nphd a: Yeah , if you can get it to {disfmarker}\npostdoc c: And {disfmarker} and {disfmarker} but , I mean , this {disfmarker} if this is a better interface for making these kinds of , uh , you know , lo clos local changes , then that 'd be fine , too . I don't {disfmarker} I have no idea . I think this is something that would need to be checked . Yeah .\nprofessor b: OK . Th - the other thing I had actually was , I {disfmarker} I didn't realize this till today , but , uh , this is , uh , Jose 's last day .\ngrad e: Yeah .\nphd h: Is my last {disfmarker} my last day .\nphd a: Oh !\npostdoc c: Oh .\nphd f: Oh !\ngrad e: You 're not gonna be here tomorrow ?\nphd h: My {disfmarker} {vocalsound} my last meeting {pause} about meetings .\ngrad e: Oh , that 's right . Tomorrow {disfmarker}\nphd h: Yeah .\nphd d: The last meeting meeting ?\nphd h: Because , eh , I leave , eh , the next Sunday .\ngrad e: It 's off .\nphd a: Oh .\nphd f: Mm - hmm .\nphd h: I will come back to home {disfmarker} to Spain .\nprofessor b: Yeah .\nphd a: Oh .\nprofessor b: I d so I {disfmarker} I jus\nphd f: Mm - hmm .\nphd h: And I {disfmarker} I would like to {disfmarker} to {disfmarker} to say thank you very much , eh , to all people {pause} in the group and at ICSI ,\nphd f: Mm - hmm .\ngrad e: Yeah . It was good having you .\nphd f: Mmm .\nphd a: Yeah .\nphd h: because I {disfmarker} I enjoyed @ @ very much ,\nphd f: Mmm .\nphd h: uh . And I 'm sorry by the result of overlapping , because , eh , {vocalsound} I haven't good results , eh , yet but , eh , {vocalsound} I {disfmarker} {vocalsound} I pretend {comment} to {disfmarker} to continuing out to Spain , eh , during the {disfmarker} the following months ,\nprofessor b: Uh - huh .\nphd h: eh , because I have , eh , another ideas but , eh , I haven't enough time to {disfmarker} to {disfmarker} {vocalsound} with six months it 's not enough to {disfmarker} {vocalsound} to {disfmarker} to research ,\ngrad e: Yep .\nprofessor b: Yeah .\nphd h: eh , and e i I mean , if , eh , the topic is , eh , so difficult , uh , in my opinion , there isn't {disfmarker}\nprofessor b: Yeah . Maybe somebody else will come along and will be , uh , interested in working on it and could start off from where you are also , you know . They 'd make use of {disfmarker} of what you 've done .\nphd h: Yeah .\nprofessor b: Yeah .\nphd h: Yeah . But , eh , I {disfmarker} I will try to recommend , eh , at , eh , {vocalsound} the Spanish government but , eh , the following @ @ scholarship , eh , eh , {vocalsound} eh , will be here {pause} more time , because eh , i in my opinion is {disfmarker} is better , {vocalsound} eh , for us {pause} to {disfmarker} to spend more time here and to work more time i i in a topic .\nprofessor b: Yeah , it 's a very short time .\nphd h: No ? But , uh {disfmarker}\nprofessor b: Yeah . Yeah .\ngrad e: Yeah , six months is hard .\nphd h: Yeah . It is .\ngrad e: I think a year is a lot better .\nphd h: Yeah .\nprofessor b: Yeah .\nphd h: It 's difficult . You {disfmarker} e you have , eh {disfmarker} you are lucky , and you {disfmarker} you find a solution {comment} in {disfmarker} in {disfmarker} in some few tim uh , months , eh ? OK . But , eh , I think it 's not , eh , common . But , eh , anyway , thank you . Thank you very much . Eh , I {disfmarker} I bring the chocolate , eh , to {disfmarker} {vocalsound} {vocalsound} to tear , uh , with {disfmarker} with you ,\nphd a: Oh .\npostdoc c: Ah .\nphd f: Mmm .\npostdoc c: Nice .\nphd h: uh . I {disfmarker} I hope if you need , eh , something , eh , from us in the future , I {disfmarker} I will be at Spain , {vocalsound} to you help , uh .\nprofessor b: Well .\ngrad e: Great .\npostdoc c: Great .\nphd a: Right .\nprofessor b: Thank you , Jose .\npostdoc c: Thank you .\nphd h: And , thank you very much .\nphd f: Have a good trip .\nprofessor b: Yeah .\npostdoc c: Yeah .\nphd f: Keep in touch .\nphd h: Thank you .\nprofessor b: Yeah . OK . I guess , uh , unless somebody has something else , we 'll read {disfmarker} read our digits\ngrad e: Digits ?\nprofessor b: and we 'll get our {disfmarker}\nphd d: Uh .\nprofessor b: get our last bit of , uh , Jose 's {disfmarker} Jose {disfmarker} Jose 's digit {disfmarker}\nphd d: Oops .\ngrad e: Are we gonna do them simultaneously or {disfmarker} ?\nphd h: You {disfmarker} eh {disfmarker}\nprofessor b: Uh , I 'm sorry ?\nphd h: Ye - ye you prefer , eh , to eat , eh , chocolate , eh , at the coffee break , eh , at the {disfmarker} ? {vocalsound} Or you prefer now , before after {disfmarker} ?\npostdoc c: Well , we have a time {disfmarker}\nphd f: No , we prefer to keep it for ourselves .\nphd d: During {disfmarker}\npostdoc c: Well , we have a s a time {disfmarker} time constraint .\nphd f: Yeah , yeah .\nphd d: during digits .\nprofessor b: So keep it away from that end of the table .\npostdoc c: Yeah .\nphd f: Yeah .\nphd h: Yeah .\nphd a: Why is it that I can read your mind ?\npostdoc c: Yeah .\ngrad e: Well , we 've gotta wait until after di after we take the mikes off .\nphd d: No , no .\ngrad e: So are we gonna do digits simultaneously\nphd a: You {disfmarker} This is our reward if we {pause} do our digi\nprofessor b: Well ? Yeah .\npostdoc c: OK .\nphd d: Yeah .\ngrad e: or what ?\nphd d: Simultaneous digit chocolate task .\nphd h: I {disfmarker} I think , eh , it 's enough , eh , for more peopl for more people {pause} after .\nprofessor b: We 're gonna {disfmarker} we 're gonna do digits at the same {disfmarker}\nphd a: Oh .\nphd f: Mmm !\npostdoc c: That 's nice .\nphd h: But , eh {disfmarker}\nphd f: Mm - hmm .\nphd a: Oh , thanks , Jose .\nprofessor b: Um .\npostdoc c: Wow .\nphd h: To Andreas , the idea is {disfmarker} is good . {vocalsound} s To eat here .\nprofessor b: Well {disfmarker}\nphd f: Mmm .\npostdoc c: Wow . Very nice .\nphd f: Oh .\nphd a: Oh , wow .\nprofessor b: Tha - that 's {disfmarker} that looks great .\nphd f: Oh , yeah . Th - it doesn't {disfmarker} it won't leave this room .\nprofessor b: Alright , so in the interest of getting to the {disfmarker}\nphd a: We could do digits while other people eat .\nphd d: Yeah .\nphd a: So it 's background crunching .\nphd d: Yeah .\nphd h: Yeah .\nphd f: Mmm .\nphd a: We don't have background chewing .\npostdoc c: Nice .\nphd h: Is , eh , a {disfmarker} another acoustic event .\nphd d: Background crunch . Yeah .\nphd a: No , we don't have any data with background eating .\nphd f: Mmm .\nphd d: Yeah .\nphd a: I 'm serious . You\nprofessor b: She 's {disfmarker} she 's serious .\nphd a: I am serious .\ngrad e: It 's just the rest of the digits {disfmarker} the rest of the digits are very clean ,\nprofessor b: She is serious .\nphd f: Mmm .\nphd a: Well {disfmarker} ?\nphd h: Are you {disfmarker} ? Oh , they 're clean .\nphd d: Yeah !\ngrad e: um , without a lot of background noise ,\nphd a: And it {disfmarker} You have to write down , like , while y what you 're {disfmarker} what ch chocolate you 're eating\ngrad e: so I 'm just not sure {disfmarker}\nphd a: cuz they might make different sounds , like n nuts {disfmarker} chocolate with nuts , chocolate without nuts .\npostdoc c: Oh .\nprofessor b: Um {disfmarker}\nphd d: Crunchy frogs .\nphd f: Chocolate adaptation .\nprofessor b: Actually {disfmarker} {vocalsound} actually kind of careful cuz I have a strong allergy to nuts , so I have to sort of figure out one without th\nphd a: That w Oh , yeah , they {disfmarker} they might .\nprofessor b: It 's hard to {disfmarker} hard to say .\nphd a: Maybe those ? They 're so {disfmarker} I don't know .\nprofessor b: I don't know . Um {disfmarker}\nphd a: This is {disfmarker} You know , this is a different kind of speech ,\nprofessor b: Well {disfmarker}\nphd h: Take {disfmarker} take several .\nphd a: looking at chocolates , deciding {disfmarker}\nphd f: Mmm .\nphd a: you know , it 's another style .\nprofessor b: Yeah . I may {disfmarker} I may hold off .\nphd f: Mmm .\nprofessor b: But if I was {disfmarker} eh , but maybe I 'll get some later . Thanks .\nphd f: Mmm .\nprofessor b: Well {disfmarker} well , why don't we {disfmarker} ? He {disfmarker} he 's worried about a ticket . Why don't we do a simultaneous one ?\nphd a: OK .\nprofessor b: Simultaneous one ?\npostdoc c: OK .\ngrad e: OK .\nphd f: Mmm .\nphd a: And you laughed at me , too , f the first time I said that .\nprofessor b: OK .\ngrad e: Remember to read the transcript number , please .\nphd f: Right .\nphd h: OK .\nprofessor b: I have to what ?\nphd d: Oops .\nphd h: Yeah .\nphd a: You laughed at me , too , the first time I sa said {disfmarker}\nprofessor b: I did ,\nphd a: You really shouldn't , uh , te\nprofessor b: and now I love it so much .\ngrad e: OK , everyone ready ?\nphd a: You have to sort of , um {disfmarker} Jose , if you haven't done this , you have to plug your ears while you 're t talking\nprofessor b: W wait {disfmarker} wait a minute {disfmarker} wait a minute . W we want {disfmarker} we want {disfmarker}\nphd a: so that you don't get confused , I guess .\nprofessor b: we want it synchronized .\nphd a: Yeah . Oh , you 've done this one before ?\npostdoc c: Hey , you 've done this before . Haven't you ?\nphd h: Yeah .\nphd d: That 's {disfmarker}\nphd a: Together ?\npostdoc c: You 've read {pause} digits together with us , haven't you {disfmarker} I mean , at the same time ?\nphd a: I 'm not {disfmarker} we {disfmarker} we {disfmarker} Oh , and you haven't done this either .\nprofessor b: OK .\npostdoc c: Oh , you haven't !\nphd h: No .\npostdoc c: Oh , OK .\nphd d: Oh , yeah .\nphd a: I the first time is {pause} traumatic ,\nprofessor b: We\nphd a: but {disfmarker}\nprofessor b: Y {vocalsound} Yeah , bu\npostdoc c: Oh , and the groupings are important ,\nphd h: Mmm .\npostdoc c: so yo you 're supposed to pause between the groupings .\nphd h: The grouping .\nprofessor b: Yeah .\nphd h: Yeah .\nprofessor b: OK . So , uh {disfmarker}\nphd f: You mean that the {disfmarker} the grouping is supposed to be synchronized ?\nprofessor b: No , no .\npostdoc c: No .\ngrad e: Yeah , sure .\nphd f: No ?\nphd a: That 'd be good .\nprofessor b: Synchronized digits .\npostdoc c: No .\nphd f: No ?\nphd a: We - we 'll give everybody the same sheet\nphd f: It 's like a {disfmarker} like a Greek {disfmarker} like a Greek choir ?\nphd a: but they say different {disfmarker}\nphd f: You know ?\nprofessor b: Yes .\ngrad e: Hey , what a good idea .\nphd f: Like {disfmarker}\ngrad e: We could do the same sheet for everyone .\nphd f: Yeah .\ngrad e: Have them all read them at once .\nphd a: Well , different digits\nphd d: Eh {disfmarker}\nphd a: but same groupings .\ngrad e: Or {disfmarker} or just same digits .\nphd a: So they would all be {disfmarker} Yeah .\npostdoc c: Yeah . That 'd be good .\ngrad e: See if anyone notices .\nprofessor b: There 's so many possibilities .\npostdoc c: And then {disfmarker} then we can sing them next time .\nprofessor b: Uh . OK , why don't we go ? Uh , one two three {disfmarker} Go !\npostdoc c: OK . Mmm !\nprofessor b: And Andreas has the last word .\ngrad e: Did you read it twice or what ?\nphd a: He 's try No , he 's trying to get good recognition performance .\npostdoc c: He had the h\nphd h: Yeah .\npostdoc c: He had the {disfmarker} the long form .\nphd h: Yeah .\ngrad e: And we 're off .\nphd f: No ."}]}