{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AWS SageMaker Inference Provider for Inspect AI - Quick Start\n",
        "\n",
        "## What is Inspect AI?\n",
        "\n",
        "[Inspect AI](https://inspect.ai-safety-institute.org.uk/) is an open-source framework for large language model evaluations created by the UK AI Safety Institute. It provides a standardized way to run benchmarks and custom evaluations across different model providers, with built-in support for:\n",
        "\n",
        "- Multiple evaluation tasks (multiple choice, generation, code execution, agent-based)\n",
        "- Diverse scoring methods (exact match, model-graded, custom metrics)\n",
        "- Parallel execution and retry logic for robust evaluations\n",
        "- Rich logging and visualization of results\n",
        "\n",
        "## How This Notebook Benefits You\n",
        "\n",
        "This notebook enables you to:\n",
        "- **Evaluate models on SageMaker endpoints** using the same benchmarks used by the AI research community\n",
        "- **Run evaluations at scale** with parallel inference across multiple endpoint instances\n",
        "- **Compare model performance** using standardized benchmarks (MMLU, TruthfulQA, HumanEval, etc.)\n",
        "- **Integrate seamlessly** with your existing SageMaker infrastructure\n",
        "\n",
        "## Limitations\n",
        "\n",
        "**Supported Models:**\n",
        "- Currently tested with **Amazon Nova models** (Nova Micro, Nova Lite, Nova Pro)\n",
        "- Works with any model deployed via **vLLM** or **OpenAI-compatible inference servers** on SageMaker\n",
        "- Requires endpoints that support the OpenAI Chat Completions API format\n",
        "\n",
        "**Known Constraints:**\n",
        "- Tool calling support depends on the underlying model's capabilities\n",
        "- Some advanced features (like structured outputs) may require specific model versions\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- **AWS account** with SageMaker endpoint deployed (running vLLM or OpenAI-compatible inference)\n",
        "  - Learn more: [What is Amazon SageMaker?](https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html)\n",
        "  - Endpoint creation guide: [Deploy Models for Inference](https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html)\n",
        "- **AWS credentials** configured (via AWS CLI, environment variables, or IAM role)\n",
        "  - AWS CLI setup: [Configuring the AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html)\n",
        "  - IAM roles: [IAM Roles for SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html)\n",
        "- **Python 3.12 or higher**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Configure AWS Credentials\n",
        "\n",
        "Ensure your AWS credentials are properly configured. The SageMaker provider uses boto3 to authenticate with AWS.\n",
        "\n",
        "### Configuration Options\n",
        "\n",
        "Choose one of the following methods:\n",
        "\n",
        "1. **AWS CLI Configuration** (Recommended)\n",
        "   - Run `aws configure` and provide your credentials\n",
        "   - Guide: [Configuring the AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html)\n",
        "\n",
        "2. **Environment Variables**\n",
        "   ```bash\n",
        "   export AWS_ACCESS_KEY_ID=your_access_key\n",
        "   export AWS_SECRET_ACCESS_KEY=your_secret_key\n",
        "   export AWS_DEFAULT_REGION=us-west-2\n",
        "   ```\n",
        "   - Guide: [Environment Variables](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-envvars.html)\n",
        "\n",
        "3. **IAM Role** (For EC2/SageMaker Notebooks)\n",
        "   - Automatically uses the instance's IAM role\n",
        "   - Guide: [IAM Roles for Amazon EC2](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html)\n",
        "\n",
        "### Required IAM Permissions\n",
        "\n",
        "Your IAM user/role needs these permissions:\n",
        "```json\n",
        "{\n",
        "  \"Version\": \"2012-10-17\",\n",
        "  \"Statement\": [\n",
        "    {\n",
        "      \"Effect\": \"Allow\",\n",
        "      \"Action\": [\n",
        "        \"sagemaker:CreateModel\",\n",
        "        \"sagemaker:CreateEndpointConfig\",\n",
        "        \"sagemaker:CreateEndpoint\",\n",
        "        \"sagemaker:DescribeEndpoint\",\n",
        "        \"sagemaker:InvokeEndpoint\",\n",
        "        \"sagemaker:DeleteEndpoint\",\n",
        "        \"sagemaker:UpdateEndpoint\"\n",
        "      ],\n",
        "      \"Resource\": \"arn:aws:sagemaker:*:*:*\"\n",
        "    },\n",
        "    {\n",
        "      \"Effect\": \"Allow\",\n",
        "      \"Action\": [\n",
        "        \"iam:PassRole\"\n",
        "      ],\n",
        "      \"Resource\": \"arn:aws:iam::*:role/*SageMaker*\",\n",
        "      \"Condition\": {\n",
        "        \"StringEquals\": {\n",
        "          \"iam:PassedToService\": \"sagemaker.amazonaws.com\"\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\n",
        "### Verify Configuration\n",
        "\n",
        "Run the cell below to verify your credentials are working:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Create/retrieve the IAM user credentials from AWS console\n",
        "2. Configure the IAM user credentials for cli use\n",
        "    1. `aws configure`\n",
        "    2. input AWS AccessKey ID, AWS Secret Access Key , and default region\n",
        "    3. `aws_session_token` is not needed and should be removed in `~/.aws/credentials` if it exists\n",
        "\n",
        "\n",
        "3. You can also create and assume the IAM role that has permissions to access the Nova RFT Starter Kit bucket:\n",
        "    1. `aws configure`\n",
        "    2. `aws sts assume-role --role-arn \"arn:aws:iam::YourAccountNumber:role/YourRoleName\" --role-session-name mysession`\n",
        "    3. `aws_session_token` is needed in `~/.aws/credentials`\n",
        "    4. Note: Replace YourRoleName with the appropriate IAM role name for your organization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Start your python3.12 virtual environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Create and activate your venv\n",
        "python3.12 -m venv .venv\n",
        "source .venv/bin/activate  # (Linux/Mac)\n",
        "\n",
        "# 2. Install ipykernel inside the venv\n",
        "pip install ipykernel\n",
        "\n",
        "# 3. Register the venv as a Jupyter kernel\n",
        "python -m ipykernel install --user --name=myproject --display-name=\"Python (myproject)\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initialize the AWS SDK and verify your credentials:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip install uv\n",
        "! uv pip install boto3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import boto3\n",
        "\n",
        "# Verify AWS credentials\n",
        "try:\n",
        "    sts = boto3.client('sts')\n",
        "    identity = sts.get_caller_identity()\n",
        "    print(f\"✓ AWS credentials configured\")\n",
        "    print(f\"  Account: {identity['Account']}\")\n",
        "    print(f\"  User/Role: {identity['Arn']}\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ AWS credentials not configured: {e}\")\n",
        "    print(\"\\nPlease configure AWS credentials using one of:\")\n",
        "    print(\"  - AWS CLI: aws configure\")\n",
        "    print(\"  - Environment variables: AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY\")\n",
        "    print(\"  - IAM role (if running on AWS)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Configure and Deploy Your SageMaker Endpoint\n",
        "\n",
        "Set up your SageMaker endpoint. For more details, see [Deploy a SageMaker endpoint](https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html).\n",
        "\n",
        "Update the configuration below with your values, then run the cells to deploy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# CONFIGURATION - Update these values for your deployment\n",
        "# =============================================================================\n",
        "\n",
        "import boto3\n",
        "import time\n",
        "\n",
        "# AWS Region\n",
        "REGION = \"us-east-1\"\n",
        "\n",
        "# Your SageMaker execution role ARN\n",
        "AWS_ACCOUNT_ID = \"YOUR_ACCOUNT_ID\"  # Replace with your AWS account ID\n",
        "SAGEMAKER_EXECUTION_ROLE_ARN = f\"arn:aws:iam::{AWS_ACCOUNT_ID}:role/SageMakerExecutionRole\"\n",
        "\n",
        "# Deployment name (used to generate resource names)\n",
        "DEPLOYMENT_NAME = \"DEPLOYMENT_NAME\"\n",
        "\n",
        "# Model artifacts location in S3 (must end with /)\n",
        "MODEL_S3_LOCATION = \"s3://your-bucket/path/to/model/\"\n",
        "\n",
        "# Container image URI (provided by AWS)\n",
        "ECR_ACCOUNT_MAP = {\n",
        "    \"us-east-1\": \"708977205387\",\n",
        "    \"us-west-2\": \"176779409107\"\n",
        "}\n",
        "\n",
        "IMAGE = f\"{ECR_ACCOUNT_MAP[REGION]}.dkr.ecr.{REGION}.amazonaws.com/nova-inference-repo:SM-Inference-latest\"\n",
        "\n",
        "# Instance type - choose based on your model:\n",
        "#   Nova Micro: ml.g5.2xlarge, ml.g5.12xlarge, ml.p4d.24xlarge, ml.p5.48xlarge\n",
        "#   Nova Lite:  ml.g5.12xlarge, ml.g5.48xlarge, ml.p4d.24xlarge, ml.p5.48xlarge\n",
        "#   Nova Lite 2: ml.p4d.24xlarge, ml.p5.48xlarge\n",
        "#   Nova Pro:  ml.p4d.24xlarge, ml.p5.48xlarge\n",
        "\n",
        "INSTANCE_TYPE = \"ml.g5.12xlarge\"\n",
        "\n",
        "# Model parameters\n",
        "CONTEXT_LENGTH = \"12000\"   # Maximum context length\n",
        "MAX_CONCURRENCY = \"16\"     # Maximum concurrent requests\n",
        "\n",
        "# =============================================================================\n",
        "# Generate resource names (no changes needed below)\n",
        "# =============================================================================\n",
        "MODEL_NAME = f\"{DEPLOYMENT_NAME}-model\"\n",
        "ENDPOINT_CONFIG_NAME = f\"{DEPLOYMENT_NAME}-config\"\n",
        "ENDPOINT_NAME = f\"{DEPLOYMENT_NAME}\"\n",
        "\n",
        "print(f\"Configuration:\")\n",
        "print(f\"  Region: {REGION}\")\n",
        "print(f\"  Instance Type: {INSTANCE_TYPE}\")\n",
        "print(f\"  Endpoint Name: {ENDPOINT_NAME}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# DEPLOY - Run this cell to create the endpoint\n",
        "# =============================================================================\n",
        "\n",
        "sagemaker = boto3.client('sagemaker', region_name=REGION)\n",
        "\n",
        "# 1. Create Model\n",
        "print(\"Creating model...\")\n",
        "sagemaker.create_model(\n",
        "    ModelName=MODEL_NAME,\n",
        "    PrimaryContainer={\n",
        "        'Image': IMAGE,\n",
        "        'ModelDataSource': {\n",
        "            'S3DataSource': {\n",
        "                'S3Uri': MODEL_S3_LOCATION,\n",
        "                'S3DataType': 'S3Prefix',\n",
        "                'CompressionType': 'None'\n",
        "            }\n",
        "        },\n",
        "        'Environment': {\n",
        "            'CONTEXT_LENGTH': CONTEXT_LENGTH,\n",
        "            'MAX_CONCURRENCY': MAX_CONCURRENCY,\n",
        "        }\n",
        "    },\n",
        "    ExecutionRoleArn=SAGEMAKER_EXECUTION_ROLE_ARN,\n",
        "    EnableNetworkIsolation=True\n",
        ")\n",
        "print(f\"✓ Model created: {MODEL_NAME}\")\n",
        "\n",
        "# 2. Create Endpoint Configuration\n",
        "print(\"Creating endpoint configuration...\")\n",
        "sagemaker.create_endpoint_config(\n",
        "    EndpointConfigName=ENDPOINT_CONFIG_NAME,\n",
        "    ProductionVariants=[{\n",
        "        'VariantName': 'primary',\n",
        "        'ModelName': MODEL_NAME,\n",
        "        'InitialInstanceCount': 1,\n",
        "        'InstanceType': INSTANCE_TYPE,\n",
        "    }]\n",
        ")\n",
        "print(f\"✓ Endpoint config created: {ENDPOINT_CONFIG_NAME}\")\n",
        "\n",
        "# 3. Create Endpoint\n",
        "print(\"Creating endpoint (this takes 15-30 minutes)...\")\n",
        "sagemaker.create_endpoint(\n",
        "    EndpointName=ENDPOINT_NAME,\n",
        "    EndpointConfigName=ENDPOINT_CONFIG_NAME\n",
        ")\n",
        "\n",
        "# 4. Wait for endpoint to be ready\n",
        "while True:\n",
        "    response = sagemaker.describe_endpoint(EndpointName=ENDPOINT_NAME)\n",
        "    status = response['EndpointStatus']\n",
        "    \n",
        "    if status == 'InService':\n",
        "        print(f\"\\n✅ Endpoint ready: {ENDPOINT_NAME}\")\n",
        "        break\n",
        "    elif status == 'Failed':\n",
        "        print(f\"\\n❌ Endpoint failed: {response.get('FailureReason', 'Unknown')}\")\n",
        "        break\n",
        "    else:\n",
        "        print(f\"⏳ Status: {status}...\")\n",
        "        time.sleep(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once the endpoint shows `InService`, proceed to the next step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Install Eval Dependencies\n",
        "\n",
        "Install Inspect AI, the evaluation benchmarks, and required AWS dependencies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a new python3.12 virtual environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If you need a fresh virtual environment, create and register it as a Jupyter kernel (see Step 1).\n",
        "# The cells below use %pip to install directly into the current kernel's environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install core packages into the current kernel environment\n",
        "%pip install inspect-ai inspect-evals\n",
        "\n",
        "# Install AWS dependencies for SageMaker provider\n",
        "%pip install aioboto3 boto3 botocore openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Install the SageMaker Provider\n",
        "\n",
        "### What is the SageMaker Provider?\n",
        "\n",
        "The SageMaker provider is a custom Inspect AI model provider that enables communication between Inspect AI and your SageMaker endpoints. It acts as an adapter that:\n",
        "\n",
        "1. **Translates Inspect AI requests** into the format expected by your SageMaker endpoint (OpenAI Chat Completions API)\n",
        "2. **Handles AWS authentication** using boto3/aioboto3 to securely invoke your endpoints\n",
        "3. **Manages retries and error handling** for robust evaluation runs\n",
        "4. **Supports advanced features** like tool calling, structured outputs, and parallel inference\n",
        "\n",
        "### How It Works\n",
        "\n",
        "The provider code (`sagemaker.py`) implements the `ModelAPI` interface required by Inspect AI. When you run an evaluation:\n",
        "- Inspect AI calls the provider with evaluation samples\n",
        "- The provider formats requests and invokes your SageMaker endpoint via `boto3.client('sagemaker-runtime').invoke_endpoint()`\n",
        "- Responses are parsed and returned to Inspect AI for scoring\n",
        "\n",
        "### Installation Steps\n",
        "\n",
        "This cell will:\n",
        "1. Locate your Inspect AI installation\n",
        "2. Create the `sagemaker.py` provider file\n",
        "3. Register it in `providers.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Find the Inspect AI installation directory\n",
        "try:\n",
        "    import inspect_ai\n",
        "    \n",
        "    # Use multiple methods to find the installation path\n",
        "    if hasattr(inspect_ai, '__file__') and inspect_ai.__file__:\n",
        "        inspect_ai_path = os.path.dirname(inspect_ai.__file__)\n",
        "    else:\n",
        "        # Fallback: use the module's __path__ attribute\n",
        "        inspect_ai_path = str(Path(inspect_ai.__path__[0]))\n",
        "    \n",
        "    providers_dir = os.path.join(inspect_ai_path, 'model', '_providers')\n",
        "    \n",
        "    # Verify the directory exists or can be created\n",
        "    os.makedirs(providers_dir, exist_ok=True)\n",
        "    \n",
        "    print(f\"✓ Found Inspect AI at: {inspect_ai_path}\")\n",
        "    print(f\"  Providers directory: {providers_dir}\")\n",
        "    \n",
        "except ImportError:\n",
        "    print(\"✗ Inspect AI not found. Please install it first: pip install inspect-ai\")\n",
        "    sys.exit(1)\n",
        "except Exception as e:\n",
        "    print(f\"✗ Error locating Inspect AI: {e}\")\n",
        "    print(\"  Trying alternative method...\")\n",
        "    import inspect_ai\n",
        "    import importlib.util\n",
        "    spec = importlib.util.find_spec('inspect_ai')\n",
        "    if spec and spec.origin:\n",
        "        inspect_ai_path = os.path.dirname(spec.origin)\n",
        "        providers_dir = os.path.join(inspect_ai_path, 'model', '_providers')\n",
        "        os.makedirs(providers_dir, exist_ok=True)\n",
        "        print(f\"✓ Found Inspect AI at: {inspect_ai_path}\")\n",
        "        print(f\"  Providers directory: {providers_dir}\")\n",
        "    else:\n",
        "        raise RuntimeError(\"Could not locate Inspect AI installation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Install the sagemaker Inference provider into Inspect AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sagemaker_provider_code = '''\"\"\"AWS SageMaker model provider for Inspect AI.\"\"\"\n",
        "\n",
        "import json\n",
        "from logging import getLogger\n",
        "from typing import Any\n",
        "from botocore.config import Config\n",
        "from botocore.exceptions import ClientError\n",
        "from openai.types.chat import ChatCompletion\n",
        "from typing_extensions import override\n",
        "from inspect_ai._util.constants import DEFAULT_MAX_TOKENS\n",
        "from inspect_ai._util.content import Content\n",
        "from inspect_ai._util.error import pip_dependency_error\n",
        "from inspect_ai._util.images import file_as_data_uri\n",
        "from inspect_ai._util.url import is_http_url\n",
        "from inspect_ai._util.version import verify_required_version\n",
        "from inspect_ai.model._openai import chat_choices_from_openai, model_output_from_openai\n",
        "from inspect_ai.tool import ToolChoice, ToolInfo\n",
        "from inspect_ai.tool._tool_choice import ToolFunction\n",
        "from inspect_ai.model._chat_message import ChatMessage, ChatMessageAssistant, ChatMessageSystem, ChatMessageTool, ChatMessageUser\n",
        "from inspect_ai.model._generate_config import GenerateConfig\n",
        "from inspect_ai.model._model import ModelAPI\n",
        "from inspect_ai.model._model_call import ModelCall\n",
        "from inspect_ai.model._model_output import ModelOutput\n",
        "\n",
        "logger = getLogger(__name__)\n",
        "\n",
        "SAGEMAKER_DEFAULTS = {\"region_name\": \"us-east-1\", \"read_timeout\": 600, \"connect_timeout\": 60}\n",
        "SAGEMAKER_RETRY_ERROR_CODES = {0, 500, 503, 504}\n",
        "\n",
        "class SagemakerAPI(ModelAPI):\n",
        "    def __init__(self, model_name: str, config: GenerateConfig = GenerateConfig(), **model_args: Any):\n",
        "        super().__init__(model_name=model_name, base_url=None, api_key=None, api_key_vars=[], config=config)\n",
        "        self.endpoint_name = model_name\n",
        "        self.model_args = SAGEMAKER_DEFAULTS | model_args\n",
        "        try:\n",
        "            import aioboto3\n",
        "            verify_required_version(\"Sagemaker API\", \"aioboto3\", \"13.0.0\")\n",
        "            self.session = aioboto3.Session()\n",
        "        except ImportError:\n",
        "            raise pip_dependency_error(\"Sagemaker API\", [\"aioboto3\"])\n",
        "        self.request_content_type = \"application/json\"\n",
        "        self.request_accept_type = \"application/json\"\n",
        "\n",
        "    @override\n",
        "    def connection_key(self) -> str:\n",
        "        return self.endpoint_name\n",
        "\n",
        "    @override\n",
        "    def max_tokens(self) -> int | None:\n",
        "        return DEFAULT_MAX_TOKENS\n",
        "\n",
        "    @override\n",
        "    def should_retry(self, ex: Exception) -> bool:\n",
        "        if isinstance(ex, ClientError):\n",
        "            error_code = ex.response.get(\"Error\", {}).get(\"Code\", \"\")\n",
        "            status_code = ex.response.get(\"OriginalStatusCode\", -1)\n",
        "            return error_code == \"ModelError\" and status_code in SAGEMAKER_RETRY_ERROR_CODES\n",
        "        return False\n",
        "\n",
        "    @override\n",
        "    def collapse_user_messages(self) -> bool:\n",
        "        return True\n",
        "\n",
        "    @override\n",
        "    def collapse_assistant_messages(self) -> bool:\n",
        "        return True\n",
        "\n",
        "    async def generate(self, input: list[ChatMessage], tools: list[ToolInfo], tool_choice: ToolChoice, config: GenerateConfig):\n",
        "        config = self._prepare_vllm_config(input, config)\n",
        "        tools_config = self._prepare_tools_config(tools)\n",
        "        processed_messages = await self._prepare_messages(input)\n",
        "        request_body = self._build_request_body(config, processed_messages, tools_config, tool_choice)\n",
        "        async with self._create_client() as client:\n",
        "            body_bytes = await self._invoke_endpoint(client, request_body)\n",
        "        output = json.loads(body_bytes.decode(\"utf-8\"))\n",
        "        model_output = model_output_from_response(output, tools)\n",
        "        model_call = ModelCall.create(request=request_body, response=output, time=0)\n",
        "        return model_output, model_call\n",
        "\n",
        "    def _prepare_vllm_config(self, input: list[ChatMessage], config: GenerateConfig) -> GenerateConfig:\n",
        "        if not (input and isinstance(input[-1], ChatMessageAssistant)):\n",
        "            return config\n",
        "        config = config.model_copy()\n",
        "        if config.extra_body is None:\n",
        "            config.extra_body = {}\n",
        "        config.extra_body.setdefault(\"add_generation_prompt\", False)\n",
        "        config.extra_body.setdefault(\"continue_final_message\", True)\n",
        "        return config\n",
        "\n",
        "    def _prepare_tools_config(self, tools: list[ToolInfo]):\n",
        "        if not tools:\n",
        "            return None\n",
        "        return [{\"type\": \"function\", \"function\": {\"name\": t.name, \"description\": t.description, \"parameters\": t.parameters.model_dump(exclude_none=True)}} for t in tools]\n",
        "\n",
        "    async def _prepare_messages(self, input: list[ChatMessage]):\n",
        "        collapsed = collapse_consecutive_messages(input, self.collapse_user_messages(), self.collapse_assistant_messages())\n",
        "        return [await process_chat_message(message) for message in collapsed]\n",
        "\n",
        "    def _create_client(self):\n",
        "        return self.session.client(service_name=\"sagemaker-runtime\", region_name=self.model_args[\"region_name\"], endpoint_url=self.model_args.get(\"endpoint_url\"), config=Config(read_timeout=self.model_args[\"read_timeout\"], connect_timeout=self.model_args[\"connect_timeout\"], retries={\"total_max_attempts\": 1, \"mode\": \"standard\"}))\n",
        "\n",
        "    def _build_request_body(self, config: GenerateConfig, messages, tools_config, tool_choice: ToolChoice):\n",
        "        request_body = {\"messages\": messages, \"max_tokens\": config.max_tokens, \"temperature\": config.temperature, \"top_p\": config.top_p}\n",
        "        self._add_optional_params(request_body, config)\n",
        "        if tools_config:\n",
        "            request_body[\"tools\"] = tools_config\n",
        "            self._add_tool_choice(request_body, tool_choice)\n",
        "            if config.parallel_tool_calls is not None:\n",
        "                request_body[\"parallel_tool_calls\"] = config.parallel_tool_calls\n",
        "        if config.response_schema is not None:\n",
        "            request_body[\"response_format\"] = {\"type\": \"json_schema\", \"json_schema\": {\"name\": config.response_schema.name, \"schema\": config.response_schema.json_schema.model_dump(exclude_none=True), \"description\": config.response_schema.description, \"strict\": config.response_schema.strict}}\n",
        "        if config.extra_body:\n",
        "            request_body.update(config.extra_body)\n",
        "        return request_body\n",
        "\n",
        "    def _add_optional_params(self, request_body, config: GenerateConfig):\n",
        "        for k, v in [(\"top_k\", config.top_k), (\"stop\", config.stop_seqs), (\"frequency_penalty\", config.frequency_penalty), (\"presence_penalty\", config.presence_penalty), (\"logit_bias\", config.logit_bias), (\"seed\", config.seed), (\"n\", config.num_choices), (\"logprobs\", config.logprobs), (\"top_logprobs\", config.top_logprobs), (\"best_of\", config.best_of), (\"reasoning_effort\", config.reasoning_effort)]:\n",
        "            if v is not None:\n",
        "                request_body[k] = v\n",
        "\n",
        "    def _add_tool_choice(self, request_body, tool_choice: ToolChoice):\n",
        "        if isinstance(tool_choice, ToolFunction):\n",
        "            request_body[\"tool_choice\"] = {\"type\": \"function\", \"function\": {\"name\": tool_choice.name}}\n",
        "        elif tool_choice == \"any\":\n",
        "            request_body[\"tool_choice\"] = \"required\"\n",
        "        elif tool_choice == \"none\":\n",
        "            request_body[\"tool_choice\"] = \"none\"\n",
        "        else:\n",
        "            request_body[\"tool_choice\"] = \"auto\"\n",
        "\n",
        "    async def _invoke_endpoint(self, client, request_body):\n",
        "        response = await client.invoke_endpoint(EndpointName=self.endpoint_name, ContentType=self.request_content_type, Accept=self.request_accept_type, Body=json.dumps(request_body))\n",
        "        return await response[\"Body\"].read()\n",
        "\n",
        "async def process_chat_message(message: ChatMessage):\n",
        "    if isinstance(message, (ChatMessageSystem, ChatMessageUser)):\n",
        "        content = await process_content(message.content)\n",
        "        return {\"role\": message.role, \"content\": content}\n",
        "    elif isinstance(message, ChatMessageAssistant):\n",
        "        content = await process_content(message.content)\n",
        "        result = {\"role\": message.role, \"content\": content}\n",
        "        if message.tool_calls:\n",
        "            result[\"tool_calls\"] = [{\"id\": tc.id, \"type\": \"function\", \"function\": {\"name\": tc.function, \"arguments\": json.dumps(tc.arguments)}} for tc in message.tool_calls]\n",
        "        return result\n",
        "    elif isinstance(message, ChatMessageTool):\n",
        "        content = f\"Error: {message.error.message}\" if message.error else message.text\n",
        "        return {\"role\": \"tool\", \"tool_call_id\": str(message.tool_call_id), \"content\": content}\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected message type: {type(message)}\")\n",
        "\n",
        "async def process_content(content):\n",
        "    if isinstance(content, str):\n",
        "        return content\n",
        "    processed = []\n",
        "    for item in content:\n",
        "        if item.type == \"text\":\n",
        "            processed.append({\"type\": \"text\", \"text\": item.text})\n",
        "        elif item.type == \"image\":\n",
        "            image_url = item.image if is_http_url(item.image) else await file_as_data_uri(item.image)\n",
        "            processed.append({\"type\": \"image_url\", \"image_url\": {\"url\": image_url, \"detail\": getattr(item, \"detail\", \"auto\")}})\n",
        "        elif item.type == \"reasoning\":\n",
        "            processed.append({\"type\": \"reasoning\", \"reasoning\": item.reasoning})\n",
        "    if len(processed) == 1 and processed[0][\"type\"] == \"text\":\n",
        "        return processed[0][\"text\"]\n",
        "    return processed\n",
        "\n",
        "def collapse_consecutive_messages(messages, collapse_user, collapse_assistant):\n",
        "    if not messages:\n",
        "        return []\n",
        "    collapsed = [messages[0]]\n",
        "    for msg in messages[1:]:\n",
        "        last = collapsed[-1]\n",
        "        if msg.role == last.role and ((isinstance(msg, ChatMessageUser) and collapse_user) or (isinstance(msg, ChatMessageAssistant) and collapse_assistant)):\n",
        "            last.content.extend(msg.content)\n",
        "        else:\n",
        "            collapsed.append(msg)\n",
        "    return collapsed\n",
        "\n",
        "def model_output_from_response(output, tools: list[ToolInfo]):\n",
        "    completion = ChatCompletion.model_validate(output)\n",
        "    choices = chat_choices_from_openai(completion, tools)\n",
        "    return model_output_from_openai(completion, choices)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and register the sagemaker provider code\n",
        "\n",
        "if sagemaker_provider_code:\n",
        "    # Write the provider file\n",
        "    sagemaker_file = os.path.join(providers_dir, 'sagemaker.py')\n",
        "    with open(sagemaker_file, 'w') as f:\n",
        "        f.write(sagemaker_provider_code)\n",
        "    \n",
        "    print(f\"✓ SageMaker provider installed at: {sagemaker_file}\")\n",
        "    \n",
        "    # Also register the provider in providers.py\n",
        "    providers_file = os.path.join(providers_dir, 'providers.py')\n",
        "    \n",
        "    # Read the current providers.py\n",
        "    with open(providers_file, 'r') as f:\n",
        "        providers_content = f.read()\n",
        "    \n",
        "    # Check if sagemaker is already registered\n",
        "    if '@modelapi(name=\"sagemaker\")' not in providers_content:\n",
        "        # Find the bedrock registration and add sagemaker after it\n",
        "        bedrock_end = providers_content.find('@modelapi(name=\"mockllm\")')\n",
        "        if bedrock_end > 0:\n",
        "            sagemaker_registration = '''\\n\\n@modelapi(name=\"sagemaker\")\n",
        "def sagemaker() -> type[ModelAPI]:\n",
        "    from .sagemaker import SagemakerAPI\n",
        "\n",
        "    return SagemakerAPI\n",
        "\n",
        "\n",
        "'''\n",
        "            # Insert the registration\n",
        "            new_content = providers_content[:bedrock_end] + sagemaker_registration + providers_content[bedrock_end:]\n",
        "            \n",
        "            # Write back\n",
        "            with open(providers_file, 'w') as f:\n",
        "                f.write(new_content)\n",
        "            \n",
        "            print(f\"✓ SageMaker provider registered in: {providers_file}\")\n",
        "        else:\n",
        "            print(\"⚠ Could not find insertion point in providers.py\")\n",
        "    else:\n",
        "        print(\"✓ SageMaker provider already registered\")\n",
        "    \n",
        "    print(\"\\n✓ Installation complete! You can now use model='sagemaker/your-endpoint-name'\")\n",
        "else:\n",
        "    print(\"✗ No provider code available. Please load or paste the code first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Find Evaluation Benchmarks\n",
        "\n",
        "Let's download evaluation benchmarks from the inspect AI benchmarks environments to test the SageMaker provider."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! git clone https://github.com/UKGovernmentBEIS/inspect_evals.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Onboard a new public benchmark via coding agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here is an example to guide you how to leverage an AI Coding agent (kiro, amazon q, claude code) to onboard a new public benchmarks that works with Inspect ai. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### In your coding environment, set a system prompt like this:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You are an expert at onboarding public benchmarks to Inspect AI (https://github.com/UKGovernmentBEIS/inspect_ai).\n",
        "\n",
        "#### Your Workflow\n",
        "\n",
        "1. **Research Phase**\n",
        "   - Study the benchmark's paper, dataset format, and evaluation metrics\n",
        "   - Review similar implementations in `inspect_evals/` (e.g., mmlu, truthfulqa, humaneval)\n",
        "   - Identify task type: multiple_choice, generation, code_execution, or agent\n",
        "\n",
        "2. **Implementation Phase**\n",
        "   - Create task file following Inspect AI patterns\n",
        "   - Implement `record_to_sample()` to convert dataset records to `Sample(input, target, choices, metadata)`\n",
        "   - Use appropriate solver: `multiple_choice()`, `generate()`, or `chain_of_thought()`\n",
        "   - Use appropriate scorer: `choice()`, `match()`, `model_graded_qa()`, or custom\n",
        "\n",
        "3. **Validation Phase**\n",
        "   - Test with: `inspect eval your_task.py --model openai/gpt-4o-mini --limit 5`\n",
        "   - Verify scores align with published baselines\n",
        "   - View results with: `inspect view`\n",
        "\n",
        "## Key References\n",
        "- Docs: https://inspect.ai-safety-institute.org.uk/\n",
        "- Examples: https://github.com/UKGovernmentBEIS/inspect_evals\n",
        "\n",
        "Always match the benchmark's official evaluation methodology.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Construct your user prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Onboard TruthfulQA (https://github.com/sylinrl/TruthfulQA) to the benchmark folder.\n",
        "Dataset: huggingface.co/datasets/truthful_qa\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As a final step, monitor your agent behavior and waiting for it to complete. Once the code implementation has been complete, validate in your benchmark folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Run Evaluation with SageMaker\n",
        "\n",
        "Now let's run the evaluation using your SageMaker endpoint.\n",
        "\n",
        "### Key Parameters Explained\n",
        "\n",
        "When running evaluations with Inspect AI, these parameters control performance and reliability:\n",
        "\n",
        "**`--max-connections`** (default: 10)\n",
        "- Controls how many parallel requests are sent to your endpoint\n",
        "- **Recommended values:**\n",
        "  - Single instance endpoint: 10-50\n",
        "  - Multi-instance endpoint: 100-500 (scale with instance count)\n",
        "  - Example: 10 instances × 25 connections = 250 max connections\n",
        "- **Too high:** May overwhelm endpoint, causing throttling or timeouts\n",
        "- **Too low:** Underutilizes endpoint capacity, slower evaluations\n",
        "\n",
        "**`--max-retries`** (default: 3)\n",
        "- Number of retry attempts for failed requests\n",
        "- **Recommended values:**\n",
        "  - Stable endpoints: 10-20\n",
        "  - Large-scale evaluations: 50-100\n",
        "- Handles transient errors (503 Service Unavailable, 504 Gateway Timeout)\n",
        "- Uses exponential backoff between retries\n",
        "\n",
        "**Model-specific parameters** (via `-M` flag)\n",
        "- `region_name`: AWS region where your endpoint is deployed\n",
        "- `endpoint_url`: Custom endpoint URL (optional, for testing/staging environments)\n",
        "- `read_timeout`: Request timeout in seconds (default: 600)\n",
        "- `connect_timeout`: Connection timeout in seconds (default: 60)\n",
        "\n",
        "### Example Configuration\n",
        "\n",
        "For a 10-instance endpoint running Nova Micro:\n",
        "```bash\n",
        "--max-connections 256  # ~25 connections per instance\n",
        "--max-retries 100      # Handle transient errors in long runs\n",
        "--limit 100            # Limit the first 100 samples\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run evaluation - update the endpoint name and region to match your deployment\n",
        "!cd inspect_evals/src/inspect_evals/ && inspect eval mmlu_pro/mmlu_pro.py \\\n",
        "--model sagemaker/my-nova-endpoint \\\n",
        "-M region_name=us-east-1 \\\n",
        "--max-connections 16 \\\n",
        "--max-retries 50 \\\n",
        "--display plain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### View Inference output and evaluation results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! inspect view"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "1. Explore more benchmarks from `inspect_evals`\n",
        "2. Create custom evaluations for your use case\n",
        "3. Run evaluations at scale with different model configurations\n",
        "4. View detailed logs and results in the Inspect AI viewer\n",
        "\n",
        "For more information:\n",
        "- [Inspect AI Documentation](https://inspect.ai-safety-institute.org.uk/)\n",
        "- [Inspect Evals Repository](https://github.com/UKGovernmentBEIS/inspect_evals)\n",
        "- [AWS SageMaker Documentation](https://docs.aws.amazon.com/sagemaker/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Appendix A: Update Endpoint\n",
        "\n",
        "Use this section to update an existing endpoint with a new model or configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# UPDATE ENDPOINT - Modify configuration and run to update\n",
        "# =============================================================================\n",
        "\n",
        "import boto3\n",
        "import time\n",
        "\n",
        "REGION = \"us-east-1\"\n",
        "AWS_ACCOUNT_ID = \"123456789012\"\n",
        "SAGEMAKER_EXECUTION_ROLE_ARN = f\"arn:aws:iam::{AWS_ACCOUNT_ID}:role/SageMakerExecutionRole\"\n",
        "\n",
        "# Existing endpoint to update\n",
        "EXISTING_ENDPOINT_NAME = \"my-nova-endpoint\"\n",
        "\n",
        "# New configuration\n",
        "NEW_MODEL_NAME = \"my-nova-endpoint-model-v2\"\n",
        "NEW_ENDPOINT_CONFIG_NAME = \"my-nova-endpoint-config-v2\"\n",
        "MODEL_S3_LOCATION = \"s3://your-bucket/path/to/new/model/\"\n",
        "INSTANCE_TYPE = \"ml.g5.12xlarge\"\n",
        "\n",
        "# Container image\n",
        "ECR_ACCOUNTS = {\"us-east-1\": \"708977205387\", \"us-west-2\": \"176779409107\"}\n",
        "IMAGE = f\"{ECR_ACCOUNTS.get(REGION, '708977205387')}.dkr.ecr.{REGION}.amazonaws.com/nova-inference-repo:v1.0.0\"\n",
        "\n",
        "sagemaker = boto3.client('sagemaker', region_name=REGION)\n",
        "\n",
        "# 1. Create new model\n",
        "print(f\"Creating new model: {NEW_MODEL_NAME}\")\n",
        "sagemaker.create_model(\n",
        "    ModelName=NEW_MODEL_NAME,\n",
        "    PrimaryContainer={\n",
        "        'Image': IMAGE,\n",
        "        'ModelDataSource': {\n",
        "            'S3DataSource': {\n",
        "                'S3Uri': MODEL_S3_LOCATION,\n",
        "                'S3DataType': 'S3Prefix',\n",
        "                'CompressionType': 'None'\n",
        "            }\n",
        "        },\n",
        "        'Environment': {\n",
        "            'CONTEXT_LENGTH': '12000',\n",
        "            'MAX_CONCURRENCY': '16',\n",
        "        }\n",
        "    },\n",
        "    ExecutionRoleArn=SAGEMAKER_EXECUTION_ROLE_ARN\n",
        ")\n",
        "print(f\"✓ Model created\")\n",
        "\n",
        "# 2. Create new endpoint configuration\n",
        "print(f\"Creating new endpoint config: {NEW_ENDPOINT_CONFIG_NAME}\")\n",
        "sagemaker.create_endpoint_config(\n",
        "    EndpointConfigName=NEW_ENDPOINT_CONFIG_NAME,\n",
        "    ProductionVariants=[{\n",
        "        'VariantName': 'primary',\n",
        "        'ModelName': NEW_MODEL_NAME,\n",
        "        'InitialInstanceCount': 1,\n",
        "        'InstanceType': INSTANCE_TYPE\n",
        "    }]\n",
        ")\n",
        "print(f\"✓ Endpoint config created\")\n",
        "\n",
        "# 3. Update endpoint\n",
        "print(f\"Updating endpoint: {EXISTING_ENDPOINT_NAME}\")\n",
        "sagemaker.update_endpoint(\n",
        "    EndpointName=EXISTING_ENDPOINT_NAME,\n",
        "    EndpointConfigName=NEW_ENDPOINT_CONFIG_NAME\n",
        ")\n",
        "\n",
        "# 4. Wait for update\n",
        "print(\"Waiting for update to complete...\")\n",
        "while True:\n",
        "    response = sagemaker.describe_endpoint(EndpointName=EXISTING_ENDPOINT_NAME)\n",
        "    status = response['EndpointStatus']\n",
        "    if status == 'InService':\n",
        "        print(f\"✅ Endpoint updated successfully!\")\n",
        "        break\n",
        "    elif status == 'Failed':\n",
        "        print(f\"❌ Update failed: {response.get('FailureReason', 'Unknown')}\")\n",
        "        break\n",
        "    print(f\"⏳ Status: {status}...\")\n",
        "    time.sleep(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Appendix B: Delete Endpoint\n",
        "\n",
        "Use this section to clean up resources when you're done with the endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# DELETE ENDPOINT - Run to delete endpoint and free up resources\n",
        "# =============================================================================\n",
        "\n",
        "import boto3\n",
        "\n",
        "REGION = \"us-east-1\"\n",
        "ENDPOINT_NAME = \"my-nova-endpoint\"  # Endpoint to delete\n",
        "\n",
        "sagemaker = boto3.client('sagemaker', region_name=REGION)\n",
        "\n",
        "# Delete the endpoint\n",
        "print(f\"Deleting endpoint: {ENDPOINT_NAME}\")\n",
        "sagemaker.delete_endpoint(EndpointName=ENDPOINT_NAME)\n",
        "print(f\"✅ Endpoint deletion initiated\")\n",
        "print(\"Note: The endpoint will be fully deleted in a few minutes.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
