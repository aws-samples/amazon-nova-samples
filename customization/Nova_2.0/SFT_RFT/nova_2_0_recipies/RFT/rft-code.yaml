# Note:
# This recipe can run on p5.48xlarge and p5en.48xlarge instance types.

## Run config
run:
  name: "my-rft-run" # Unique run name (appears in logs/artifacts).
  model_type: amazon.nova-2-lite-v1:0:256k
  # model_name_or_path: nova-lite-2/prod
  model_name_or_path:
    # S3 URI
    # data_s3_path: s3://<bucket>/<data file>      # Training dataset in JSONL;

  replicas: 4
  reward_lambda_arn:

    ## SMTJ GRPO Training specific configs
training_config:
  max_epochs: 2 # Full passes over dataset (higher = more steps/quality, longer).
  max_length: 8192 # Context window (tokens) for inputs+prompt;
  global_batch_size: 16 # Total samples per optimizer step across all replicas (16/32/64/128/256).
  reasoning_effort: high # Enables reasoning mode High / Low / or null for non-reasoning

  trainer:
    entropy_coeff: 0.0 # A bonus added to the policy loss that rewards higher-output entropy.
    kl_loss_coef: 0.001 # Weight on the KL penalty between the actor (trainable policy) and a frozen reference model

    optim:
      optimizer: adam
      lr: 1e-6 # Peak/base Learning Rate for trainable params
      min_lr: 0.0 # Minimum learning rate, default to 0.0

  model:
    peft:
      peft_scheme: "lora" # Parameter-efficient fine-tuning strategy.
      lora_tuning:
        loraplus_lr_ratio: 16.0 # LoRA+ only: scales B-matrix LR vs A (stability/learning speed).
        alpha: 128 # LoRA scaling (effectively adjusts injected rank contribution).
        adapter_dropout: 0.0 # Dropout on adapter pathway

  rollout:
    # How responses are generated for GRPO/advantage calc.
    advantage_strategy:
      number_generation: 2 # N samples per prompt to estimate advantages (variance vs cost).
    generator:
      max_new_tokens: 6000 # Cap on tokens generated per sample
      set_random_seed: true # Seed generation for reproducibility across runs.
      temperature: 1 # Softmax temperature;
      top_k: 1 # Sample only from top-K logits
    rewards:
      api_endpoint:
        lambda_arn: ${oc.select:run.reward_lambda_arn}
        lambda_concurrency_limit: 12 # Max concurrent Lambda invocations (throughput vs. throttling).
