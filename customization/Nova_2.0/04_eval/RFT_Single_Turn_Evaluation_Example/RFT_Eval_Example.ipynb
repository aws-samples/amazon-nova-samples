{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85106545-da2c-4639-9fd4-55b6bf7d9cb5",
   "metadata": {},
   "source": [
    "# üöÄüî• Custom Nova Model Evaluation using Forge RFT in SageMaker Training Job - Lambda Single Turn üî•üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eb69ec-06cb-4103-9483-0668cfccdaf0",
   "metadata": {},
   "source": [
    "# RFT Evaluation with Custom Reward Functions\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook demonstrates how to evaluate Amazon Nova models using **Reinforcement Fine-Tuning (RFT) evaluation** with custom reward functions. In this specific example, we will be using an **AWS Lambda function** which will be hosting a custom-coded reward function to evaluate a model on its ability to solve **algebraic equations**.\n",
    "\n",
    "Please note - Lambda is one of two potential infrastructrue solutions that Nova RFT evaluation can support. The other workflow is \"Bring Your Own Orchestrator\" which uses the [Verifers](https://github.com/tang-ti/verifiers/tree/main) open source library to allow for custom environments and should be used for more complex use cases.\n",
    "\n",
    "**When to use Lambda-based RFT evaluation:**\n",
    "- Single-turn tasks with custom scoring logic\n",
    "- Reward computation completes within 15 minutes\n",
    "- You want AWS to handle the orchestration infrastructure\n",
    "\n",
    "**When to use BYOO (Bring Your Own Orchestrator) RFT evaluation:**\n",
    "- Multi-turn agent scenarios (e.g., coding agents that iteratively debug across multiple interactions)\n",
    "- Complex reward calculations that exceed 15-minute Lambda timeout\n",
    "- Custom orchestration logic for simulating realistic environments\n",
    "- Tasks requiring stateful interactions between model and environment\n",
    "- Full control over the rollout generation process and conversation flow\n",
    "\n",
    "**Use Case Example: Math Problem Solving**\n",
    "\n",
    "We'll evaluate a Nova model on solving algebraic equations. The Lambda function will:\n",
    "- Parse the model's JSON response to extract the answer\n",
    "- Compare it against the ground truth\n",
    "- Return a binary reward (1.0 for correct, 0.0 for incorrect)\n",
    "- Track additional metrics like format compliance\n",
    "\n",
    "**Recipe we will be using for this example**\n",
    "This is the recipe we will be using to start our example job. This recipe yaml file will be included within the notebook.\n",
    "```\n",
    "  name: nova-lite-math-eval\n",
    "  model_type: amazon.nova-2-lite-v1:0:256k\n",
    "  model_name_or_path: nova-lite-2/prod\n",
    "  replicas: 1\n",
    "  data_s3_path: \"\"  # Leave empty for SageMaker Training job\n",
    "  output_s3_path: \"\"  # Leave empty for SageMaker Training job\n",
    "\n",
    "evaluation:\n",
    "  task: rft_eval # Must specify gen_qa for RFT evaluation. Do not change for this example.\n",
    "  strategy: rft_eval # Must specify gen_qa for RFT evaluation. Do not change for this example.\n",
    "  metric: all\n",
    "\n",
    "inference:\n",
    "  max_new_tokens: 100\n",
    "  top_k: -1\n",
    "  top_p: 1.0\n",
    "  temperature: 0\n",
    "  top_logprobs: 0\n",
    "  reasoning_effort: null\n",
    "\n",
    "rl_env:\n",
    "  reward_lambda_arn: arn:aws:lambda:us-east-1:123456789123:function:SageMaker-RFT-Math-Evaluator\n",
    "```\n",
    "Some important configuration parameters to note:\n",
    "- **name**: The name of the evaluation run. This will be used when generating the output directory name.\n",
    "- **model_name_or_path**: For this example, we will be using the Nova 2 Lite model.\n",
    "- **reasoning_effort**: This can be set to either null, low, or high. This value will modify the amount of tokens the Nova 2 lite model will use during its reasoning.\n",
    "- **top_logprobs**: The amount of tokens that will have logprobs shown during the output. These values can be found in the output parquet file. This can be useful for analyzing the model behavior.\n",
    "- **max_new_tokens**: The amount of tokens that the model will generate before stopping. For this specific example, we can have a relatively low number because we expect the model to just print out the answers to simple math questions!\n",
    "- **reward_lambda_arn**: The arn of the AWS Lambda function you will create as a part of this example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5c99ad-ed85-4ffe-8aaf-280a627d90b0",
   "metadata": {},
   "source": [
    "## Setup and Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7368b5-5a90-435e-9ede-fb812b25ea1d",
   "metadata": {},
   "source": [
    "These dependencies will be used during the execution and analysis of the evaluation run. \n",
    "\n",
    "**IMPORTANT: Ensure that this specific version (2.254.1) of the Sagemaker CLI is used. Nova Forge does not currently support the latest SageMaker v3 CLI!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dcf4115-1cfd-4cab-adf5-aaafd04e5350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sagemaker==2.254.1\n",
      "  Using cached sagemaker-2.254.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting attrs<26,>=24 (from sagemaker==2.254.1)\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting boto3<2.0,>=1.39.5 (from sagemaker==2.254.1)\n",
      "  Downloading boto3-1.42.21-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: cloudpickle>=2.2.1 in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.254.1) (3.1.2)\n",
      "Requirement already satisfied: docker in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.254.1) (7.1.0)\n",
      "Requirement already satisfied: fastapi in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.254.1) (0.121.1)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.254.1) (0.2.0)\n",
      "Requirement already satisfied: graphene<4,>=3 in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.254.1) (3.4.3)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.254.1) (6.10.0)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.254.1) (4.23.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.26.4 in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.254.1) (1.26.4)\n",
      "Requirement already satisfied: omegaconf<3,>=2.2 in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.254.1) (2.3.0)\n",
      "Requirement already satisfied: packaging<25,>=23.0 in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.254.1) (24.2)\n",
      "Requirement already satisfied: pandas>=2.3.0 in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.254.1) (2.3.3)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.254.1) (0.3.4)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.254.1) (4.5.0)\n",
      "Requirement already satisfied: protobuf<6.32,>=3.12 in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.254.1) (5.28.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.254.1) (5.9.8)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.254.1) (6.0.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.254.1) (2.32.5)\n",
      "Requirement already satisfied: sagemaker-core<2.0.0,>=1.0.17 in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.254.1) (1.0.64)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.254.1) (0.7.7)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.254.1) (1.0.1)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.254.1) (3.2.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.254.1) (4.67.1)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.254.1) (1.26.20)\n",
      "Requirement already satisfied: uvicorn in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.254.1) (0.38.0)\n",
      "Collecting botocore<1.43.0,>=1.42.21 (from boto3<2.0,>=1.39.5->sagemaker==2.254.1)\n",
      "  Downloading botocore-1.42.21-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from boto3<2.0,>=1.39.5->sagemaker==2.254.1) (1.0.1)\n",
      "Collecting s3transfer<0.17.0,>=0.16.0 (from boto3<2.0,>=1.39.5->sagemaker==2.254.1)\n",
      "  Using cached s3transfer-0.16.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.12/site-packages (from botocore<1.43.0,>=1.42.21->boto3<2.0,>=1.39.5->sagemaker==2.254.1) (2.9.0.post0)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /opt/conda/lib/python3.12/site-packages (from graphene<4,>=3->sagemaker==2.254.1) (3.2.7)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /opt/conda/lib/python3.12/site-packages (from graphene<4,>=3->sagemaker==2.254.1) (3.2.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7.1 in /opt/conda/lib/python3.12/site-packages (from graphene<4,>=3->sagemaker==2.254.1) (4.15.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.12/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker==2.254.1) (3.23.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /opt/conda/lib/python3.12/site-packages (from omegaconf<3,>=2.2->sagemaker==2.254.1) (4.9.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.43.0,>=1.42.21->boto3<2.0,>=1.39.5->sagemaker==2.254.1) (1.17.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker==2.254.1) (2.12.4)\n",
      "Requirement already satisfied: rich<15.0.0,>=13.0.0 in /opt/conda/lib/python3.12/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker==2.254.1) (14.2.0)\n",
      "Requirement already satisfied: mock<5.0,>4.0 in /opt/conda/lib/python3.12/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker==2.254.1) (4.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.12/site-packages (from jsonschema->sagemaker==2.254.1) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.12/site-packages (from jsonschema->sagemaker==2.254.1) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from jsonschema->sagemaker==2.254.1) (0.28.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker==2.254.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker==2.254.1) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker==2.254.1) (0.4.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from rich<15.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker==2.254.1) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich<15.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker==2.254.1) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker==2.254.1) (0.1.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas>=2.3.0->sagemaker==2.254.1) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas>=2.3.0->sagemaker==2.254.1) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->sagemaker==2.254.1) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->sagemaker==2.254.1) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->sagemaker==2.254.1) (2025.10.5)\n",
      "Requirement already satisfied: starlette<0.50.0,>=0.40.0 in /opt/conda/lib/python3.12/site-packages (from fastapi->sagemaker==2.254.1) (0.49.2)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /opt/conda/lib/python3.12/site-packages (from fastapi->sagemaker==2.254.1) (0.0.4)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /opt/conda/lib/python3.12/site-packages (from starlette<0.50.0,>=0.40.0->fastapi->sagemaker==2.254.1) (4.11.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.12/site-packages (from anyio<5,>=3.6.2->starlette<0.50.0,>=0.40.0->fastapi->sagemaker==2.254.1) (1.3.1)\n",
      "Requirement already satisfied: ppft>=1.7.7 in /opt/conda/lib/python3.12/site-packages (from pathos->sagemaker==2.254.1) (1.7.7)\n",
      "Requirement already satisfied: dill>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from pathos->sagemaker==2.254.1) (0.4.0)\n",
      "Requirement already satisfied: pox>=0.3.6 in /opt/conda/lib/python3.12/site-packages (from pathos->sagemaker==2.254.1) (0.3.6)\n",
      "Requirement already satisfied: multiprocess>=0.70.18 in /opt/conda/lib/python3.12/site-packages (from pathos->sagemaker==2.254.1) (0.70.18)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.12/site-packages (from uvicorn->sagemaker==2.254.1) (8.3.0)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.12/site-packages (from uvicorn->sagemaker==2.254.1) (0.16.0)\n",
      "Using cached sagemaker-2.254.1-py3-none-any.whl (1.7 MB)\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading boto3-1.42.21-py3-none-any.whl (140 kB)\n",
      "Downloading botocore-1.42.21-py3-none-any.whl (14.6 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m155.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached s3transfer-0.16.0-py3-none-any.whl (86 kB)\n",
      "Installing collected packages: attrs, botocore, s3transfer, boto3, sagemaker\n",
      "\u001b[2K  Attempting uninstall: attrs\n",
      "\u001b[2K    Found existing installation: attrs 23.2.0\n",
      "\u001b[2K    Uninstalling attrs-23.2.0:\n",
      "\u001b[2K      Successfully uninstalled attrs-23.2.0\n",
      "\u001b[2K  Attempting uninstall: botocore\n",
      "\u001b[2K    Found existing installation: botocore 1.37.3\n",
      "\u001b[2K    Uninstalling botocore-1.37.3:\n",
      "\u001b[2K      Successfully uninstalled botocore-1.37.3‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1/5\u001b[0m [botocore]\n",
      "\u001b[2K  Attempting uninstall: s3transferm‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1/5\u001b[0m [botocore]\n",
      "\u001b[2K    Found existing installation: s3transfer 0.11.3‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1/5\u001b[0m [botocore]\n",
      "\u001b[2K    Uninstalling s3transfer-0.11.3:‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1/5\u001b[0m [botocore]\n",
      "\u001b[2K      Successfully uninstalled s3transfer-0.11.3‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1/5\u001b[0m [botocore]\n",
      "\u001b[2K  Attempting uninstall: boto30m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1/5\u001b[0m [botocore]\n",
      "\u001b[2K    Found existing installation: boto3 1.37.3‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1/5\u001b[0m [botocore]\n",
      "\u001b[2K    Uninstalling boto3-1.37.3:‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3/5\u001b[0m [boto3]\n",
      "\u001b[2K      Successfully uninstalled boto3-1.37.3[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3/5\u001b[0m [boto3]\n",
      "\u001b[2K  Attempting uninstall: sagemaker[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3/5\u001b[0m [boto3]\n",
      "\u001b[2K    Found existing installation: sagemaker 2.245.0‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3/5\u001b[0m [boto3]\n",
      "\u001b[2K    Uninstalling sagemaker-2.245.0:‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/5\u001b[0m [sagemaker]\n",
      "\u001b[2K      Successfully uninstalled sagemaker-2.245.00m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/5\u001b[0m [sagemaker]\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5/5\u001b[0m [sagemaker]/5\u001b[0m [sagemaker]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 1.4.0 requires nvidia-ml-py3<8.0,>=7.352.0, which is not installed.\n",
      "sagemaker-studio 1.1.1 requires pydynamodb>=0.7.4, which is not installed.\n",
      "aiobotocore 2.22.0 requires botocore<1.37.4,>=1.37.2, but you have botocore 1.42.21 which is incompatible.\n",
      "autogluon-multimodal 1.4.0 requires transformers[sentencepiece]<4.50,>=4.38.0, but you have transformers 4.57.1 which is incompatible.\n",
      "autogluon-timeseries 1.4.0 requires transformers[sentencepiece]<4.50,>=4.38.0, but you have transformers 4.57.1 which is incompatible.\n",
      "sagemaker-studio-analytics-extension 0.2.2 requires sparkmagic==0.22.0, but you have sparkmagic 0.21.0 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed attrs-25.4.0 boto3-1.42.21 botocore-1.42.21 s3transfer-0.16.0 sagemaker-2.254.1\n"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker==2.254.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ca50a7b-760f-43e2-8787-b2a74bd9f71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sagemaker version: 2.254.1\n",
      "Execution Role: arn:aws:iam::618100645563:role/service-role/AmazonSageMaker-ExecutionRole-20251113T000017\n",
      "üöÄ All dependencies successfully installed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sagemaker, boto3\n",
    "import json\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import glob\n",
    "import ast\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# Setup SageMaker session\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "print(f\"Sagemaker version: {sagemaker.__version__}\")\n",
    "print(f\"Execution Role: {role}\")\n",
    "print(\"üöÄ All dependencies successfully installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602635b4-d2ca-46bf-9e94-ac93f4dab6e2",
   "metadata": {},
   "source": [
    "## Step 1: Implementing Lambda Function\n",
    "\n",
    "This series of steps will cover the creation of the custom Lambda reward function including required permissions as well as go over requirements for function inputs and outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12da7c88-11c0-4b5d-a403-bdccbb3239b3",
   "metadata": {},
   "source": [
    "### Step 1a: Creating AWS Lambda function\n",
    "1. Go to AWS Lambda Console\n",
    "2. Click \"Create function\"\n",
    "3. Choose \"Author from scratch\"\n",
    "4. Configure:\n",
    "   - **Function name**: `SageMaker-RFT-Math-Evaluator` (Ensure that the function name is prefixed by \"SageMaker-\", this is a requirement!)\n",
    "   - **Runtime**: Python 3.12\n",
    "   - **Architecture**: x86_64\n",
    "5. Click \"Create function\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9544a2d3-3a75-4cf1-9348-d9a710f4f01f",
   "metadata": {},
   "source": [
    "### Step 1b: Add custom Lambda code\n",
    "\n",
    "\n",
    "1. In the Lambda console, scroll to \"Code source\"\n",
    "2. Replace the default code with the Lambda function code shown below\n",
    "3. Click \"Deploy\"\n",
    "\n",
    "Note: The code below is implemented following the structure recommended in the official [Nova Forge RFT reward function documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/nova-implementing-reward-functions.html#nova-reward-fields). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ade82f-0de5-492c-9760-e0cd81f3769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \"\"\"AWS Lambda handler for RFT Math Evaluation\"\"\"\n",
    "    print(f\"Received {len(event)} samples for evaluation\")\n",
    "    samples = event if isinstance(event, list) else [event]\n",
    "    results = []\n",
    "    \n",
    "    for sample in samples:\n",
    "        sample_id = sample.get(\"id\", \"unknown\")\n",
    "        print(f\"\\nProcessing sample: {sample_id}\")\n",
    "        \n",
    "        # Extract model response (last assistant message)\n",
    "        model_response = next(\n",
    "            (msg[\"content\"] for msg in reversed(sample[\"messages\"]) \n",
    "             if msg[\"role\"] == \"assistant\"), \n",
    "            \"\"\n",
    "        )\n",
    "        \n",
    "        print(f\"Raw model response: {model_response[:150]}...\")\n",
    "        \n",
    "        # Calculate score\n",
    "        score = lambda_grader(model_response, sample[\"reference_answer\"])\n",
    "        \n",
    "        print(f\"Score for {sample_id}: {score}\")\n",
    "        \n",
    "        # Build result\n",
    "        result = {\n",
    "            \"id\": sample_id,\n",
    "            \"aggregate_reward_score\": score,\n",
    "            \"metrics_list\": [\n",
    "                {\"name\": \"correctness\", \"value\": score, \"type\": \"Reward\"}\n",
    "            ]\n",
    "        }\n",
    "        results.append(result)\n",
    "    \n",
    "    print(f\"\\nReturning {len(results)} results\")\n",
    "    print(f\"Full response: {json.dumps(results, indent=2)}\")\n",
    "    return results\n",
    "\n",
    "def lambda_grader(model_response, reference_answer):\n",
    "    \"\"\"Calculates correctness score for math response\"\"\"\n",
    "    try:\n",
    "        # Remove any special tokens (pattern: <|...|>)\n",
    "        cleaned = re.sub(r'<\\|[^|]+\\|>', '', model_response)\n",
    "        \n",
    "        # Remove markdown code blocks\n",
    "        cleaned = re.sub(r'```\\w*\\s*|\\s*```', '', cleaned).strip()\n",
    "        \n",
    "        print(f\"Cleaned response: {cleaned}\")\n",
    "        \n",
    "        # Extract JSON object using regex (handles multi-line)\n",
    "        json_match = re.search(r'\\{[^}]*\\}', cleaned, re.DOTALL)\n",
    "        if json_match:\n",
    "            json_str = json_match.group(0)\n",
    "            print(f\"Extracted JSON: {json_str}\")\n",
    "            \n",
    "            parsed = json.loads(json_str)\n",
    "            answer = parsed.get(\"x\")\n",
    "            expected = reference_answer[\"x\"]\n",
    "            \n",
    "            print(f\"Parsed answer: {answer}, Expected: {expected}\")\n",
    "            \n",
    "            return 1.0 if answer == expected else 0.0\n",
    "        else:\n",
    "            print(\"No JSON object found in response\")\n",
    "            return 0.0\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing response: {e}\")\n",
    "        return 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4821f16f-e908-4a7e-a91b-5d9eb76072c1",
   "metadata": {},
   "source": [
    "### Step 1c: Example Lambda inputs & outputs\n",
    "\n",
    "#### Example Lambda input\n",
    "Here is an example input to the Lambda function. Inputs will always follow this same JSON structure:\n",
    "```\n",
    "[\n",
    "  {\n",
    "    \"id\": \"math_001\",\n",
    "    \"messages\": [\n",
    "      {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a math solver. Follow instructions exactly.\"\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Solve for x: 2x + 5 = 13. Return JSON: {\\\"x\\\": <number>}\"\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"{\\\"x\\\": 4}\"\n",
    "      }\n",
    "    ],\n",
    "    \"reference_answer\": {\"x\": 4}\n",
    "  }\n",
    "]\n",
    "\n",
    "```\n",
    "\n",
    "#### Example Lambda output\n",
    "Here is an example output from the Lambda function. Outputs must be in this JSON format for the custom Lambda reward function to correctly interact with the evaluation job.\n",
    "```\n",
    "[\n",
    "  {\n",
    "    \"id\": \"math_001\",\n",
    "    \"aggregate_reward_score\": 1.0,\n",
    "    \"metrics_list\": [\n",
    "      {\n",
    "        \"name\": \"correctness\",\n",
    "        \"value\": 1.0,\n",
    "        \"type\": \"Reward\"\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72616fb-56bb-4cc6-ab6d-c9cd8c56336d",
   "metadata": {},
   "source": [
    "### Step 1d: Update SageMaker execution role with correct permissions\n",
    "\n",
    "In order for the evaluation job to have the correct permissions to utilize the custom reward function, Lambda execution permission must be granted to the Sagemaker Training Job execution role. This role can be found from the above cell where we instantiated dependencies.\n",
    "\n",
    "To grant permission:\n",
    "1. Go to IAM Console\n",
    "2. Click Roles ‚Üí Search for your SageMaker Training Job execution role name\n",
    "3. Click the role name\n",
    "4. Click Add permissions ‚Üí Create inline policy\n",
    "5. Click JSON tab and paste:\n",
    "   ```\n",
    "   {\n",
    "  \"Version\": \"2012-10-17\",\n",
    "  \"Statement\": [\n",
    "    {\n",
    "      \"Effect\": \"Allow\",\n",
    "      \"Action\": \"lambda:InvokeFunction\",\n",
    "      \"Resource\": \"arn:aws:lambda:<YOUR_AWS_REGION>:<YOUR_AWS_ACC_ID>:function:SageMaker-RFT-Math-Evaluator\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49a1042a-08f4-45bd-b6aa-361fa3ac3308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Role: arn:aws:iam::618100645563:role/service-role/AmazonSageMaker-ExecutionRole-20251113T000017\n"
     ]
    }
   ],
   "source": [
    "# Run this to find the execution role ARN of your SageMaker instance. \n",
    "# The role name is just the appended ID after \"/service-role/\"\n",
    "print(f\"Execution Role: {execution_role}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d126abe-f07a-4e14-8a7e-f8a7ca2198e4",
   "metadata": {},
   "source": [
    "## Step 2: Upload dataset\n",
    "Quick steps to upload a custom dataset which will be supported by RFT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ea2044-a0d4-4cb9-bac0-10f5f182f625",
   "metadata": {},
   "source": [
    "#### Example provided dataset\n",
    "For this example we will use this provided dataset:\n",
    "\n",
    "```\n",
    "{\"id\": \"math_001\", \"messages\": [{\"role\": \"system\", \"content\": \"You are a math solver. Return ONLY valid JSON. Do not use markdown formatting or code blocks.\"}, {\"role\": \"user\", \"content\": \"Solve for x: 2x + 5 = 13. Return only JSON format: {\\\"x\\\": <number>}\"}], \"reference_answer\": {\"x\": 4}}\n",
    "{\"id\": \"math_002\", \"messages\": [{\"role\": \"system\", \"content\": \"You are a math solver. Return ONLY valid JSON. Do not use markdown formatting or code blocks.\"}, {\"role\": \"user\", \"content\": \"Solve for x: 3x - 7 = 8. Return only JSON format: {\\\"x\\\": <number>}\"}], \"reference_answer\": {\"x\": 5}}\n",
    "{\"id\": \"math_003\", \"messages\": [{\"role\": \"system\", \"content\": \"You are a math solver. Return ONLY valid JSON. Do not use markdown formatting or code blocks.\"}, {\"role\": \"user\", \"content\": \"Solve for x: x/2 + 3 = 7. Return only JSON format: {\\\"x\\\": <number>}\"}], \"reference_answer\": {\"x\": 8}}\n",
    "{\"id\": \"math_004\", \"messages\": [{\"role\": \"system\", \"content\": \"You are a math solver. Return ONLY valid JSON. Do not use markdown formatting or code blocks.\"}, {\"role\": \"user\", \"content\": \"Solve for x: 5x + 10 = 35. Return only JSON format: {\\\"x\\\": <number>}\"}], \"reference_answer\": {\"x\": 5}}\n",
    "{\"id\": \"math_005\", \"messages\": [{\"role\": \"system\", \"content\": \"You are a math solver. Return ONLY valid JSON. Do not use markdown formatting or code blocks.\"}, {\"role\": \"user\", \"content\": \"Solve for x: 4x - 12 = 0. Return only JSON format: {\\\"x\\\": <number>}\"}], \"reference_answer\": {\"x\": 3}}\n",
    "```\n",
    "\n",
    "This dataset is in the required format for RFT datasets.\n",
    "\n",
    "The required schema for RFT datasets is\n",
    "```\n",
    "{\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"<string>\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"<string>\",\n",
    "          \"text\": \"<string>\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"reference_answer\": {\n",
    "    \"<key>\": \"<value>\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "**Important current limitations**\n",
    "- Text only: No multimodal inputs (images, audio, video) are supported\n",
    "- Single-turn conversations: Only supports single user message (no multi-turn dialogues)\n",
    "- JSON format: Input data must be in JSONL format (one JSON object per line)\n",
    "- Model outputs: Evaluation is performed on generated completions from the specified model\n",
    "\n",
    "For more information on the required dataset format, see https://docs.aws.amazon.com/sagemaker/latest/dg/nova-rft-evaluation.html.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d09f7c-da5f-4c69-a17d-7bf9028aa2c8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Step 2a:\n",
    "1. Upload the provided dataset in a jsonl formatted document to the s3 location of your choice.\n",
    "2. Take note of the location of the dataset in S3; this will be used by the evaluation job to locate the dataset during execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f1d4ba-5dee-40dc-8756-98bb9d40f32b",
   "metadata": {},
   "source": [
    "## Step 3: Create your recipe yaml file\n",
    "\n",
    "1. The recipe yaml will be provided as a part of this example notebook under the filename \"rft_Eval_Example.yaml\"\n",
    "2. Modify the Lambda ARN in the recipe file to match the one created in the above instructions.\n",
    "3. Modify the yaml file match the specifications you'd like (naming, model type, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cde9d1-3003-48fa-8cf5-af4afdec6311",
   "metadata": {},
   "source": [
    "## Step 4: Execute and run SageMaker Training Job using the created resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5426314-06a6-4108-b29b-0e612a852e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Remote debugging, profiler and debugger hooks are disabled for Nova recipes.\n",
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker:Creating training-job with name: jmoul-nova-lite-math-eval-2025-12-24-00-17-48-051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-24 00:17:49 Starting - Starting the training job\n",
      "2025-12-24 00:17:49 Pending - Training job waiting for capacity......\n",
      "2025-12-24 00:18:42 Pending - Preparing the instances for training...................................................\n",
      "2025-12-24 00:27:26 Downloading - Downloading the training image............\n",
      "2025-12-24 00:29:22 Training - Training image download completed. Training in progress.......\u001b[34m/usr/local/lib/python3.12/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.12/site-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m2025-12-24 00:30:09,567 - INFO - Successfully registered Nova model as AutoModel\u001b[0m\n",
      "\u001b[34m[2025-12-24 00:30:10,878] [unknown_run_name] Starting Model Evaluation\u001b[0m\n",
      "\u001b[34m[2025-12-24 00:30:10,879] [unknown_run_name] Provided recipe config for evaluation: {'run': {'name': 'nova-lite-math-eval', 'model_type': 'amazon.nova-2-lite-v1:0:256k', 'model_name_or_path': 'nova-lite-2/prod', 'replicas': 1, 'data_s3_path': '', 'output_s3_path': ''}, 'evaluation': {'task': 'rft_eval', 'strategy': 'rft_eval', 'metric': 'all'}, 'inference': {'max_new_tokens': 100, 'top_k': -1, 'top_p': 1.0, 'temperature': 0, 'top_logprobs': 0, 'reasoning_effort': None}, 'rl_env': {'reward_lambda_arn': 'arn:aws:lambda:us-east-1:618100645563:function:SageMaker-RFT-Math-Evaluator'}}\u001b[0m\n",
      "\u001b[34m[2025-12-24 00:30:10,880] [unknown_run_name] Run name: nova-lite-math-eval\u001b[0m\n",
      "\u001b[34m[2025-12-24 00:30:11,088] [nova-lite-math-eval] Validating dataset file: math_eval.jsonl\u001b[0m\n",
      "\u001b[34m[2025-12-24 00:30:11,094] [nova-lite-math-eval] Found the model, loading model weights\u001b[0m\n",
      "\u001b[34m[2025-12-24 00:30:11,094] [nova-lite-math-eval] Found the model, loading model weights\u001b[0m\n",
      "\u001b[34m[2025-12-24 00:30:11,096] [nova-lite-math-eval] FutureWarning: The filesystem tracking backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance. (in /usr/local/lib/python3.12/site-packages/mlflow/tracking/_tracking_service/utils.py:177)\u001b[0m\n",
      "\u001b[34m[2025-12-24 00:30:11,539] [nova-lite-math-eval] Inferencing server still starting...\u001b[0m\n",
      "\u001b[34m[2025-12-24 00:30:11,766] [nova-lite-math-eval] INFO 12-24 00:30:11 [__init__.py:216] Automatically detected platform cuda.\u001b[0m\n",
      "\u001b[34m[2025-12-24 00:30:41,541] [nova-lite-math-eval] Inferencing server still starting...\u001b[0m\n",
      "\u001b[34m[2025-12-24 00:31:11,543] [nova-lite-math-eval] Inferencing server still starting...\u001b[0m\n",
      "\u001b[34m[2025-12-24 00:31:41,544] [nova-lite-math-eval] Inferencing server still starting...\u001b[0m\n",
      "\u001b[34m[2025-12-24 00:32:11,546] [nova-lite-math-eval] Inferencing server still starting...\u001b[0m\n",
      "\u001b[34m[2025-12-24 00:32:41,548] [nova-lite-math-eval] Inferencing server still starting...\u001b[0m\n",
      "\u001b[34m[2025-12-24 00:33:13,550] [nova-lite-math-eval] Inferencing server still starting...\u001b[0m\n",
      "\u001b[34m[2025-12-24 00:34:17,551] [nova-lite-math-eval] Inferencing server still starting...\u001b[0m\n",
      "\u001b[34m[2025-12-24 00:36:17,554] [nova-lite-math-eval] Inferencing server has started.\u001b[0m\n",
      "\u001b[34m[2025-12-24 00:36:17,555] [nova-lite-math-eval] Starting evaluation with task rft_eval\u001b[0m\n",
      "\u001b[34m[2025-12-24 00:36:18,172] [nova-lite-math-eval] INFO 12-24 00:36:18 [__init__.py:216] Automatically detected platform cuda.\u001b[0m\n",
      "\u001b[34mThe tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \u001b[0m\n",
      "\u001b[34mThe tokenizer class you load from this checkpoint is 'PreTrainedTokenizer'. \u001b[0m\n",
      "\u001b[34mThe class this function is called from is 'NovaTokenizer'.\u001b[0m\n",
      "\u001b[34m[2025-12-24 00:36:44,598] [nova-lite-math-eval] #015Generating train split: 0 examples [00:00, ? examples/s]\u001b[0m\n",
      "\u001b[34m[2025-12-24 00:36:44,602] [nova-lite-math-eval] #015Generating train split: 5 examples [00:00, 1168.33 examples/s]\u001b[0m\n",
      "\u001b[34m[2025-12-24 00:36:44,608] [nova-lite-math-eval] #015Splits:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2025-12-24 00:36:44,609] [nova-lite-math-eval] #015  0%|          | 0/5 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2025-12-24 00:36:44,609] [nova-lite-math-eval] #033[A\u001b[0m\n",
      "\u001b[34m[2025-12-24 00:36:45,410] [nova-lite-math-eval] #015 20%|##        | 1/5 [00:00<00:03,  1.25it/s]\u001b[0m\n",
      "\u001b[34m[2025-12-24 00:36:45,410] [nova-lite-math-eval] #033[A\u001b[0m\n",
      "\u001b[34m[2025-12-24 00:36:45,415] [nova-lite-math-eval] #015100%|##########| 5/5 [00:00<00:00,  6.20it/s]\u001b[0m\n",
      "\u001b[34m[2025-12-24 00:36:45,417] [nova-lite-math-eval] #015Splits: 100%|##########| 1/1 [00:00<00:00,  1.24it/s]\u001b[0m\n",
      "\u001b[34m[2025-12-24 00:36:45,417] [nova-lite-math-eval] #015Splits: 100%|##########| 1/1 [00:00<00:00,  1.24it/s]\u001b[0m\n",
      "\u001b[34m[2025-12-24 00:36:46,011] [nova-lite-math-eval] #015Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]\u001b[0m\n",
      "\u001b[34m[2025-12-24 00:36:46,012] [nova-lite-math-eval] #015Creating parquet from Arrow format: 100%|##########| 1/1 [00:00<00:00, 1346.05ba/s]\u001b[0m\n",
      "\u001b[34m[2025-12-24 00:36:46,043] [nova-lite-math-eval] Finished evaluation, closing the inference server\u001b[0m\n",
      "\u001b[34msys:1: DeprecationWarning: builtin type swigvarlink has no __module__ attribute\u001b[0m\n",
      "\n",
      "2025-12-24 00:38:02 Uploading - Uploading generated training model\n",
      "2025-12-24 00:38:02 Completed - Training job completed\n",
      "Training seconds: 646\n",
      "Billable seconds: 646\n",
      "‚úÖ Evaluation job completed! Job name: jmoul-nova-lite-math-eval-2025-12-24-00-17-48-051\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "input_s3_uri = \"S3_URI_FOR_INPUT_DATASET\"\n",
    "output_s3_uri = \"S3_PATH_FOR_OUTPUT_LOCATION\"\n",
    "instance_type = \"YOUR_INSTANCE_TYPE\"\n",
    "job_name = \"nova-lite-math-eval-workbook-example\"\n",
    "recipe_path = \"./rft_eval_recipe.yaml\"\n",
    "image_uri = \"708977205387.dkr.ecr.us-east-1.amazonaws.com/nova-evaluation-repo:SM-TJ-Eval-V2-latest\"\n",
    "\n",
    "# Create training input\n",
    "evalInput = TrainingInput(\n",
    "    s3_data=input_s3_uri,\n",
    "    distribution='FullyReplicated',\n",
    "    s3_data_type='S3Prefix'\n",
    ")\n",
    "\n",
    "# Create estimator\n",
    "estimator = PyTorch(\n",
    "    output_path=output_s3_uri,\n",
    "    base_job_name=job_name,\n",
    "    role=role,\n",
    "    instance_type=instance_type,\n",
    "    training_recipe=recipe_path,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    image_uri=image_uri\n",
    ")\n",
    "\n",
    "# Run evaluation\n",
    "estimator.fit(inputs={\"train\": evalInput})\n",
    "\n",
    "print(f\"‚úÖ Evaluation job completed! Job name: {estimator.latest_training_job.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bc61f1-9d22-4036-b64f-8472a74dab7d",
   "metadata": {},
   "source": [
    "## Step 4: Results analysis\n",
    "This step will give a code example of how to examine the outputs from the RFT evaluation job as well as show model inference outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d8245a-b3ec-4a73-b95a-5b1cd17195d8",
   "metadata": {},
   "source": [
    "#### Code example\n",
    "Autoatically grabs the values output from the SMTJ and prints them out in a human readable format.  \n",
    "\n",
    "**Make sure to update the bucket value to the correct output path for your data specified during job setup!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e4f734e-34cc-4a7b-b3ca-3a76e082c36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from: s3://nova-eval-forge-smoke-test/output/jmoul-nova-lite-math-eval-2025-12-24-00-17-48-051/output/output.tar.gz\n",
      "==================================================\n",
      "EVALUATION RESULTS\n",
      "==================================================\n",
      "\n",
      "üìä Aggregated Evaluation Metrics:\n",
      "\n",
      "Task: custom|rft_eval_rft_eval|0\n",
      "  lambda_correctness: 1.000\n",
      "  lambda_reward_score: 1.000\n",
      "\n",
      "==================================================\n",
      "SAMPLE RESULTS FROM OUTPUT PARQUET\n",
      "==================================================\n",
      "\n",
      "üìù Sample 1 - math_004:\n",
      "  Question: Solve for x: 5x + 10 = 35. Return only JSON format: {\"x\": <number>}\n",
      "  Model Response: '<|begin_of_solution|>```json\\n{\"x\": 5}\\n```<|end_of_solution|>'\n",
      "  Expected Answer: {'x': 5}\n",
      "  ‚úÖ Reward Score: 1.00\n",
      "  ‚úÖ Correctness: 1.00\n",
      "\n",
      "üìù Sample 2 - math_002:\n",
      "  Question: Solve for x: 3x - 7 = 8. Return only JSON format: {\"x\": <number>}\n",
      "  Model Response: '<|begin_of_solution|>```json\\n{\"x\": 5}\\n```<|end_of_solution|>'\n",
      "  Expected Answer: {'x': 5}\n",
      "  ‚úÖ Reward Score: 1.00\n",
      "  ‚úÖ Correctness: 1.00\n",
      "\n",
      "üìù Sample 3 - math_003:\n",
      "  Question: Solve for x: x/2 + 3 = 7. Return only JSON format: {\"x\": <number>}\n",
      "  Model Response: '<|begin_of_solution|>```json\\n{\"x\": 8}\\n```<|end_of_solution|>'\n",
      "  Expected Answer: {'x': 8}\n",
      "  ‚úÖ Reward Score: 1.00\n",
      "  ‚úÖ Correctness: 1.00\n",
      "\n",
      "üìù Sample 4 - math_005:\n",
      "  Question: Solve for x: 4x - 12 = 0. Return only JSON format: {\"x\": <number>}\n",
      "  Model Response: '<|begin_of_solution|>```json\\n{\"x\": 3}\\n```<|end_of_solution|>'\n",
      "  Expected Answer: {'x': 3}\n",
      "  ‚úÖ Reward Score: 1.00\n",
      "  ‚úÖ Correctness: 1.00\n",
      "\n",
      "üìù Sample 5 - math_001:\n",
      "  Question: Solve for x: 2x + 5 = 13. Return only JSON format: {\"x\": <number>}\n",
      "  Model Response: '<|begin_of_solution|>```json\\n{\"x\": 4}\\n```<|end_of_solution|>'\n",
      "  Expected Answer: {'x': 4}\n",
      "  ‚úÖ Reward Score: 1.00\n",
      "  ‚úÖ Correctness: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_435662/4041288447.py:32: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall('results/')\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import tarfile\n",
    "import json\n",
    "import glob\n",
    "import ast\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Clean old results\n",
    "if os.path.exists('results/'):\n",
    "    shutil.rmtree('results/')\n",
    "if os.path.exists('results.tar.gz'):\n",
    "    os.remove('results.tar.gz')\n",
    "\n",
    "# S3 path to output file\n",
    "s3_output_path = \"S3_OUTPUT_URI_FOR_ZIP_FILE\"\n",
    "\n",
    "# Parse S3 path\n",
    "s3_parts = s3_output_path.replace(\"s3://\", \"\").split(\"/\", 1)\n",
    "bucket = s3_parts[0]\n",
    "key = s3_parts[1]\n",
    "\n",
    "print(f\"Downloading from: {s3_output_path}\")\n",
    "\n",
    "# Download output tar.gz\n",
    "s3 = boto3.client('s3')\n",
    "s3.download_file(bucket, key, 'results.tar.gz')\n",
    "\n",
    "# Extract results\n",
    "with tarfile.open('results.tar.gz', 'r:gz') as tar:\n",
    "    tar.extractall('results/')\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"EVALUATION RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Find all result files\n",
    "json_files = glob.glob('results/**/results_*.json', recursive=True)\n",
    "parquet_files = glob.glob('results/**/details_*.parquet', recursive=True)\n",
    "\n",
    "# Load results JSON (aggregated metrics)\n",
    "if json_files:\n",
    "    with open(json_files[0], 'r') as f:\n",
    "        results = json.load(f)\n",
    "        print(\"\\nüìä Aggregated Evaluation Metrics:\")\n",
    "        \n",
    "        for task_name, metrics in results['results'].items():\n",
    "            print(f\"\\nTask: {task_name}\")\n",
    "            for metric_name, value in metrics.items():\n",
    "                print(f\"  {metric_name}: {value:.3f}\")\n",
    "\n",
    "# Load and display parquet details\n",
    "if parquet_files:\n",
    "    df = pd.read_parquet(parquet_files[0])\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"SAMPLE RESULTS FROM OUTPUT PARQUET\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    sample_print_count = 5\n",
    "    for i in range(min(sample_print_count, len(df))):\n",
    "        row = df.iloc[i]\n",
    "        \n",
    "        # Parse predictions (stored as string representation of list)\n",
    "        predictions = ast.literal_eval(row['predictions']) if isinstance(row['predictions'], str) else row['predictions']\n",
    "        prediction = predictions[0] if predictions else \"No prediction\"\n",
    "        \n",
    "        # Parse string representations to dicts\n",
    "        metrics = ast.literal_eval(row['metrics']) if isinstance(row['metrics'], str) else row['metrics']\n",
    "        specifics = ast.literal_eval(row['specifics']) if isinstance(row['specifics'], str) else row['specifics']\n",
    "        \n",
    "        lambda_metrics = metrics['rft_eval_lambda_metric']\n",
    "        \n",
    "        print(f\"\\nüìù Sample {i + 1} - {specifics['sample_id']}:\")\n",
    "        print(f\"  Question: {specifics['original_line']['messages'][1]['content']}\")\n",
    "        print(f\"  Model Response: {repr(prediction)}\")\n",
    "        print(f\"  Expected Answer: {specifics['original_line']['reference_answer']}\")\n",
    "        print(f\"  ‚úÖ Reward Score: {lambda_metrics['lambda_reward_score']:.2f}\")\n",
    "        print(f\"  ‚úÖ Correctness: {lambda_metrics['lambda_correctness']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f036778-9c37-4ee4-9207-1a383cb56c03",
   "metadata": {},
   "source": [
    "#Summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
