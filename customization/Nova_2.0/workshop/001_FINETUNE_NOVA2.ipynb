{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ad542e7-9ef8-41d1-9d6c-3c6c2efb7f19",
   "metadata": {},
   "source": [
    "# Supervised Fine-Tuning (SFT) with Parameter Efficient Fine Tuning(PEFT LoRA) of Amazon Nova using Amazon SageMaker Training Job\n",
    "\n",
    "You can customize Amazon Nova models through base recipes using Amazon SageMaker training jobs. These recipes support Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO), with both Full-Rank and Low-Rank Adaptation (LoRA) options.\n",
    "\n",
    "The end-to-end customization workflow involves stages like model training, model evaluation, and deployment for inference. This model customization approach on SageMaker AI provides greater flexibility and control to fine-tune its supported Amazon Nova models, optimize hyperparameters with precision, and implement techniques including LoRA Parameter-Efficient Fine-Tuning (PEFT), Full-Rank Supervised Fine-Tuning, and Direct Preference Optimization (DPO).\n",
    "\n",
    "This notebook demonstrates Supervised Fine-Tuning (SFT) with Parameter-Efficient Fine-Tuning (PEFT) of Amazon Nova using Amazon SageMaker Training Job. SFT is a technique that allows fine-tuning language models on specific tasks using labeled examples, while PEFT enables efficient fine-tuning by updating only a small subset of the model's parameters.\n",
    "\n",
    "\n",
    "> _**Note:** This notebook demonstrates fine-tuning using Nova Lite, but the same techniques can be applied to Nova Pro or Nova Micro models with appropriate adjustments to the configuration._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e809d78-c38c-4de2-b5ee-b77c0aa9b843",
   "metadata": {},
   "source": [
    "## Installing Dependencies\n",
    "\n",
    "The first cell installs the required Python packages for this notebook. For more details on other pre-requisites needed check out [AWS Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/nova-model-general-prerequisites.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907944ea-dbfb-4de0-9e13-1fd28c901031",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r ./requirements.txt --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6c9e5c-c57c-42cd-baf4-e139422cc147",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8b6105-ecec-4213-b56d-589238844dca",
   "metadata": {},
   "source": [
    "## Step 0: Prerequisites\n",
    "\n",
    "This section sets up the necessary AWS credentials and SageMaker session to run the notebook. You'll need proper IAM permissions to use SageMaker.\n",
    "\n",
    "\n",
    "If you are going to use Sagemaker in a local environment. You need access to an IAM Role with the required permissions for Sagemaker. You can find [here](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html) more about it.\n",
    "\n",
    "The code initializes a SageMaker session, sets up the IAM role, and configures the S3 bucket for storing training data and model artifacts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce51663-0171-4d54-b16e-f85e3cadb692",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "sagemaker_session_bucket = None\n",
    "\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client(\"iam\")\n",
    "    role = iam.get_role(RoleName=\"sagemaker_execution_role\")[\"Role\"][\"Arn\"]\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "bucket_name = sess.default_bucket()\n",
    "default_prefix = sess.default_bucket_prefix\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab0eea1",
   "metadata": {},
   "source": [
    "### Low-rank adapter fine tuning\n",
    "\n",
    "\n",
    "The most effective and cost-efficient method to enhance the base model performance is through the utilization of Low Rank Adapter (LoRA) fine-tuning. The underlying principle of LoRA is that only a small number of additional weights requires updating to adapt it to new tasks or domains. LoRA efficiently fine-tunes large language models by introducing low-rank trainable weight matrices into specific model layers, reducing the number of trainable parameters while maintaining model quality. A LoRA adapter augments the base foundation model by incorporating lightweight adapter layers that modify the modelâ€™s weights during inference, while keeping the original model parameters frozen. This approach is also considered one of the most cost-effective fine-tuning techniques. For more information, see Fine-tune models with adapter inference components\n",
    "\n",
    "In what cases is Low-rank Adapter Fine tuning recommended?\n",
    "\n",
    "* Developers are recommended to generally start with Low-rank Adapter Fine tuning due to its fast training procedure.\n",
    "* It is recommended to use Low-rank Adapter (LoRA) fine-tuning in cases where the base model performance is already satisfactory, and the goal is to enhance the model's capabilities across multiple related tasks, such as text summarization and language translation. LoRA's regularization properties help prevent over-fitting and mitigate the \"forgetting\" of the source domain, ensuring the model remains versatile and adaptable to various applications.\n",
    "* Consider using LoRA for instruction fine-tuning (IFT) scenarios with relatively small datasets. LoRA performs better with smaller, task-specific datasets than broader larger datasets.\n",
    "* It is recommended to leverage Low-rank Adapter (LoRA) fine-tuning on Amazon SageMaker AI when the developer has a larger labeled dataset that exceeds the Bedrock Customization Data Limits.\n",
    "* Additionally, LoRA on SageMaker AI is recommended when the developer has already achieved promising results through Bedrock Customization, and seeks to further optimize hyper-parameters.\n",
    "\n",
    "![lora-arch](imgs/lora_based_arch.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b95b61-8666-4015-bf2e-fcf68ce38c5b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82089d28-b97a-4956-83fb-d8c46d44fdb5",
   "metadata": {},
   "source": [
    "## Step 1: Prepare the dataset\n",
    "\n",
    "In this example, we are going to load [IBMresearch/finQA](https://huggingface.co/datasets/ibm-research/finqa) dataset, an open-source financial dataset with 2.8k financial reports for 8k Q&A pairs to study numerical reasoning with structured and unstructured evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f368c020-e9a3-48b3-a53b-45404bba9482",
   "metadata": {},
   "source": [
    "### Understanding the Nova Format\n",
    "\n",
    "Let's format the dataset by using the prompt style for Amazon Nova:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"system\": [{\"text\": Content of the System prompt}],\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\"text\": Content of the user prompt]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [\"text\": Content of the answer]\n",
    "        },\n",
    "        ...\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec5c7b6",
   "metadata": {},
   "source": [
    "### Step 1.3: Data Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5efd8ac",
   "metadata": {},
   "source": [
    "The notebook defines utility functions to clean the dataset content by removing prefixes and handling special cases:\n",
    "\n",
    "```python\n",
    "def clean_prefix(content):\n",
    "    # Removes prefixes like \"USER:\", \"ASSISTANT:\", etc.\n",
    "    ...\n",
    "\n",
    "def clean_message_list(message_list):\n",
    "    # Cleans message lists from None values and converts to proper format\n",
    "    ...\n",
    "\n",
    "def clean_numbered_conversation(message_list):\n",
    "    # Cleans message lists from None values and converts to proper format\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d19914-72ef-493a-88db-366d01d1b8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import Dict, Any, List\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from random import randint\n",
    "\n",
    "# --- Utility Functions (Provided in previous steps) ---\n",
    "\n",
    "def clean_prefix(content):\n",
    "    \"\"\"Remove conversational prefixes from content.\"\"\"\n",
    "    prefixes = [ \"SYSTEM:\", \"System:\", \"USER:\", \"User:\", \"ASSISTANT:\", \"Assistant:\", \"Bot:\", \"BOT:\", ]\n",
    "    if isinstance(content, str):\n",
    "        lines = content.split(\"\\n\")\n",
    "        cleaned_lines = []\n",
    "        for line in lines:\n",
    "            cleaned_line = line.strip()\n",
    "            for prefix in prefixes:\n",
    "                if cleaned_line.startswith(prefix):\n",
    "                    cleaned_line = cleaned_line[len(prefix) :].strip()\n",
    "                    break\n",
    "            cleaned_lines.append(cleaned_line)\n",
    "        return \"\\n\".join(cleaned_lines)\n",
    "    return content\n",
    "\n",
    "# Placeholder for clean_message_list (used for final cleanup step, as per your request)\n",
    "def clean_message_list(message_list):\n",
    "    \"\"\"Applies clean_prefix to content text within the Nova format structure.\"\"\"\n",
    "    if not isinstance(message_list, list):\n",
    "        return message_list\n",
    "    \n",
    "    cleaned = []\n",
    "    for item in message_list:\n",
    "        if item.get(\"content\"):\n",
    "            new_content = []\n",
    "            for content_item in item[\"content\"]:\n",
    "                if isinstance(content_item, dict) and \"text\" in content_item:\n",
    "                    # Re-apply cleaning here if necessary\n",
    "                    content_item[\"text\"] = clean_prefix(content_item[\"text\"])\n",
    "                    new_content.append(content_item)\n",
    "            item[\"content\"] = new_content\n",
    "            cleaned.append(item)\n",
    "    return cleaned\n",
    "\n",
    "# --- FinQA Data Processing Functions ---\n",
    "\n",
    "def finqa_to_standard_format(example: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Converts a FinQA example into the intermediate standard message list format.\"\"\"\n",
    "    \n",
    "    # 1. Format Table for prompt\n",
    "    table_data = example.get('table', [])\n",
    "    table_str = \"\"\n",
    "    # ... (Table formatting logic) ...\n",
    "    if table_data and isinstance(table_data, list) and table_data[0]:\n",
    "        header = table_data[0]\n",
    "        rows = table_data[1:]\n",
    "        table_str += \"| \" + \" | \".join(map(str, header)) + \" |\\n\"\n",
    "        table_str += \"| \" + \" | \".join([\"---\"] * len(header)) + \" |\\n\"\n",
    "        for row in rows:\n",
    "            table_str += \"| \" + \" | \".join(map(str, row)) + \" |\\n\"\n",
    "    else:\n",
    "        table_str = \"No structured table data provided.\"\n",
    "    \n",
    "    user_prompt = f\"\"\"Given the following financial context and table data:\n",
    "\n",
    "---\n",
    "CONTEXT: {example['pre_text']}\n",
    "\n",
    "TABLE:\n",
    "{table_str}\n",
    "\n",
    "---\n",
    "QUESTION: {example['question']}\n",
    "\n",
    "Please generate the step-by-step calculation program to answer the question.\"\"\"\n",
    "\n",
    "    assistant_response = example['program_re']\n",
    "\n",
    "    messages: List[Dict[str, Any]] = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a specialized financial analysis AI. Your task is to convert financial questions into accurate executable calculation programs based on provided context and data.\"},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "        {\"role\": \"assistant\", \"content\": assistant_response}\n",
    "    ]\n",
    "    return {\"messages\": messages}\n",
    "\n",
    "def convert_to_nova_format(example: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Converts the standard message list into the Nova format structure.\"\"\"\n",
    "    standard_messages = example.get(\"messages\", [])\n",
    "    if not standard_messages:\n",
    "        return {\"system\": [], \"messages\": []}\n",
    "\n",
    "    nova_system = []\n",
    "    nova_messages = []\n",
    "\n",
    "    for i, msg in enumerate(standard_messages):\n",
    "        role = msg[\"role\"]\n",
    "        content = msg[\"content\"]\n",
    "        cleaned_content = clean_prefix(content)\n",
    "        \n",
    "        # Required Nova structure: content is [{\"text\": ...}]\n",
    "        nova_content_struct = [{\"text\": cleaned_content}]\n",
    "        \n",
    "        if role == \"system\" and i == 0:\n",
    "            nova_system = nova_content_struct\n",
    "        else:\n",
    "            nova_messages.append({\"role\": role, \"content\": nova_content_struct})\n",
    "            \n",
    "    # Return the new keys\n",
    "    return {\"system\": nova_system, \"messages\": nova_messages}\n",
    "\n",
    "\n",
    "def convert_to_nova_test_format(example: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Converts the standard message list into the Nova test/evaluation format.\n",
    "    Required format: {\"system\": str, \"query\": str, \"response\": str}\n",
    "    \"\"\"\n",
    "    standard_messages = example.get(\"messages\", [])\n",
    "    if not standard_messages:\n",
    "        return {\"system\": \"\", \"query\": \"\", \"response\": \"\"}\n",
    "    \n",
    "    system_content = \"\"\n",
    "    query_content = \"\"\n",
    "    response_content = \"\"\n",
    "    \n",
    "    for msg in standard_messages:\n",
    "        role = msg[\"role\"]\n",
    "        content = clean_prefix(msg[\"content\"])\n",
    "        \n",
    "        if role == \"system\":\n",
    "            system_content = content\n",
    "        elif role == \"user\":\n",
    "            query_content = content\n",
    "        elif role == \"assistant\":\n",
    "            response_content = content\n",
    "    \n",
    "    return {\n",
    "        \"system\": system_content,\n",
    "        \"query\": query_content,\n",
    "        \"response\": response_content\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d3999e-71b1-43ec-98fc-dcfc42c2f7ef",
   "metadata": {},
   "source": [
    "## Loading dataset and applying preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b6ca39-dada-460f-8103-0223ab091590",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"1. Loading FinQA DatasetDict (all splits)...\")\n",
    "dataset_dict = load_dataset(\"ibm-research/finqa\", trust_remote_code=True)\n",
    "final_dataset_dict = DatasetDict()\n",
    "\n",
    "# Loop through each split (train, validation, test)\n",
    "for split_name in dataset_dict.keys():\n",
    "    print(f\"\\nProcessing split: {split_name}...\")\n",
    "    \n",
    "    current_dataset = dataset_dict[split_name]\n",
    "    initial_features = list(current_dataset.features.keys())\n",
    "    \n",
    "    # --- Step 1: Convert FinQA structure to standard message list ---\n",
    "    processed_std = current_dataset.map(\n",
    "        finqa_to_standard_format, \n",
    "        remove_columns=initial_features\n",
    "    )\n",
    "    \n",
    "    # --- Step 2: Convert to appropriate Nova format based on split ---\n",
    "    if split_name == \"test\":\n",
    "        # Test split: Use flat string format (system/query/response)\n",
    "        processed_nova = processed_std.map(convert_to_nova_test_format)\n",
    "        \n",
    "        # Convert to pandas for any final cleanup if needed\n",
    "        processed_df = processed_nova.to_pandas()\n",
    "        \n",
    "        # Convert back to Dataset\n",
    "        final_dataset = Dataset.from_pandas(processed_df)\n",
    "        \n",
    "    else:\n",
    "        # Train/Validation splits: Use nested Nova format (system array + messages array)\n",
    "        processed_nova = processed_std.map(convert_to_nova_format)\n",
    "        \n",
    "        # --- Step 3: Apply cleanup and finalize structure ---\n",
    "        # Convert to pandas to apply column-wise function (clean_message_list)\n",
    "        processed_df = processed_nova.to_pandas()\n",
    "        \n",
    "        # Apply the cleaning function to the 'messages' column\n",
    "        # Note: 'system' is separate in Nova format, so clean_message_list only applies to 'messages'.\n",
    "        processed_df[\"messages\"] = processed_df[\"messages\"].apply(clean_message_list)\n",
    "        \n",
    "        # Convert back to Dataset\n",
    "        final_dataset = Dataset.from_pandas(processed_df)\n",
    "    \n",
    "    # Assign the final processed split to the DatasetDict\n",
    "    final_dataset_dict[split_name] = final_dataset\n",
    "    \n",
    "    # Print example for verification\n",
    "    if final_dataset.num_rows > 0:\n",
    "        rand_index = randint(0, final_dataset.num_rows - 1)\n",
    "        print(f\"\\nExample from {split_name} split (Row {rand_index}):\")\n",
    "        print(json.dumps(final_dataset[rand_index], indent=2))\n",
    "\n",
    "print(\"\\n--- FINAL RESULT ---\")\n",
    "print(final_dataset_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5278d2e",
   "metadata": {},
   "source": [
    "### Step 1.4: Splitting data into test , train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335f6202-60d8-43bd-911a-3ec74bf8c20b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from random import randint\n",
    "\n",
    "# 1. Define the datasets using the correct keys from final_dataset_dict\n",
    "test_dataset = final_dataset_dict[\"test\"]\n",
    "val_dataset = final_dataset_dict[\"validation\"]\n",
    "train_dataset = final_dataset_dict[\"train\"]\n",
    "\n",
    "rand_index = randint(0, len(test_dataset) - 1)\n",
    "print(f\"Sampling a random example from test_dataset (Index {rand_index}):\")\n",
    "print(test_dataset[rand_index])\n",
    "\n",
    "# choose a small number of samples for the training job\n",
    "N_SAMPLES = 100\n",
    "\n",
    "# 2. Get the first N_SAMPLES from each split\n",
    "# Note: If a split has fewer than 100 samples, it will return all available samples.\n",
    "test_subset = test_dataset.select(range(min(N_SAMPLES, len(test_dataset))))\n",
    "val_subset = val_dataset.select(range(min(N_SAMPLES, len(val_dataset))))\n",
    "train_subset = train_dataset.select(range(min(N_SAMPLES, len(train_dataset))))\n",
    "\n",
    "# 3. Verification and Output\n",
    "print(f\"Original Test Size: {len(test_dataset)}\")\n",
    "print(f\"Subset Test Size: {len(test_subset)}\")\n",
    "print(f\"Subset Train Size: {len(train_subset)}\")\n",
    "print(f\"Subset Validation Size: {len(val_subset)}\")\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dd6bac",
   "metadata": {},
   "source": [
    "### Step 1.5: Data Preperation on test data for Offline Evaluation post fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc7f8ba",
   "metadata": {},
   "source": [
    "Let's format the test dataset in the format:\n",
    "\n",
    "Required Fields:\n",
    "\n",
    "* query: String containing the question or instruction that needs an answer\n",
    "* response: String containing the expected model output\n",
    "\n",
    "Optional Fields:\n",
    "\n",
    "* system: String containing the system prompt that sets the behavior, role, or personality of the AI model before it processes the query\n",
    "\n",
    "Example Entry\n",
    "```\n",
    "\n",
    "{\n",
    "   \"system\":\"You are a english major with top marks in class who likes to give minimal word responses: \",\n",
    "   \"query\":\"What is the symbol that ends the sentence as a question\",\n",
    "   \"response\":\"?\"\n",
    "}\n",
    "{\n",
    "   \"system\":\"You are a pattern analysis specialist that provides succinct answers: \",\n",
    "   \"query\":\"What is the next number in this series? 1, 2, 4, 8, 16, ?\",\n",
    "   \"response\":\"32\"\n",
    "}\n",
    "{\n",
    "   \"system\":\"You have great attention to detail that follows instructions accurately: \",\n",
    "   \"query\":\"Repeat only the last two words of the following: I ate a hamburger today and it was kind of dry\",\n",
    "   \"response\":\"of dry\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64815f4-4614-4670-92a7-ef6b39dfeef2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset \n",
    "\n",
    "# flatten the dataset\n",
    "all_examples = []\n",
    "\n",
    "for examples_list in test_subset:\n",
    "    column_name = test_subset.column_names[0]\n",
    "    examples = examples_list[column_name]\n",
    "    print(examples)\n",
    "    all_examples.extend(examples)\n",
    "\n",
    "# create a new dataset with the desired structure\n",
    "test_subset_formatted = Dataset.from_dict(\n",
    "    {\n",
    "        \"system\": [example[\"system\"] for example in all_examples],\n",
    "        \"query\": [example[\"query\"] for example in all_examples],\n",
    "        \"response\": [example[\"response\"] for example in all_examples],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(test_subset_formatted[randint(0, len(test_subset))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e667af-8197-4d2f-8432-82db6a1d3006",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T16:46:36.592759Z",
     "iopub.status.busy": "2024-12-17T16:46:36.591798Z",
     "iopub.status.idle": "2024-12-17T16:46:36.603128Z",
     "shell.execute_reply": "2024-12-17T16:46:36.598965Z",
     "shell.execute_reply.started": "2024-12-17T16:46:36.592728Z"
    }
   },
   "source": [
    "### Step 1.6: Upload all 3 curated datasets (train, test, val) to Amazon S3\n",
    "\n",
    "The notebook applies the functions to transform the datasets into the required formats\n",
    "\n",
    "\n",
    "The processed datasets are saved locally and then uploaded to Amazon S3 for use in SageMaker training:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97f29e5-4aed-4939-8d51-ad3c5268299f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db05863-3acb-483b-8e34-2aacbdbc68a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# save train_dataset to s3 using our SageMaker session\n",
    "if default_prefix:\n",
    "    input_path = f\"{default_prefix}/datasets/nova-sft-peft\"\n",
    "else:\n",
    "    input_path = f\"datasets/nova-sft-peft\"\n",
    "\n",
    "train_dataset_s3_path = f\"s3://{bucket_name}/{input_path}/train/dataset.jsonl\"\n",
    "val_dataset_s3_path = f\"s3://{bucket_name}/{input_path}/val/dataset.jsonl\"\n",
    "test_dataset_s3_path = f\"s3://{bucket_name}/{input_path}/test/gen_qa.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064d0321-1bd5-4c62-845a-bb1b9a3891a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "TRAIN_FULL_PATH = \"./data/train/subset_train.jsonl\"\n",
    "VAL_FULL_PATH = \"./data/val/subset_validation.jsonl\"\n",
    "TEST_FULL_PATH = \"./data/test/subset_test.json\" \n",
    "\n",
    "\n",
    "# 1. Save datasets to local files\n",
    "print(\"1. Creating local directories and saving datasets...\")\n",
    "os.makedirs(\"./data/train\", exist_ok=True)\n",
    "os.makedirs(\"./data/val\", exist_ok=True)\n",
    "os.makedirs(\"./data/test\", exist_ok=True) \n",
    "\n",
    "# Save the splits from the final_dataset_dict subsets\n",
    "print(f\"Saving train split (first {len(train_subset)} samples) to {TRAIN_FULL_PATH}\")\n",
    "# Use the SUBSET dataset object to save\n",
    "train_subset.to_json(TRAIN_FULL_PATH, orient=\"records\", lines=True)\n",
    "\n",
    "# Note: The FinQA validation split is stored under the key \"validation\"\n",
    "print(f\"Saving validation split (first {len(val_subset)} samples) to {VAL_FULL_PATH}\")\n",
    "# Use the SUBSET dataset object to save\n",
    "val_subset.to_json(VAL_FULL_PATH, orient=\"records\", lines=True)\n",
    "\n",
    "print(f\"Saving test split (first {len(test_subset)} samples) to {TEST_FULL_PATH}\")\n",
    "# Note: Retaining the user's original call signature for test (without orient/lines args)\n",
    "# Use the SUBSET dataset object to save\n",
    "test_subset.to_json(TEST_FULL_PATH)\n",
    "\n",
    "\n",
    "# 2. Upload local files to S3\n",
    "print(\"\\n2. Uploading datasets to S3 using s3_client...\")\n",
    "\n",
    "# Use the FULL local paths for upload_file\n",
    "s3_client.upload_file(\n",
    "    TRAIN_FULL_PATH, bucket_name, f\"{input_path}/train/dataset.jsonl\"\n",
    ")\n",
    "\n",
    "s3_client.upload_file(\n",
    "    VAL_FULL_PATH, bucket_name, f\"{input_path}/val/dataset.jsonl\"\n",
    ")\n",
    "\n",
    "s3_client.upload_file(\n",
    "    TEST_FULL_PATH, bucket_name, f\"{input_path}/test/gen_qa.jsonl\"\n",
    ")\n",
    "\n",
    "\n",
    "# 3. Cleanup local files\n",
    "print(\"\\n3. Cleaning up local data directory...\")\n",
    "try:\n",
    "    shutil.rmtree(\"./data\")\n",
    "except OSError as e:\n",
    "    # Handle case where directory might not exist or permissions fail\n",
    "    print(f\"Error cleaning up local directory: {e}\")\n",
    "\n",
    "\n",
    "# 4. Print confirmation\n",
    "print(\"\\nDatasets uploaded successfully:\")\n",
    "print(f\"Training data uploaded to: {train_dataset_s3_path}\")\n",
    "print(f\"Validation data uploaded to: {val_dataset_s3_path}\")\n",
    "print(f\"Test data uploaded to: {test_dataset_s3_path}\")\n",
    "%store test_dataset_s3_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af9c237-28bd-474e-9444-94aaea8e6979",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4457beda-117d-4782-9f04-0680c199e98a",
   "metadata": {},
   "source": [
    "## Step 2: Model fine-tuning\n",
    "\n",
    "We now define the PyTorch estimator to run the supervised fine-tuning on a tool-calling dataset for our Amazon Nova model\n",
    "\n",
    "This section sets up and runs the fine-tuning job using SageMaker. It uses Supervised Fine-Tuning (SFT) with Parameter-Efficient Fine-Tuning (PEFT) to efficiently train the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6758cba-f81e-4ca9-84d9-452107235ca3",
   "metadata": {},
   "source": [
    "#### Instance Type and Count\n",
    "\n",
    "P5 instances are optimized for deep learning workloads, providing high-performance GPUs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8cecfd-e640-4527-99d4-cb3cec9093b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instance_type = \"ml.p5.48xlarge\"\n",
    "instance_count = 4\n",
    "\n",
    "instance_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f43862-c99b-481d-a858-707d59977b02",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Image URI\n",
    "\n",
    "This specifies the pre-built container for SFT fine-tuning, which is different from the DPO container.\n",
    "\n",
    "The images URIs are available in the documentation [here](https://docs.aws.amazon.com/sagemaker/latest/dg/nova-fine-tuning-training-job.html#nova-model-training-jobs-notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5df7700-7c66-4af8-aea0-da0e5af493bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_uri = f\"708977205387.dkr.ecr.{sess.boto_region_name}.amazonaws.com/nova-fine-tune-repo:SM-TJ-SFT-V2-latest\"\n",
    "\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433811bb-461e-4ac7-ab05-175bff7fdf61",
   "metadata": {},
   "source": [
    "#### Configuring the Model and Recipe\n",
    "\n",
    "This specifies which model to fine-tune and the recipe to use. The recipe includes \"lora\" indicating parameter-efficient fine-tuning, and \"sft\" indicating supervised fine-tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d100cecc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"nova-lite-2/prod\"\n",
    "recipe=\"fine-tuning/nova/nova_2_0/nova_lite/SFT/nova_lite_2_0_p5_gpu_lora_sft\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95841fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# define Training Job Name\n",
    "job_name = f\"train-{model_id.split('/')[0].replace('.', '-')}-peft-sft\"\n",
    "\n",
    "# define OutputDataConfig path\n",
    "if default_prefix:\n",
    "    output_path = f\"s3://{bucket_name}/{default_prefix}/{job_name}\"\n",
    "else:\n",
    "    output_path = f\"s3://{bucket_name}/{job_name}\"\n",
    "\n",
    "recipe_overrides = {\n",
    "    \"run\": {\n",
    "        \"replicas\": instance_count,  # Required\n",
    "    },\n",
    "}\n",
    "\n",
    "estimator = PyTorch(\n",
    "    output_path=output_path,\n",
    "    base_job_name=job_name,\n",
    "    role=role,\n",
    "    disable_profiler=True,\n",
    "    debugger_hook_config=False,\n",
    "    instance_count=instance_count,\n",
    "    instance_type=instance_type,\n",
    "    training_recipe=recipe,\n",
    "    recipe_overrides=recipe_overrides,\n",
    "    max_run=432000,\n",
    "    sagemaker_session=sess,\n",
    "    image_uri=image_uri\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4241e1ea-38e7-47db-9e5a-827d63f1e278",
   "metadata": {},
   "source": [
    "#### Configuring the Data Channels\n",
    "\n",
    "Configure the Data Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a386bd9-172c-485c-af45-ebc1d126470b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "train_input = TrainingInput(\n",
    "    s3_data=train_dataset_s3_path,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    s3_data_type=\"Converse\",\n",
    ")\n",
    "\n",
    "val_input = TrainingInput(\n",
    "    s3_data=val_dataset_s3_path,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    s3_data_type=\"Converse\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e1cec0-4b88-41df-9015-bca465fc1b67",
   "metadata": {},
   "source": [
    "### Starting the Training Job\n",
    "This starts the training job with the configured estimator and datasets. Note that it uses the test dataset for validation during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25e13aa-1df2-43fc-bae4-15f5b7113191",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# starting the train job with our uploaded datasets as input\n",
    "estimator.fit(inputs={\"train\": train_input, \"validation\": val_input}, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f849fce-08f0-4a5d-a733-2c040b0e7c18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_job_name = estimator.latest_training_job.name\n",
    "print('Training Job Name:  {}'.format(training_job_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befdf22a-8b72-409c-84c1-0fd1d2f30946",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, Markdown, Image\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/jobs/{}\">Training Job</a> After About 5 Minutes</b>'.format(\"us-east-1\", training_job_name)))\n",
    "\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region={}#logStream:group=/aws/sagemaker/TrainingJobs;prefix={};streamFilter=typeLogStreamPrefix\">CloudWatch Logs</a> After About 5 Minutes</b>'.format(\"us-east-1\", training_job_name)))\n",
    "\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://s3.console.aws.amazon.com/s3/buckets/{}/train-nova-lite-peft-sft/{}/output/?region={}&tab=overview\">S3 Output Data</a> After The Training Job Has Completed</b>'.format(bucket_name, training_job_name, \"us-east-1\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44498e29",
   "metadata": {},
   "source": [
    "---\n",
    "## _Wait Until the ^^ Training Job ^^ Completes Above!( 35-40 mins)_\n",
    "\n",
    "**While you wait, go to 02-evaluate-fine-tuned-models.ipynb. In the notebook, we will plot the loss curve for a previously fine-tuned model, and view results from previously run evaluation jobs of the base model and fine-tuned models to see how fine-tuning has improved model performance.**\n",
    "\n",
    "You're welcome to come back to this notebook once the training job is complete and run the section below to understand how to get the model outputs and submit an evaluation job.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5603ad40-69ed-4144-9c75-b4640bd829e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Reading the Output Content of fine tuned model\n",
    "\n",
    "After the job is complete, the trained model weights will be available in an escrow S3 bucket. This secure bucket is controlled by Amazon and uses special access controls. You can access the paths shared in manifest files that are saved in a customer S3 bucket as part of the training process. You will point to this S3 location when you wish to host the fine-tuned model on Bedrock as well. In this section, let's download the artifacts (training and validation metrics), and get the escrow S3 bucket location from `manifest.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eb45e6-5399-411a-936c-5ba41aa7c936",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_s3_uri = estimator.model_data\n",
    "\n",
    "%store model_s3_uri\n",
    "\n",
    "output_s3_uri = \"/\".join(model_s3_uri.split(\"/\")[:-1])+\"/output.tar.gz\"\n",
    "%store output_s3_uri\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aff07c-4920-4cc6-b797-e6b4063be925",
   "metadata": {},
   "source": [
    "### Downloading and Extracting the Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7c2532-546f-4f23-8d45-20fe7de734f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p ./tmp/train_output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52a1683-9105-40e7-ab61-44cb4ec38d1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 cp $output_s3_uri ./tmp/train_output/output.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6706c446-4a6b-457e-84eb-6a696665e06e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!tar -xvzf ./tmp/train_output/output.tar.gz -C ./tmp/train_output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0264e1d0-b218-4ea7-9008-884a6e3bec32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "escrow_model_uri = json.load(open('./tmp/train_output/manifest.json'))['checkpoint_s3_bucket']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6e806d-8a85-4291-9fc6-59af355d53c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "escrow_model_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3090fff6-075d-4bdc-acf6-393a00699d96",
   "metadata": {},
   "source": [
    "Store the escrow model URI for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ab7448-525a-4a41-913d-a644e43926e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store escrow_model_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabea137-16b5-48bb-bc31-845fe3f389fd",
   "metadata": {},
   "source": [
    "### Plotting the Train/Loss Curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66fba4e-b634-41e6-92f1-31396f489984",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the CSV files\n",
    "train_df = pd.read_csv('./tmp/train_output/step_wise_training_metrics.csv')\n",
    "#val_df = pd.read_csv('./tmp/train_output/validation_metrics.csv')\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_df['step_number'], train_df['training_loss'], label='Training Loss', color='blue')\n",
    "#plt.plot(val_df['step_number'], val_df['validation_loss'], label='Validation Loss', color='red')\n",
    "\n",
    "plt.xlabel('Step Number')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2169dac-d93e-4c39-9dd3-c17cd57b3bed",
   "metadata": {},
   "source": [
    "### In this notebook we covered how you can fine tune Nova2.0 with Lora SFT recipe on a financial dataset. Move on to next notebook to learn how to evaluate this model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
