{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fedd772",
   "metadata": {},
   "source": [
    "# W2 Form Extraction - Custom Model Evaluation\n",
    "\n",
    "Evaluate the fine-tuned model and compare it against the base model baseline\n",
    "established in notebook 01.\n",
    "\n",
    "In this notebook we will:\n",
    "\n",
    "- Run the fine-tuned model on 100 test samples\n",
    "- Compare accuracy metrics against the base model\n",
    "- Clean up AWS resources (deployment, IAM role and policy)\n",
    "\n",
    "**Prerequisite:** Run `04_deploy_on_bedrock.ipynb` first and ensure the deployment is active."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999422c9",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c4ac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from util import *\n",
    "\n",
    "clients = get_aws_clients()\n",
    "session         = clients[\"session\"]\n",
    "bedrock         = clients[\"bedrock\"]\n",
    "bedrock_runtime = clients[\"bedrock_runtime\"]\n",
    "account_id      = clients[\"account_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff3aa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r bucket_name\n",
    "%store -r test_s3_paths\n",
    "%store -r deployment_arn\n",
    "%store -r role_name\n",
    "%store -r policy_arn\n",
    "%store -r base_eval_results\n",
    "\n",
    "print(f\"Deployment ARN: {deployment_arn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfed158b",
   "metadata": {},
   "source": [
    "## Evaluate Fine-tuned Model (100 test samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aa2c0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running custom model evaluation on 100 test samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model: 100%|██████████| 100/100 [03:19<00:00,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Structured Output (Valid JSON):\n",
      "  Parse success rate: 100.00% (100/100)\n",
      "  Parse failures:     0\n",
      "\n",
      "Overall Field Extraction Accuracy: 91.13%\n",
      "\n",
      "Accuracy by Field Category:\n",
      "  - Employee Information: 92.67%\n",
      "  - Employer Information: 84.33%\n",
      "  - Earnings: 88.71%\n",
      "  - Benefits: 100.00%\n",
      "  - Multi-State Employment: 93.68%\n",
      "  - Other: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_data = build_test_data_in_memory(test_s3_paths, account_id)\n",
    "\n",
    "print(\"Running custom model evaluation on 100 test samples...\")\n",
    "custom_eval_results = evaluate_model_on_test_data(\n",
    "    bedrock_runtime, test_data, 100, deployment_arn\n",
    ")\n",
    "\n",
    "so = custom_eval_results[\"structured_output\"]\n",
    "print(f\"\\nStructured Output (Valid JSON):\")\n",
    "print(f\"  Parse success rate: {so['parse_success_rate']:.2%} ({so['parse_successes']}/{so['total']})\")\n",
    "print(f\"  Parse failures:     {so['parse_failures']}\")\n",
    "\n",
    "print(f\"\\nOverall Field Extraction Accuracy: {custom_eval_results['overall_accuracy']:.2%}\")\n",
    "print(\"\\nAccuracy by Field Category:\")\n",
    "for category, accuracy in custom_eval_results[\"category_accuracies\"].items():\n",
    "    print(f\"  - {category}: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bec421",
   "metadata": {},
   "source": [
    "## Compare Base vs. Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37dbc9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                           Base Model   Fine-tuned  Improvement\n",
      "--------------------------------------------------------------------\n",
      "Structured Output Rate             100.00%     100.00%      +0.00%\n",
      "Overall Accuracy                    51.90%      91.13%     +39.22%\n",
      "\n",
      "Employee Information                60.00%      92.67%     +32.67%\n",
      "Employer Information                48.00%      84.33%     +36.33%\n",
      "Earnings                            42.57%      88.71%     +46.14%\n",
      "Benefits                            50.00%     100.00%     +50.00%\n",
      "Multi-State Employment              62.91%      93.68%     +30.77%\n",
      "Other                                0.00%       0.00%      +0.00%\n"
     ]
    }
   ],
   "source": [
    "base_so   = base_eval_results[\"structured_output\"]\n",
    "custom_so = custom_eval_results[\"structured_output\"]\n",
    "base_acc   = base_eval_results[\"overall_accuracy\"]\n",
    "custom_acc = custom_eval_results[\"overall_accuracy\"]\n",
    "\n",
    "print(f\"{'Metric':<30} {'Base Model':>12} {'Fine-tuned':>12} {'Improvement':>12}\")\n",
    "print(\"-\" * 68)\n",
    "print(f\"{'Structured Output Rate':<30} {base_so['parse_success_rate']:>11.2%} {custom_so['parse_success_rate']:>11.2%} {custom_so['parse_success_rate'] - base_so['parse_success_rate']:>+11.2%}\")\n",
    "print(f\"{'Overall Accuracy':<30} {base_acc:>11.2%} {custom_acc:>11.2%} {custom_acc - base_acc:>+11.2%}\")\n",
    "print()\n",
    "\n",
    "for category in base_eval_results[\"category_accuracies\"]:\n",
    "    b = base_eval_results[\"category_accuracies\"][category]\n",
    "    c = custom_eval_results[\"category_accuracies\"].get(category, 0)\n",
    "    print(f\"{category:<30} {b:>11.2%} {c:>11.2%} {c - b:>+11.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5ee574",
   "metadata": {},
   "source": [
    "## Resource Cleanup\n",
    "\n",
    "Delete the deployment and IAM resources to avoid unnecessary costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f214621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_up(\n",
    "    session,\n",
    "    bedrock,\n",
    "    deployment_arn=deployment_arn,\n",
    "    role_name=role_name,\n",
    "    policy_arn=policy_arn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a924b33-9858-43cb-b75f-d176acced8c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
