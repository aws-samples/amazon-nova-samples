{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0720be9d-2dd5-49d9-9bb4-d1ee7aa030d2",
   "metadata": {},
   "source": [
    "# W2 Form OCR with Amazon Nova Lite - Data Preparation for Fine-tuning\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook demonstrates how to prepare data for fine-tuning Amazon Nova Lite models for OCR tasks, specifically focusing on extracting structured data from scanned W2 tax forms.\n",
    "\n",
    "Scanned tax document OCR presents unique challenges due to the critical importance of accurately extracting numerical values, identifying form fields, and maintaining the semantic structure of the information. Fine-tuning allows our model to specialize in this high-precision extraction task.\n",
    "\n",
    "In this notebook, we'll:\n",
    "\n",
    "- Process a dataset of scanned W2 tax form images\n",
    "- Upload the images to Amazon S3 for processing\n",
    "- Create prompts optimized for OCR extraction of structured tax data\n",
    "- Format the dataset for Amazon Nova Lite model fine-tuning job\n",
    "- Prepare the training, validation, and test datasets for fine-tuning\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before starting, ensure you have:\n",
    "\n",
    "- An AWS account with access to Amazon Bedrock for Amazon Nova Lite model\n",
    "- Appropriate IAM permissions for Bedrock and S3\n",
    "- A working SageMaker environment with the necessary libraries\n",
    "\n",
    "You'll need to create an IAM role with the following permissions:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:PutObject\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::YOUR_BUCKET_NAME\",\n",
    "                \"arn:aws:s3:::YOUR_BUCKET_NAME/*\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"bedrock:CreateModelCustomizationJob\",\n",
    "                \"bedrock:GetModelCustomizationJob\",\n",
    "                \"bedrock:ListModelCustomizationJobs\",\n",
    "                \"bedrock:StopModelCustomizationJob\"\n",
    "            ],\n",
    "            \"Resource\": \"arn:aws:bedrock:us-west-2:YOUR_ACCOUNT_ID:model-customization-job/*\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f6b171-c82e-4348-ab5c-b37b20ab334f",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "First, let's install and import the necessary libraries for working with OCR data and AWS services:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6f7002-28bf-48f0-8c71-2fa834c0bacb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T14:16:20.242077Z",
     "iopub.status.busy": "2025-08-15T14:16:20.241578Z",
     "iopub.status.idle": "2025-08-15T14:16:26.830007Z",
     "shell.execute_reply": "2025-08-15T14:16:26.828620Z",
     "shell.execute_reply.started": "2025-08-15T14:16:20.242044Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "%pip install --upgrade pip\n",
    "%pip install boto3 datasets pillow tqdm ipywidgets deepdiff --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9138744-e0be-4cb7-86bb-c4b988051420",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T14:16:26.835502Z",
     "iopub.status.busy": "2025-08-15T14:16:26.834998Z",
     "iopub.status.idle": "2025-08-15T14:16:26.843723Z",
     "shell.execute_reply": "2025-08-15T14:16:26.842950Z",
     "shell.execute_reply.started": "2025-08-15T14:16:26.835467Z"
    }
   },
   "outputs": [],
   "source": [
    "# Restart kernel to ensure updated packages take effect\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521efe64-84fc-4268-aad2-e486a0fe7e87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T14:16:26.845790Z",
     "iopub.status.busy": "2025-08-15T14:16:26.844990Z",
     "iopub.status.idle": "2025-08-15T14:16:28.060705Z",
     "shell.execute_reply": "2025-08-15T14:16:28.059592Z",
     "shell.execute_reply.started": "2025-08-15T14:16:26.845756Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "import io\n",
    "import uuid\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921e0489-0e61-4567-ad62-06a016256790",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T14:16:28.062657Z",
     "iopub.status.busy": "2025-08-15T14:16:28.062102Z",
     "iopub.status.idle": "2025-08-15T14:16:28.256576Z",
     "shell.execute_reply": "2025-08-15T14:16:28.255673Z",
     "shell.execute_reply.started": "2025-08-15T14:16:28.062619Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set AWS region\n",
    "region = \"us-east-1\"\n",
    "\n",
    "# Create AWS clients\n",
    "session = boto3.session.Session(region_name=region)\n",
    "s3_client = session.client('s3')\n",
    "sts_client = session.client('sts')\n",
    "bedrock = session.client(service_name=\"bedrock\")\n",
    "\n",
    "# Get account ID\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "\n",
    "# Generate bucket name with account ID for uniqueness\n",
    "bucket_name = f\"nova-vision-ft-{account_id}-{region}\"\n",
    "\n",
    "print(f\"Account ID: {account_id}\")\n",
    "print(f\"Bucket name: {bucket_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a542933f-fd17-4a08-925b-107db28b2c7d",
   "metadata": {},
   "source": [
    "## Create S3 Storage for W2 Form Images\n",
    "\n",
    "Let's create an S3 bucket to store our scanned W2 form images and processed OCR data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124b2256-afef-42d8-a8ed-6093201a7947",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T14:16:28.257997Z",
     "iopub.status.busy": "2025-08-15T14:16:28.257657Z",
     "iopub.status.idle": "2025-08-15T14:16:28.362080Z",
     "shell.execute_reply": "2025-08-15T14:16:28.361314Z",
     "shell.execute_reply.started": "2025-08-15T14:16:28.257974Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    if region == 'us-east-1':\n",
    "        s3_client.create_bucket(\n",
    "            Bucket=bucket_name\n",
    "        )\n",
    "    else:\n",
    "        # For all other regions, specify the LocationConstraint\n",
    "        s3_client.create_bucket(\n",
    "            Bucket=bucket_name,\n",
    "            CreateBucketConfiguration={'LocationConstraint': region}\n",
    "        )\n",
    "    print(f\"Bucket {bucket_name} created successfully\")\n",
    "except s3_client.exceptions.BucketAlreadyExists:\n",
    "    print(f\"Bucket {bucket_name} already exists\")\n",
    "except s3_client.exceptions.BucketAlreadyOwnedByYou:\n",
    "    print(f\"Bucket {bucket_name} already owned by you\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating bucket: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d8d040-56e6-4f67-8e3c-445bd0750e53",
   "metadata": {},
   "source": [
    "## Download and Prepare the W2 Form Dataset\n",
    "\n",
    "For this OCR fine-tuning task, we'll use a dataset of scanned W2 tax forms from Hugging Face. These forms contain structured tax information that we want our model to accurately extract. We'll use 1800 samples for training, 100 for validation, and 100 for testing to ensure the model learns to recognize diverse form layouts and handwriting styles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aed5d4-1494-40a0-84b4-9fb064efa294",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #FFFFCC; color: #856404; padding: 15px; border-left: 6px solid #FFD700; margin-bottom: 15px;\">\n",
    "<h3 style=\"margin-top: 0; color: #856404;\">⚠️ W2 Form Dataset Processing</h3>\n",
    "<p>This cell downloads the synthetic W2 tax form dataset which:</p>\n",
    "<ul>\n",
    "  <li>Contains <b>2,000 scanned W2 form images</b> with synthetic but realistic tax data</li>\n",
    "  <li>May take <b>5-10 minutes</b> to download and process depending on your connection</li>\n",
    "  <li>Requires sufficient disk space for storing high-resolution document scans</li>\n",
    "  <li>Contains sensitive (though synthetic) information resembling real tax forms</li>\n",
    "</ul>\n",
    "<p>This dataset is specifically designed for training OCR models on structured tax document extraction tasks.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd63e2b5-0255-4e3e-bdf4-f12a1d89f828",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T14:16:28.363571Z",
     "iopub.status.busy": "2025-08-15T14:16:28.363245Z",
     "iopub.status.idle": "2025-08-15T14:16:29.615258Z",
     "shell.execute_reply": "2025-08-15T14:16:29.614301Z",
     "shell.execute_reply.started": "2025-08-15T14:16:28.363547Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create directories to store images and metadata\n",
    "os.makedirs('ocr_images/train', exist_ok=True)\n",
    "os.makedirs('ocr_images/val', exist_ok=True)\n",
    "os.makedirs('ocr_images/test', exist_ok=True)\n",
    "\n",
    "\n",
    "# Select a subset for our fine-tuning task\n",
    "# We want 1200 examples total (1000 train, 100 val, 100 test)\n",
    "train_data = load_dataset(\"singhsays/fake-w2-us-tax-form-dataset\", split=\"train\")\n",
    "val_data = load_dataset(\"singhsays/fake-w2-us-tax-form-dataset\", split=\"validation\")\n",
    "test_data = load_dataset(\"singhsays/fake-w2-us-tax-form-dataset\", split=\"test\")\n",
    "\n",
    "\n",
    "print(f\"\\nNumber of training examples: {len(train_data)}\")\n",
    "print(f\"Number of validation examples: {len(val_data)}\")\n",
    "print(f\"Number of test examples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead76317-fe8e-4a48-bfec-c0090f7bb2b1",
   "metadata": {},
   "source": [
    "## Upload W2 Form Images to S3\n",
    "\n",
    "Now, let's upload the scanned W2 form images to S3 for processing by our OCR model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6951fdfc-fdc9-4630-800b-1b01f887bd7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T14:16:29.617964Z",
     "iopub.status.busy": "2025-08-15T14:16:29.617414Z",
     "iopub.status.idle": "2025-08-15T14:20:58.558167Z",
     "shell.execute_reply": "2025-08-15T14:20:58.557366Z",
     "shell.execute_reply.started": "2025-08-15T14:16:29.617940Z"
    }
   },
   "outputs": [],
   "source": [
    "def upload_images_to_s3(dataset, subset):\n",
    "    \"\"\"Upload images to S3 and return paths\"\"\"\n",
    "    print(f\"Uploading {subset} images to S3...\")\n",
    "    \n",
    "    s3_paths = []\n",
    "    \n",
    "    for i, item in enumerate(tqdm(dataset)):\n",
    "        try:\n",
    "            # Get image from dataset\n",
    "            image = item['image']\n",
    "            image_format = image.format if hasattr(image, 'format') else 'jpeg'\n",
    "            \n",
    "            # Convert image to bytes\n",
    "            with io.BytesIO() as buffer:\n",
    "                image.save(buffer, format=image_format)\n",
    "                image_bytes = buffer.getvalue()\n",
    "\n",
    "            # Define S3 path for this image\n",
    "            s3_key = f\"ocr_images/{subset}/img_{i}.{image_format.lower()}\"\n",
    "            \n",
    "            # Upload image to S3\n",
    "            s3_client.put_object(Bucket=bucket_name, Key=s3_key, Body=image_bytes)\n",
    "            \n",
    "            # Store S3 URI for later use\n",
    "            s3_uri = f\"s3://{bucket_name}/{s3_key}\"\n",
    "            \n",
    "            # Save metadata about this image\n",
    "            s3_paths.append({\n",
    "                'index': i,\n",
    "                's3_uri': s3_uri,\n",
    "                'gt': item[\"ground_truth\"]\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error uploading image {i}: {e}\")\n",
    "    \n",
    "    return s3_paths\n",
    "\n",
    "# Upload images to S3\n",
    "train_s3_paths = upload_images_to_s3(train_data, 'train')\n",
    "val_s3_paths = upload_images_to_s3(val_data, 'val')\n",
    "test_s3_paths = upload_images_to_s3(test_data, 'test')\n",
    "\n",
    "print(f\"Uploaded {len(train_s3_paths)} training images\")\n",
    "print(f\"Uploaded {len(val_s3_paths)} validation images\")\n",
    "print(f\"Uploaded {len(test_s3_paths)} test images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c2c66c-6f05-437a-966b-747e5000c906",
   "metadata": {},
   "source": [
    "## Format W2 Data for OCR Model Fine-tuning\n",
    "\n",
    "Let's prepare the tax form data in the required format for Bedrock Amazon Nova Lite OCR fine-tuning. The goal is to teach the model to extract structured information from tax forms into consistent JSON format:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2230f6-8f59-4039-b2d9-105ed5fb70b8",
   "metadata": {},
   "source": [
    "### Convert the ground truth data into the schema we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dadb407-33c7-499c-9f06-61c0556b1fcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T14:20:58.559817Z",
     "iopub.status.busy": "2025-08-15T14:20:58.559484Z",
     "iopub.status.idle": "2025-08-15T14:20:58.566703Z",
     "shell.execute_reply": "2025-08-15T14:20:58.565750Z",
     "shell.execute_reply.started": "2025-08-15T14:20:58.559787Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_schema(original):\n",
    "    # Create employee section\n",
    "    employee = {\n",
    "          \"name\": original[\"box_e_employee_name\"],\n",
    "          \"address\": f\"{original['box_e_employee_street_address']}, {original['box_e_employee_city_state_zip']}\",\n",
    "          \"socialSecurityNumber\": original[\"box_a_employee_ssn\"]\n",
    "      }\n",
    "\n",
    "    # Create employer section\n",
    "    employer = {\n",
    "          \"name\": original[\"box_c_employer_name\"],\n",
    "          \"ein\": original[\"box_b_employer_identification_number\"],\n",
    "          \"address\": f\"{original['box_c_employer_street_address']}, {original['box_c_employer_city_state_zip']}\"\n",
    "      }\n",
    "\n",
    "    # Create earnings section\n",
    "    earnings = {\n",
    "          \"wages\": original[\"box_1_wages\"],\n",
    "          \"socialSecurityWages\": original[\"box_3_social_security_wages\"],\n",
    "          \"medicareWagesAndTips\": original[\"box_5_medicare_wages\"],\n",
    "          \"federalIncomeTaxWithheld\": original[\"box_2_federal_tax_withheld\"],\n",
    "          \"stateIncomeTax\": original[\"box_17_1_state_income_tax\"] + original[\"box_17_2_state_income_tax\"],\n",
    "          \"localWagesTips\": original[\"box_18_1_local_wages\"],\n",
    "          \"localIncomeTax\": original[\"box_19_1_local_income_tax\"]\n",
    "      }\n",
    "\n",
    "    # Create benefits section\n",
    "    benefits = {\n",
    "          \"dependentCareBenefits\": original[\"box_10_dependent_care_benefits\"],\n",
    "          \"nonqualifiedPlans\": original[\"box_11_nonqualified_plans\"]\n",
    "      }\n",
    "\n",
    "    # Create multiStateEmployment section\n",
    "    multiStateEmployment = {\n",
    "          original[\"box_15_1_state\"]: {\n",
    "              \"localWagesTips\": original[\"box_18_1_local_wages\"],\n",
    "              \"localIncomeTax\": original[\"box_19_1_local_income_tax\"],\n",
    "              \"localityName\": original[\"box_20_1_locality\"]\n",
    "          },\n",
    "          original[\"box_15_2_state\"]: {\n",
    "              \"localWagesTips\": original[\"box_18_2_local_wages\"],\n",
    "              \"localIncomeTax\": original[\"box_19_2_local_income_tax\"],\n",
    "              \"localityName\": original[\"box_20_2_locality\"]\n",
    "          }\n",
    "      }\n",
    "\n",
    "    # Combine all sections\n",
    "    return {\n",
    "          \"employee\": employee,\n",
    "          \"employer\": employer,\n",
    "          \"earnings\": earnings,\n",
    "          \"benefits\": benefits,\n",
    "          \"multiStateEmployment\": multiStateEmployment\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0dede7-8ab2-4b41-8717-43465500b92a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T14:20:58.568378Z",
     "iopub.status.busy": "2025-08-15T14:20:58.567890Z",
     "iopub.status.idle": "2025-08-15T14:20:58.575385Z",
     "shell.execute_reply": "2025-08-15T14:20:58.574372Z",
     "shell.execute_reply.started": "2025-08-15T14:20:58.568343Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_gt_data = transform_schema(json.loads(test_s3_paths[0].get(\"gt\"))[\"gt_parse\"])\n",
    "sample_gt_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08052bd3-8e1b-42bf-94a2-e87f51175507",
   "metadata": {},
   "source": [
    "## Base model inference\n",
    "\n",
    "Before fine-tuning, let's try inference with the base model and get familiar with the API syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f92caa9-9df0-4fc2-9f67-036fea1a18d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T14:20:58.577180Z",
     "iopub.status.busy": "2025-08-15T14:20:58.576497Z",
     "iopub.status.idle": "2025-08-15T14:20:58.582804Z",
     "shell.execute_reply": "2025-08-15T14:20:58.581760Z",
     "shell.execute_reply.started": "2025-08-15T14:20:58.577145Z"
    }
   },
   "outputs": [],
   "source": [
    "text_prompt=\"\"\"\n",
    "Analyze above W2 form, extracting all fields and bounding boxes, and return the data as a JSON object. \n",
    "Focus on capturing each field as labeled on the form, and be especially precise with multi-state information. \n",
    "For each field, ensure the following:\n",
    "\n",
    "1. **Employee Information**: Extract 'Employee Name,' 'Employee Address,' 'Social Security Number,' etc.\n",
    "2. **Employer Information**: Include 'Employer Name,' 'Employer EIN,' 'Employer Address,' and 'Zip Code.'\n",
    "3. **Earnings and Tax Information**: Extract 'Wages,' 'Social Security Wages,' 'Medicare Wages and Tips,' 'Federal Income Tax Withheld,' 'State Income Tax,' 'Local Wages / Tips,' 'Local Income Tax,' etc.\n",
    "4. **Benefits and Other Deductions**: Include fields like 'Dependent Care Benefits' and 'Nonqualified Plans.'\n",
    "5. **Multi-state Employment Information**: Identify all states listed on the W2, capturing information for each:\n",
    "    - Ensure each state's data is complete and correct, including 'Local Wages / Tips,' 'Local Income Tax,' and 'Locality Name.'\n",
    "    - Each state's information should be grouped under its abbreviation (e.g., \"NC\", \"UT\").\n",
    "\n",
    "The JSON output should precisely reflect all information, especially multiple states, with each state’s information grouped under its corresponding abbreviation. Here is a one-shot example for structure:\n",
    "```json\n",
    "                {\n",
    "                    \"employee\": {\n",
    "                        \"name\": \"Ann Hill\",\n",
    "                        \"address\": \"39572 Jack Trail Apt. 308, New Sarahside, MN 56848-7193\",\n",
    "                        \"socialSecurityNumber\": \"192-67-3262\"\n",
    "                    },\n",
    "                    \"employer\": {\n",
    "                        \"name\": \"Bryant Ltd Group\",\n",
    "                        \"ein\": \"06-6105986\",\n",
    "                        \"address\": \"82582 William Cape Suite 370, Scottside, ND 93090-3134\"\n",
    "                    },\n",
    "                    \"earnings\": {\n",
    "                        \"wages\": 238111.55,\n",
    "                        \"socialSecurityWages\": 309486.28,\n",
    "                        \"medicareWagesAndTips\": 205695.97,\n",
    "                        \"federalIncomeTaxWithheld\": 71007.86,\n",
    "                        \"stateIncomeTax\": 399.0,\n",
    "                        \"localWagesTips\": 5965.18,\n",
    "                        \"localIncomeTax\": 399.0\n",
    "                    },\n",
    "                    \"benefits\": {\n",
    "                        \"dependentCareBenefits\": 198,\n",
    "                        \"nonqualifiedPlans\": 7053\n",
    "                    },\n",
    "                    \"multiStateEmployment\": {\n",
    "                        \"NC\": {\n",
    "                            \"localWagesTips\": 287711.19,\n",
    "                            \"localIncomeTax\": 46607.9,\n",
    "                            \"localityName\": \"Millier Oval\"\n",
    "                        },\n",
    "                        \"UT\": {\n",
    "                            \"localWagesTips\": 301013.17,\n",
    "                            \"localIncomeTax\": 24688.05,\n",
    "                            \"localityName\": \"Gomez Covas\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ac1720-e269-41c4-aa18-580fbed60254",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T14:20:58.584904Z",
     "iopub.status.busy": "2025-08-15T14:20:58.584470Z",
     "iopub.status.idle": "2025-08-15T14:20:58.590315Z",
     "shell.execute_reply": "2025-08-15T14:20:58.589543Z",
     "shell.execute_reply.started": "2025-08-15T14:20:58.584869Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_w2(s3_uri):\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"image\": {\n",
    "                    \"format\": \"png\",\n",
    "                    \"source\": {\n",
    "                        \"s3Location\": {\n",
    "                            \"uri\": s3_uri,\n",
    "                            \"bucketOwner\" : account_id\n",
    "                        }\n",
    "                    }\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"text\": text_prompt\n",
    "\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [\n",
    "                {\"text\": \"```json\"}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f089d59-8682-4990-ac43-078e283bdb65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T14:20:58.591820Z",
     "iopub.status.busy": "2025-08-15T14:20:58.591191Z",
     "iopub.status.idle": "2025-08-15T14:21:04.033985Z",
     "shell.execute_reply": "2025-08-15T14:21:04.032863Z",
     "shell.execute_reply.started": "2025-08-15T14:20:58.591785Z"
    }
   },
   "outputs": [],
   "source": [
    "bedrock_client = boto3.client(\"bedrock-runtime\", region_name=\"us-east-1\")\n",
    "nova_lite_id = \"us.amazon.nova-lite-v1:0\"\n",
    "\n",
    "response = bedrock_client.converse(\n",
    "            modelId=nova_lite_id,\n",
    "            messages=process_w2(test_s3_paths[0].get(\"s3_uri\")),\n",
    "            inferenceConfig={\"maxTokens\": 2048, \"temperature\": 0.0, \"topP\": 0.1, \"stopSequences\": [\"```\"]},\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4c1899-37cb-4e09-bb3a-32648cc6bfb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T14:21:04.036170Z",
     "iopub.status.busy": "2025-08-15T14:21:04.035530Z",
     "iopub.status.idle": "2025-08-15T14:21:04.041746Z",
     "shell.execute_reply": "2025-08-15T14:21:04.040999Z",
     "shell.execute_reply.started": "2025-08-15T14:21:04.036135Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction = json.loads(response[\"output\"][\"message\"][\"content\"][0][\"text\"].replace(\"```\", \"\"))\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890ef813-d367-4a27-b912-5e0967c502a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T14:21:04.044543Z",
     "iopub.status.busy": "2025-08-15T14:21:04.043981Z",
     "iopub.status.idle": "2025-08-15T14:21:04.145585Z",
     "shell.execute_reply": "2025-08-15T14:21:04.144789Z",
     "shell.execute_reply.started": "2025-08-15T14:21:04.044518Z"
    }
   },
   "outputs": [],
   "source": [
    "from deepdiff import DeepDiff\n",
    "diff = DeepDiff(sample_gt_data, prediction, ignore_order=True)\n",
    "diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9b7efa-f1f3-4a1e-ae7e-0c18fe268b5a",
   "metadata": {},
   "source": [
    "## Prepare dataset for Fine-tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b78d50-264d-405e-843d-ca676624ed5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T14:21:04.146801Z",
     "iopub.status.busy": "2025-08-15T14:21:04.146461Z",
     "iopub.status.idle": "2025-08-15T14:21:04.301012Z",
     "shell.execute_reply": "2025-08-15T14:21:04.300133Z",
     "shell.execute_reply.started": "2025-08-15T14:21:04.146770Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_jsonl_entry(item, s3_uri):\n",
    "    \"\"\"Create a JSONL entry in the Bedrock conversation schema format\"\"\"\n",
    "    \n",
    "    # Extract conversation components\n",
    "    gt = transform_schema(item[\"gt_parse\"])\n",
    "    \n",
    "    # Create entry in the required format\n",
    "    return {\n",
    "        \"schemaVersion\": \"bedrock-conversation-2024\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"text\": text_prompt\n",
    "                    },\n",
    "                    {\n",
    "                        \"image\": {\n",
    "                            \"format\": \"png\",\n",
    "                            \"source\": {\n",
    "                                \"s3Location\": {\n",
    "                                    \"uri\": s3_uri,\n",
    "                                    \"bucketOwner\": account_id\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"text\": f\"```json\\n{json.dumps(gt)}\\n```\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def prepare_dataset_jsonl(s3_paths, output_file):\n",
    "    \"\"\"Prepare dataset in JSONL format for fine-tuning\"\"\"\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        for item in s3_paths:\n",
    "            # Create JSONL entry\n",
    "            entry = create_jsonl_entry(json.loads(item['gt']), item['s3_uri'])\n",
    "            \n",
    "            # Write to file\n",
    "            f.write(json.dumps(entry) + '\\n')\n",
    "    \n",
    "    print(f\"Created {output_file} with {len(s3_paths)} samples\")\n",
    "\n",
    "# Prepare JSONL files\n",
    "prepare_dataset_jsonl(train_s3_paths, 'train.jsonl')\n",
    "prepare_dataset_jsonl(val_s3_paths, 'validation.jsonl')\n",
    "prepare_dataset_jsonl(test_s3_paths, 'test.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a50119a-37d5-4043-a4e7-4bce5ab4283e",
   "metadata": {},
   "source": [
    "## Upload OCR Training Data to S3\n",
    "\n",
    "Let's upload our prepared JSONL files containing W2 form images and structured extraction targets to S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f1b3ed-ea71-4648-a6f3-0bfe40d5e13b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T14:21:04.302713Z",
     "iopub.status.busy": "2025-08-15T14:21:04.302160Z",
     "iopub.status.idle": "2025-08-15T14:21:04.610090Z",
     "shell.execute_reply": "2025-08-15T14:21:04.609124Z",
     "shell.execute_reply.started": "2025-08-15T14:21:04.302682Z"
    }
   },
   "outputs": [],
   "source": [
    "# Upload JSONL files to S3\n",
    "s3_client.upload_file('train.jsonl', bucket_name, 'data/train.jsonl')\n",
    "s3_client.upload_file('validation.jsonl', bucket_name, 'data/validation.jsonl')\n",
    "s3_client.upload_file('test.jsonl', bucket_name, 'data/test.jsonl')\n",
    "\n",
    "# Store S3 URIs for later use\n",
    "train_data_uri = f\"s3://{bucket_name}/data/train.jsonl\"\n",
    "validation_data_uri = f\"s3://{bucket_name}/data/validation.jsonl\"\n",
    "test_data_uri = f\"s3://{bucket_name}/data/test.jsonl\"\n",
    "\n",
    "print(f\"Training data URI: {train_data_uri}\")\n",
    "print(f\"Validation data URI: {validation_data_uri}\")\n",
    "print(f\"Test data URI: {test_data_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f0dc50-5487-4c76-b58a-b9b8474d171e",
   "metadata": {},
   "source": [
    "## Create IAM Role for OCR Model Fine-tuning\n",
    "Let's create an IAM role with the necessary permissions for fine-tuning our W2 form OCR model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93714a5-7870-4d34-87c8-5c7de5cd5de3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T14:21:04.611386Z",
     "iopub.status.busy": "2025-08-15T14:21:04.611053Z",
     "iopub.status.idle": "2025-08-15T14:21:14.899101Z",
     "shell.execute_reply": "2025-08-15T14:21:14.898253Z",
     "shell.execute_reply.started": "2025-08-15T14:21:04.611362Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate policy documents\n",
    "trust_policy_doc = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"bedrock.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRole\",\n",
    "            \"Condition\": {\n",
    "                \"StringEquals\": {\n",
    "                    \"aws:SourceAccount\": account_id\n",
    "                },\n",
    "                \"ArnLike\": {\n",
    "                    \"aws:SourceArn\": f\"arn:aws:bedrock:{region}:{account_id}:model-customization-job/*\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "access_policy_doc = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:PutObject\",\n",
    "                \"s3:ListBucket\",\n",
    "                \"s3:GetBucketLocation\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                f\"arn:aws:s3:::{bucket_name}\",\n",
    "                f\"arn:aws:s3:::{bucket_name}/*\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "# Create IAM client\n",
    "iam = session.client('iam')\n",
    "\n",
    "# Role name for fine-tuning\n",
    "role_name = f\"NovaVisionFineTuningRole-{int(time.time())}\"\n",
    "policy_name = f\"NovaVisionFineTuningPolicy-{int(time.time())}\"\n",
    "\n",
    "# Create role\n",
    "try:\n",
    "    response = iam.create_role(\n",
    "        RoleName=role_name,\n",
    "        AssumeRolePolicyDocument=json.dumps(trust_policy_doc),\n",
    "        Description=\"Role for fine-tuning Nova vision model with Amazon Bedrock\"\n",
    "    )\n",
    "    \n",
    "    role_arn = response[\"Role\"][\"Arn\"]\n",
    "    print(f\"Created role: {role_arn}\")\n",
    "    \n",
    "    # Create policy\n",
    "    response = iam.create_policy(\n",
    "        PolicyName=policy_name,\n",
    "        PolicyDocument=json.dumps(access_policy_doc)\n",
    "    )\n",
    "    \n",
    "    policy_arn = response[\"Policy\"][\"Arn\"]\n",
    "    print(f\"Created policy: {policy_arn}\")\n",
    "    \n",
    "    # Attach policy to role\n",
    "    iam.attach_role_policy(\n",
    "        RoleName=role_name,\n",
    "        PolicyArn=policy_arn\n",
    "    )\n",
    "    \n",
    "    print(f\"Attached policy to role\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error creating IAM resources: {e}\")\n",
    "\n",
    "# Allow time for IAM role propagation\n",
    "print(\"Waiting for IAM role to propagate...\")\n",
    "time.sleep(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c980d52-e78b-4873-9f95-59f5a19e5602",
   "metadata": {},
   "source": [
    "## Save Variables for Fine-tuning\n",
    "Let's save the important variables we'll need in the next notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2092f97-9043-40cf-8171-8b8f0862a8eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T14:21:14.900562Z",
     "iopub.status.busy": "2025-08-15T14:21:14.900294Z",
     "iopub.status.idle": "2025-08-15T14:21:14.914304Z",
     "shell.execute_reply": "2025-08-15T14:21:14.913425Z",
     "shell.execute_reply.started": "2025-08-15T14:21:14.900540Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store variables for the next notebook\n",
    "%store bucket_name\n",
    "%store train_data_uri\n",
    "%store validation_data_uri\n",
    "%store test_data_uri\n",
    "%store role_arn\n",
    "%store role_name\n",
    "%store policy_arn\n",
    "%store text_prompt\n",
    "%store test_s3_paths\n",
    "%store account_id\n",
    "\n",
    "print(\"Variables saved for use in the next notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e18555-b448-4556-869a-2a3940e98d24",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we prepared the data needed for fine-tuning a specialized OCR model for W2 tax form extraction. We:\n",
    "\n",
    "- Processed a dataset of scanned W2 tax forms with structured information\n",
    "- Uploaded the form images to S3 for model training\n",
    "- Developed prompts specifically designed for tax document OCR extraction\n",
    "- Created training data for fine-tuning Nova Lite\n",
    "- Set up the necessary IAM roles and permissions for the fine-tuning process"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
