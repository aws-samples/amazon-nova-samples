{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Multi-Agent Multimodal Reasoning with Nova 2 Omni\n",
    "\n",
    "This notebook demonstrates multi-agent patterns for multimodal reasoning using Amazon Nova 2 Omni. We use direct boto3 calls with reasoning configuration and implement agent coordination patterns.\n",
    "\n",
    "**Key Features:**\n",
    "- Multi-agent orchestration patterns\n",
    "- Specialized agents for different modalities\n",
    "- Direct boto3 calls with reasoning configuration\n",
    "- Agent coordination and result synthesis\n",
    "\n",
    "**Note:** This notebook demonstrates multi-agent patterns without requiring the Strands framework.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "from typing import Literal\n",
    "from botocore.config import Config\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "import nova_utils\n",
    "\n",
    "MODEL_ID = \"us.amazon.nova-2-omni-v1:0\"\n",
    "REGION_ID = \"us-west-2\"\n",
    "\n",
    "def get_bedrock_runtime():\n",
    "    config = Config(read_timeout=2 * 60)\n",
    "    return boto3.client(\n",
    "        service_name=\"bedrock-runtime\",\n",
    "        region_name=REGION_ID,\n",
    "        config=config\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tools-definition",
   "metadata": {},
   "source": [
    "## Define Agent Tools\n",
    "\n",
    "Create tools for agents to submit their findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-tools",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SafetyAssessmentResult(BaseModel):\n",
    "    \"\"\"Schema for safety assessment results.\"\"\"\n",
    "    identified_hazards: list[str] = Field(description=\"List of hazards identified\")\n",
    "    risk_level: Literal[\"low\", \"medium\", \"high\", \"critical\"] = Field(description=\"Overall risk level\")\n",
    "    recommended_actions: list[str] = Field(description=\"Recommended safety actions\")\n",
    "\n",
    "@tool(args_schema=SafetyAssessmentResult)\n",
    "def submit_safety_assessment(identified_hazards: list[str], risk_level: str, recommended_actions: list[str]) -> dict:\n",
    "    \"\"\"Submit safety assessment results.\"\"\"\n",
    "    return {\n",
    "        \"agent\": \"safety_analyzer\",\n",
    "        \"hazards\": identified_hazards,\n",
    "        \"risk_level\": risk_level,\n",
    "        \"actions\": recommended_actions\n",
    "    }\n",
    "\n",
    "class ComprehensiveReport(BaseModel):\n",
    "    \"\"\"Schema for comprehensive report.\"\"\"\n",
    "    summary: str = Field(description=\"Overall summary of findings\")\n",
    "    key_insights: list[str] = Field(description=\"Key insights from all agents\")\n",
    "    recommendations: list[str] = Field(description=\"Final recommendations\")\n",
    "\n",
    "@tool(args_schema=ComprehensiveReport)\n",
    "def submit_comprehensive_report(summary: str, key_insights: list[str], recommendations: list[str]) -> dict:\n",
    "    \"\"\"Submit comprehensive report synthesizing all agent findings.\"\"\"\n",
    "    return {\n",
    "        \"agent\": \"coordinator\",\n",
    "        \"summary\": summary,\n",
    "        \"insights\": key_insights,\n",
    "        \"recommendations\": recommendations\n",
    "    }\n",
    "\n",
    "def langchain_tool_to_bedrock(lc_tool):\n",
    "    schema = lc_tool.args_schema.model_json_schema()\n",
    "    return {\n",
    "        \"toolSpec\": {\n",
    "            \"name\": lc_tool.name,\n",
    "            \"description\": lc_tool.description,\n",
    "            \"inputSchema\": {\"json\": schema}\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agent-class",
   "metadata": {},
   "source": [
    "## Define Agent Class\n",
    "\n",
    "Create a simple agent class using direct boto3 calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalAgent:\n",
    "    \"\"\"Agent using direct boto3 calls with reasoning.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, system_prompt: str, tools: list, reasoning_effort: str = \"medium\"):\n",
    "        self.name = name\n",
    "        self.system_prompt = system_prompt\n",
    "        self.bedrock_tools = [langchain_tool_to_bedrock(t) for t in tools]\n",
    "        self.reasoning_effort = reasoning_effort\n",
    "        self.bedrock = get_bedrock_runtime()\n",
    "    \n",
    "    def analyze(self, content: list) -> dict:\n",
    "        \"\"\"Analyze content and return results.\"\"\"\n",
    "        request = {\n",
    "            \"modelId\": MODEL_ID,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": content\n",
    "                }\n",
    "            ],\n",
    "            \"system\": [{\"text\": self.system_prompt}],\n",
    "            \"toolConfig\": {\"tools\": self.bedrock_tools},\n",
    "            \"additionalModelRequestFields\": {\n",
    "                \"reasoningConfig\": {\n",
    "                    \"type\": \"enabled\",\n",
    "                    \"maxReasoningEffort\": self.reasoning_effort\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        response = self.bedrock.converse(**request)\n",
    "        return response\n",
    "\n",
    "safety_agent = MultimodalAgent(\n",
    "    name=\"SafetyAnalyzer\",\n",
    "    system_prompt=\"You are a safety assessment expert. Analyze images for hazards, evaluate risk levels, and recommend safety actions. Use submit_safety_assessment to report findings.\",\n",
    "    tools=[submit_safety_assessment],\n",
    "    reasoning_effort=\"high\"\n",
    ")\n",
    "\n",
    "coordinator_agent = MultimodalAgent(\n",
    "    name=\"Coordinator\",\n",
    "    system_prompt=\"You synthesize analyses from multiple agents. Review findings and provide comprehensive report. Use submit_comprehensive_report.\",\n",
    "    tools=[submit_comprehensive_report],\n",
    "    reasoning_effort=\"high\"\n",
    ")\n",
    "\n",
    "print(\"✅ Agents initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orchestrator",
   "metadata": {},
   "source": [
    "## Multi-Agent Orchestrator\n",
    "\n",
    "Coordinate multiple agents for collaborative reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-orchestrator",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiAgentOrchestrator:\n",
    "    \"\"\"Orchestrates multiple agents.\"\"\"\n",
    "    \n",
    "    def __init__(self, agents: dict, coordinator: MultimodalAgent):\n",
    "        self.agents = agents\n",
    "        self.coordinator = coordinator\n",
    "    \n",
    "    def run(self, tasks: dict) -> dict:\n",
    "        \"\"\"Run agents and synthesize results.\"\"\"\n",
    "        agent_results = {}\n",
    "        \n",
    "        for agent_name, task_content in tasks.items():\n",
    "            if agent_name in self.agents:\n",
    "                print(f\"\\n=== Running {agent_name} ===\")\n",
    "                agent = self.agents[agent_name]\n",
    "                response = agent.analyze(task_content)\n",
    "                \n",
    "                for content in response[\"output\"][\"message\"][\"content\"]:\n",
    "                    if \"toolUse\" in content:\n",
    "                        agent_results[agent_name] = content[\"toolUse\"][\"input\"]\n",
    "                        print(f\"Results: {json.dumps(agent_results[agent_name], indent=2)}\")\n",
    "        \n",
    "        print(\"\\n=== Running Coordinator ===\")\n",
    "        synthesis_prompt = f\"\"\"Synthesize these analyses:\n",
    "\n",
    "{json.dumps(agent_results, indent=2)}\n",
    "\n",
    "Provide final answer integrating all findings.\"\"\"\n",
    "        \n",
    "        coordinator_response = self.coordinator.analyze([{\"text\": synthesis_prompt}])\n",
    "        \n",
    "        for content in coordinator_response[\"output\"][\"message\"][\"content\"]:\n",
    "            if \"toolUse\" in content:\n",
    "                final_result = content[\"toolUse\"][\"input\"]\n",
    "                print(f\"Final Answer: {json.dumps(final_result, indent=2)}\")\n",
    "                return final_result\n",
    "        \n",
    "        return {\"error\": \"No final answer\"}\n",
    "\n",
    "orchestrator = MultiAgentOrchestrator(\n",
    "    agents={\"safety\": safety_agent},\n",
    "    coordinator=coordinator_agent\n",
    ")\n",
    "print(\"✅ Orchestrator initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example: Multi-Agent Image Analysis\n",
    "\n",
    "Use multiple agents to analyze an image collaboratively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "image-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "image_path = \"media/man_crossing_street.png\"\n",
    "image_bytes, image_format = nova_utils.load_image_as_bytes(image_path)\n",
    "\n",
    "tasks = {\n",
    "    \"safety\": [\n",
    "        {\"image\": {\"format\": image_format, \"source\": {\"bytes\": image_bytes}}},\n",
    "        {\"text\": \"Analyze this image for safety risks. Identify all hazards, evaluate the overall risk level, and recommend appropriate safety actions.\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"=== Starting Multi-Agent Analysis ===\")\n",
    "result = orchestrator.run(tasks)\n",
    "\n",
    "print(\"\\n=== Final Synthesized Result ===\")\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **Multi-Agent Patterns**: Coordinate specialized agents for complex tasks\n",
    "- **Direct boto3 Calls**: Enable reasoning configuration with additionalModelRequestFields\n",
    "- **Agent Specialization**: Agents focus on specific modalities or tasks\n",
    "- **Result Synthesis**: Coordinator agent integrates findings from all agents\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Add more specialized agents for different modalities\n",
    "- Implement voting mechanisms for consensus\n",
    "- Build custom orchestration patterns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
