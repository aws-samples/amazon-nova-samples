{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# LangChain Integration with Nova 2 Omni - Multimodal Reasoning\n",
    "\n",
    "This notebook demonstrates how to use Amazon Nova 2 Omni with LangChain tool definitions and direct boto3 calls for reasoning. We combine LangChain's tool schema with boto3's Bedrock API to enable reasoning configuration.\n",
    "\n",
    "**Key Features:**\n",
    "- Multimodal input processing (image, video, audio)\n",
    "- Reasoning effort configuration (low, medium, high)\n",
    "- LangChain tool definitions with Pydantic schemas\n",
    "- Direct boto3 calls for full API control\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install langchain langchain-aws -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import base64\n",
    "import boto3\n",
    "from typing import Literal\n",
    "from botocore.config import Config\n",
    "from botocore.exceptions import ClientError\n",
    "from langchain_core.tools import tool\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import nova_utils\n",
    "\n",
    "MODEL_ID = \"us.amazon.nova-2-omni-v1:0\"\n",
    "REGION_ID = \"us-west-2\"\n",
    "\n",
    "def get_bedrock_runtime():\n",
    "    config = Config(read_timeout=2 * 60)\n",
    "    return boto3.client(\n",
    "        service_name=\"bedrock-runtime\",\n",
    "        region_name=REGION_ID,\n",
    "        config=config\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tool-definition",
   "metadata": {},
   "source": [
    "## Define Tools with LangChain\n",
    "\n",
    "Use LangChain to define tool schemas, then convert them to Bedrock format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-tool",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SafetyAssessmentInput(BaseModel):\n",
    "    \"\"\"Input schema for safety risk assessment.\"\"\"\n",
    "    identified_hazards: list[str] = Field(description=\"List of potential hazards or risks\")\n",
    "    risk_level: Literal[\"low\", \"medium\", \"high\", \"critical\"] = Field(\n",
    "        description=\"Overall risk level assessment\"\n",
    "    )\n",
    "    recommended_actions: list[str] = Field(\n",
    "        description=\"List of recommended safety actions or precautions\"\n",
    "    )\n",
    "\n",
    "@tool(args_schema=SafetyAssessmentInput)\n",
    "def assess_safety_risks(identified_hazards: list[str], risk_level: str, recommended_actions: list[str]) -> dict:\n",
    "    \"\"\"Assess safety risks and hazards in a scene or situation.\n",
    "    \n",
    "    Use this tool to identify potential dangers, evaluate risk levels,\n",
    "    and recommend appropriate safety measures or precautions.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"status\": \"assessment_complete\",\n",
    "        \"hazards\": identified_hazards,\n",
    "        \"risk_level\": risk_level,\n",
    "        \"actions\": recommended_actions\n",
    "    }\n",
    "\n",
    "class RecipeExtractionInput(BaseModel):\n",
    "    \"\"\"Input schema for extracting recipe information.\"\"\"\n",
    "    dish_name: str = Field(description=\"Name of the dish being prepared\")\n",
    "    ingredients: list[str] = Field(description=\"List of ingredients used\")\n",
    "    steps: list[str] = Field(description=\"Ordered list of preparation steps\")\n",
    "    cooking_time: str = Field(description=\"Estimated total cooking time\")\n",
    "    difficulty: Literal[\"easy\", \"medium\", \"hard\"] = Field(\n",
    "        description=\"Difficulty level of the recipe\"\n",
    "    )\n",
    "\n",
    "@tool(args_schema=RecipeExtractionInput)\n",
    "def extract_recipe(dish_name: str, ingredients: list[str], steps: list[str], cooking_time: str, difficulty: str) -> dict:\n",
    "    \"\"\"Extract structured recipe information from cooking videos or images.\n",
    "    \n",
    "    Use this tool to parse cooking demonstrations and create structured\n",
    "    recipe data including ingredients, steps, timing, and difficulty.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"status\": \"recipe_extracted\",\n",
    "        \"dish\": dish_name,\n",
    "        \"ingredients\": ingredients,\n",
    "        \"steps\": steps,\n",
    "        \"time\": cooking_time,\n",
    "        \"difficulty\": difficulty\n",
    "    }\n",
    "\n",
    "# Convert LangChain tool to Bedrock format\n",
    "def langchain_tool_to_bedrock(lc_tool):\n",
    "    schema = lc_tool.args_schema.model_json_schema()\n",
    "    return {\n",
    "        \"toolSpec\": {\n",
    "            \"name\": lc_tool.name,\n",
    "            \"description\": lc_tool.description,\n",
    "            \"inputSchema\": {\n",
    "                \"json\": schema\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "safety_tools = [langchain_tool_to_bedrock(assess_safety_risks)]\n",
    "recipe_tools = [langchain_tool_to_bedrock(extract_recipe)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "image-reasoning",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example 1: Image Understanding with Medium Reasoning\n",
    "\n",
    "Analyze an image using medium reasoning effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "image-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "image_path = \"media/man_crossing_street.png\"\n",
    "image_bytes, image_format = nova_utils.load_image_as_bytes(image_path)\n",
    "\n",
    "# Create request with reasoning config\n",
    "request = {\n",
    "    \"modelId\": MODEL_ID,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"image\": {\"format\": image_format, \"source\": {\"bytes\": image_bytes}}},\n",
    "                {\"text\": \"Analyze this image for safety risks. Identify any hazards, assess the overall risk level, and recommend appropriate safety actions. Use the assess_safety_risks tool to provide your assessment.\"}\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"toolConfig\": {\"tools\": safety_tools},\n",
    "    \"additionalModelRequestFields\": {\n",
    "        \"reasoningConfig\": {\n",
    "            \"type\": \"enabled\",\n",
    "            \"maxReasoningEffort\": \"medium\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "bedrock = get_bedrock_runtime()\n",
    "response = bedrock.converse(**request)\n",
    "\n",
    "print(\"=== Image Analysis Response ===\")\n",
    "for content in response[\"output\"][\"message\"][\"content\"]:\n",
    "    if \"text\" in content:\n",
    "        print(f\"Text: {content['text']}\")\n",
    "    elif \"toolUse\" in content:\n",
    "        tool_use = content[\"toolUse\"]\n",
    "        print(f\"\\nTool: {tool_use['name']}\")\n",
    "        print(f\"Arguments: {json.dumps(tool_use['input'], indent=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "video-reasoning",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example 2: Video Analysis with High Reasoning\n",
    "\n",
    "Analyze video content with high reasoning effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "video-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load video\n",
    "video_path = \"media/Cheesecake.mp4\"\n",
    "with open(video_path, \"rb\") as f:\n",
    "    video_bytes = f.read()\n",
    "\n",
    "request = {\n",
    "    \"modelId\": MODEL_ID,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"video\": {\"format\": \"mp4\", \"source\": {\"bytes\": video_bytes}}},\n",
    "                {\"text\": \"Watch this cooking video and extract the complete recipe. Identify the dish name, all ingredients used, step-by-step instructions, total cooking time, and difficulty level. Use the extract_recipe tool to provide the structured recipe data.\"}\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"toolConfig\": {\"tools\": recipe_tools},\n",
    "    \"additionalModelRequestFields\": {\n",
    "        \"reasoningConfig\": {\n",
    "            \"type\": \"enabled\",\n",
    "            \"maxReasoningEffort\": \"medium\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "bedrock = get_bedrock_runtime()\n",
    "response = bedrock.converse(**request)\n",
    "\n",
    "print(\"=== Video Analysis Response ===\")\n",
    "for content in response[\"output\"][\"message\"][\"content\"]:\n",
    "    if \"text\" in content:\n",
    "        print(f\"Text: {content['text']}\")\n",
    "    elif \"toolUse\" in content:\n",
    "        tool_use = content[\"toolUse\"]\n",
    "        print(f\"\\nTool: {tool_use['name']}\")\n",
    "        print(f\"Arguments: {json.dumps(tool_use['input'], indent=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mmmu-pattern",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example 3: MMMU-Style Multiple Choice\n",
    "\n",
    "Implement MMMU-style evaluation with multiple choice questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mmmu-tool",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleChoiceAnswerInput(BaseModel):\n",
    "    \"\"\"Input schema for multiple choice answer submission.\"\"\"\n",
    "    selected_option: Literal[\"A\", \"B\", \"C\", \"D\"] = Field(\n",
    "        description=\"The selected answer option (A, B, C, or D)\"\n",
    "    )\n",
    "    reasoning_steps: str = Field(\n",
    "        description=\"Step-by-step reasoning that led to this answer\"\n",
    "    )\n",
    "\n",
    "@tool(args_schema=MultipleChoiceAnswerInput)\n",
    "def submit_multiple_choice_answer(selected_option: str, reasoning_steps: str) -> dict:\n",
    "    \"\"\"Submit the final answer for a multiple choice question.\n",
    "    \n",
    "    Use this tool after carefully analyzing the question and all options.\n",
    "    Provide your reasoning steps before selecting the final answer.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"status\": \"submitted\",\n",
    "        \"answer\": selected_option,\n",
    "        \"reasoning\": reasoning_steps\n",
    "    }\n",
    "\n",
    "mmmu_bedrock_tools = [langchain_tool_to_bedrock(submit_multiple_choice_answer)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mmmu-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "image_path = \"media/man_crossing_street.png\"\n",
    "image_bytes, image_format = nova_utils.load_image_as_bytes(image_path)\n",
    "\n",
    "question = \"\"\"Based on the image, what is the most appropriate action for the person to take?\n",
    "\n",
    "A) Continue walking without looking\n",
    "B) Check for traffic before crossing\n",
    "C) Run across the street quickly\n",
    "D) Wait for a green light signal\n",
    "\n",
    "Use the submit_multiple_choice_answer tool to provide your answer.\"\"\"\n",
    "\n",
    "request = {\n",
    "    \"modelId\": MODEL_ID,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"image\": {\"format\": image_format, \"source\": {\"bytes\": image_bytes}}},\n",
    "                {\"text\": question}\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"toolConfig\": {\"tools\": mmmu_bedrock_tools},\n",
    "    \"additionalModelRequestFields\": {\n",
    "        \"reasoningConfig\": {\n",
    "            \"type\": \"enabled\",\n",
    "            \"maxReasoningEffort\": \"medium\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "bedrock = get_bedrock_runtime()\n",
    "response = bedrock.converse(**request)\n",
    "\n",
    "print(\"=== MMMU-Style Question Response ===\")\n",
    "for content in response[\"output\"][\"message\"][\"content\"]:\n",
    "    if \"toolUse\" in content:\n",
    "        tool_use = content[\"toolUse\"]\n",
    "        args = tool_use[\"input\"]\n",
    "        print(f\"Selected Option: {args.get('selected_option')}\")\n",
    "        print(f\"Reasoning: {args.get('reasoning_steps')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **Hybrid Approach**: Use LangChain for tool definitions, boto3 for API calls with reasoning\n",
    "- **Reasoning Effort**: Use `low`, `medium`, or `high` based on task complexity\n",
    "- **Tool Conversion**: Convert LangChain tools to Bedrock format with `langchain_tool_to_bedrock`\n",
    "- **Full API Control**: Direct boto3 calls enable all Bedrock features including reasoning\n",
    "- **Temperature Settings**: Use 0.0-0.1 for factual tasks\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Explore **05_langgraph_multimodal_reasoning.ipynb** for stateful workflows\n",
    "- Check **06_strands_multimodal_reasoning.ipynb** for multi-agent patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c04951d-3add-49e1-b1f5-a29f967ec9fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
