{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Video Understanding Examples\n",
    "\n",
    "This notebook demonstrates how to use Amazon Nova 2 Omni for understanding video content. Nova 2 Omni can analyze videos, understand actions, extract insights, and classify video types.\n",
    "\n",
    "**Supported video formats:** mp4, mov, avi, mkv, webm\n",
    "\n",
    "**Note:** For audio understanding examples, see **01_speech_understanding_examples.ipynb**. For image generation examples, see **02_image_generation_examples.ipynb**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Helper Functions\n",
    "\n",
    "Run the cell below to establish helper functions used by the examples in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "from botocore.exceptions import ClientError\n",
    "from IPython.display import Image, display\n",
    "\n",
    "import nova_utils\n",
    "\n",
    "MODEL_ID = \"us.amazon.nova-2-omni-v1:0\"\n",
    "REGION_ID = \"us-west-2\"\n",
    "\n",
    "def get_bedrock_runtime():\n",
    "    \"\"\"Returns a properly configured Bedrock Runtime client.\"\"\"\n",
    "    config = Config(read_timeout=2 * 60)\n",
    "    bedrock = boto3.client(\n",
    "        service_name=\"bedrock-runtime\",\n",
    "        region_name=REGION_ID,\n",
    "        config=config,\n",
    "    )\n",
    "    return bedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "video-understanding-section",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Video Understanding\n",
    "\n",
    "Nova 2 Omni can analyze video content, understand actions, classify video types, and extract insights from moving images.\n",
    "\n",
    "---\n",
    "\n",
    "### Example 1a: Video Summarization\n",
    "\n",
    "Create executive summaries of video content.\n",
    "\n",
    "**Recommended inference parameters:**\n",
    "* `temperature`: 0\n",
    "* `topP`: 1\n",
    "* Some use cases may benefit from enabling model reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "video-summarize",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_VIDEO_PATH = \"media/Cheesecake.mp4\"\n",
    "user_prompt = \"Can you create an executive summary of this video's content?\"\n",
    "\n",
    "with open(INPUT_VIDEO_PATH, \"rb\") as video_file:\n",
    "    video_bytes = video_file.read()\n",
    "\n",
    "request = {\n",
    "    \"modelId\": MODEL_ID,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"video\": {\"format\": \"mp4\", \"source\": {\"bytes\": video_bytes}}},\n",
    "                {\"text\": user_prompt},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    \"inferenceConfig\": {\"temperature\": 0, \"topP\": 1, \"maxTokens\": 10000},\n",
    "}\n",
    "\n",
    "bedrock_runtime = get_bedrock_runtime()\n",
    "\n",
    "try:\n",
    "    response = bedrock_runtime.converse(**request)\n",
    "    text_content = next((item for item in response[\"output\"][\"message\"][\"content\"] if \"text\" in item), None)\n",
    "    \n",
    "    if text_content:\n",
    "        print(\"== Video Summary ==\")\n",
    "        print(text_content[\"text\"])\n",
    "\n",
    "except ClientError as err:\n",
    "    print(f\"Error occurred: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "video-captioning",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Example 1b: Step-by-Step Recipe Extraction\n",
    "\n",
    "Extract structured recipe information from cooking videos.\n",
    "\n",
    "**Recommended inference parameters:**\n",
    "* `temperature`: 0\n",
    "* `topP`: 1\n",
    "* Some use cases may benefit from enabling model reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "video-caption",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_VIDEO_PATH = \"media/Cheesecake.mp4\"\n",
    "user_prompt = \"\"\"Extract the recipe from this video. Provide:\n",
    "1. Recipe name\n",
    "2. Ingredients list with measurements\n",
    "3. Step-by-step instructions\n",
    "\n",
    "Format as a clear, structured recipe.\"\"\"\n",
    "\n",
    "with open(INPUT_VIDEO_PATH, \"rb\") as video_file:\n",
    "    video_bytes = video_file.read()\n",
    "\n",
    "request = {\n",
    "    \"modelId\": MODEL_ID,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"video\": {\"format\": \"mp4\", \"source\": {\"bytes\": video_bytes}}},\n",
    "                {\"text\": user_prompt},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    \"inferenceConfig\": {\"temperature\": 0, \"topP\": 1, \"maxTokens\": 10000},\n",
    "}\n",
    "\n",
    "bedrock_runtime = get_bedrock_runtime()\n",
    "\n",
    "try:\n",
    "    response = bedrock_runtime.converse(**request)\n",
    "    text_content = next((item for item in response[\"output\"][\"message\"][\"content\"] if \"text\" in item), None)\n",
    "    \n",
    "    if text_content:\n",
    "        print(\"== Extracted Recipe ==\")\n",
    "        print(text_content[\"text\"])\n",
    "\n",
    "except ClientError as err:\n",
    "    print(f\"Error occurred: {err}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "video-detailed-description",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Example 1c: Rich Visual Description\n",
    "\n",
    "Generate detailed descriptions focusing on visual elements, colors, composition, and cinematography.\n",
    "\n",
    "**Recommended inference parameters:**\n",
    "* `temperature`: 0\n",
    "* `topP`: 1\n",
    "* Some use cases may benefit from enabling model reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9719c6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_VIDEO_PATH = \"media/Cheesecake.mp4\"\n",
    "user_prompt = \"\"\"Provide a rich visual description of this video. Focus on:\n",
    "- Camera angles and framing (top-down, close-up, etc.)\n",
    "- Color palette and lighting\n",
    "- Visual composition and layout\n",
    "- Movement and transitions\n",
    "- Text overlays and their styling\n",
    "- Overall aesthetic and production quality\n",
    "\n",
    "Describe what makes this video visually engaging.\"\"\"\n",
    "\n",
    "with open(INPUT_VIDEO_PATH, \"rb\") as video_file:\n",
    "    video_bytes = video_file.read()\n",
    "\n",
    "request = {\n",
    "    \"modelId\": MODEL_ID,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"video\": {\"format\": \"mp4\", \"source\": {\"bytes\": video_bytes}}},\n",
    "                {\"text\": user_prompt},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    \"inferenceConfig\": {\"temperature\": 0, \"topP\": 1, \"maxTokens\": 10000},\n",
    "}\n",
    "\n",
    "bedrock_runtime = get_bedrock_runtime()\n",
    "\n",
    "try:\n",
    "    response = bedrock_runtime.converse(**request)\n",
    "    text_content = next((item for item in response[\"output\"][\"message\"][\"content\"] if \"text\" in item), None)\n",
    "    \n",
    "    if text_content:\n",
    "        print(\"== Rich Visual Description ==\")\n",
    "        print(text_content[\"text\"])\n",
    "\n",
    "except ClientError as err:\n",
    "    print(f\"Error occurred: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "video-timestamps",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Example 1d: Event Timestamp Extraction\n",
    "\n",
    "Extract timestamps for specific events in videos.\n",
    "\n",
    "**Recommended inference parameters:**\n",
    "* `temperature`: 0\n",
    "* `topP`: 1\n",
    "* Reasoning should not be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f80eadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_VIDEO_PATH = \"media/Cheesecake.mp4\"\n",
    "event_query = \"mixing ingredients\"\n",
    "user_prompt = f\"Please localize the moment that the event '{event_query}' happens in the video. Answer with the starting and ending time of the event in seconds. e.g. [[72, 82]]. If the event happen multiple times, list all of them. e.g. [[40, 50], [72, 82]]\"\n",
    "\n",
    "with open(INPUT_VIDEO_PATH, \"rb\") as video_file:\n",
    "    video_bytes = video_file.read()\n",
    "\n",
    "request = {\n",
    "    \"modelId\": MODEL_ID,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"video\": {\"format\": \"mp4\", \"source\": {\"bytes\": video_bytes}}},\n",
    "                {\"text\": user_prompt},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    \"inferenceConfig\": {\"temperature\": 0, \"topP\": 1, \"maxTokens\": 10000},\n",
    "}\n",
    "\n",
    "bedrock_runtime = get_bedrock_runtime()\n",
    "\n",
    "try:\n",
    "    response = bedrock_runtime.converse(**request)\n",
    "    text_content = next((item for item in response[\"output\"][\"message\"][\"content\"] if \"text\" in item), None)\n",
    "    \n",
    "    if text_content:\n",
    "        print(f\"== Event Timestamps for '{event_query}' ==\")\n",
    "        print(text_content[\"text\"])\n",
    "\n",
    "except ClientError as err:\n",
    "    print(f\"Error occurred: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "video-segmentation",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Example 1e: Video Segmentation with Timestamps\n",
    "\n",
    "Generate a log of video segments with timestamps and captions.\n",
    "\n",
    "**Recommended inference parameters:**\n",
    "* `temperature`: 0\n",
    "* `topP`: 1\n",
    "* Reasoning should not be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff981189",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_VIDEO_PATH = \"media/Cheesecake.mp4\"\n",
    "user_prompt = \"Segment a video into different scenes and generate caption per scene. The output should be in the format: [STARTING TIME-ENDING TIMESTAMP] CAPTION. Timestamp in MM:SS format\"\n",
    "\n",
    "with open(INPUT_VIDEO_PATH, \"rb\") as video_file:\n",
    "    video_bytes = video_file.read()\n",
    "\n",
    "request = {\n",
    "    \"modelId\": MODEL_ID,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"video\": {\"format\": \"mp4\", \"source\": {\"bytes\": video_bytes}}},\n",
    "                {\"text\": user_prompt},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    \"inferenceConfig\": {\"temperature\": 0, \"topP\": 1, \"maxTokens\": 10000},\n",
    "}\n",
    "\n",
    "bedrock_runtime = get_bedrock_runtime()\n",
    "\n",
    "try:\n",
    "    response = bedrock_runtime.converse(**request)\n",
    "    text_content = next((item for item in response[\"output\"][\"message\"][\"content\"] if \"text\" in item), None)\n",
    "    \n",
    "    if text_content:\n",
    "        print(\"== Video Segmentation ==\")\n",
    "        print(text_content[\"text\"])\n",
    "\n",
    "except ClientError as err:\n",
    "    print(f\"Error occurred: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "video-classification",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Example 1f: Video Classification\n",
    "\n",
    "Classify videos based on predefined categories.\n",
    "\n",
    "**Recommended inference parameters:**\n",
    "* `temperature`: 0\n",
    "* `topP`: 1\n",
    "* Reasoning should not be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a63729",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_VIDEO_PATH = \"media/Cheesecake.mp4\"\n",
    "user_prompt = \"\"\"What is the most appropriate category for this video? Select your answer from the options provided:\n",
    "Cooking Tutorial\n",
    "Home Repair\n",
    "Makeup Tutorial\n",
    "Other\"\"\"\n",
    "\n",
    "with open(INPUT_VIDEO_PATH, \"rb\") as video_file:\n",
    "    video_bytes = video_file.read()\n",
    "\n",
    "request = {\n",
    "    \"modelId\": MODEL_ID,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"video\": {\"format\": \"mp4\", \"source\": {\"bytes\": video_bytes}}},\n",
    "                {\"text\": user_prompt},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    \"inferenceConfig\": {\"temperature\": 0, \"topP\": 1, \"maxTokens\": 100},\n",
    "}\n",
    "\n",
    "bedrock_runtime = get_bedrock_runtime()\n",
    "\n",
    "try:\n",
    "    response = bedrock_runtime.converse(**request)\n",
    "    text_content = next((item for item in response[\"output\"][\"message\"][\"content\"] if \"text\" in item), None)\n",
    "    \n",
    "    if text_content:\n",
    "        print(\"== Video Classification ==\")\n",
    "        print(text_content[\"text\"])\n",
    "\n",
    "except ClientError as err:\n",
    "    print(f\"Error occurred: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next-steps",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **Video Summarization**: Create executive summaries of video content\n",
    "- **Recipe Extraction**: Extract structured recipe information from cooking videos\n",
    "- **Visual Description**: Analyze cinematography, colors, and composition\n",
    "- **Timestamp Extraction**: Locate specific events within videos\n",
    "- **Video Segmentation**: Break videos into timestamped segments with captions\n",
    "- **Video Classification**: Categorize videos based on content\n",
    "- **Temperature Settings**: Use temperature 0 for factual, consistent responses\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Explore **01_speech_understanding_examples.ipynb** for comprehensive audio processing examples\n",
    "- Check out **02_image_generation_examples.ipynb** to learn about image generation capabilities\n",
    "- Experiment with different prompts and inference parameters to optimize for your use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76f2685-aa4a-4cf3-b334-103d69773532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
