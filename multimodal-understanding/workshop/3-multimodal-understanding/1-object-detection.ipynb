{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Nova for Object Detection and Bounding Box Annotation\n",
    "\n",
    "Amazon Nova models have powerful capabilities for image grounding and object detection tasks across a wide range of domains. This notebook demonstrates how to use Amazon Nova models to detect objects in images and create bounding box annotations with high precision.\n",
    "\n",
    "## What you'll learn in this notebook\n",
    "\n",
    "- How to prompt Nova models for object detection with bounding boxes\n",
    "- How to parse and visualize bounding box coordinates\n",
    "- How to customize detection for specific object categories\n",
    "- How to handle different image types and scenarios\n",
    "\n",
    "## Real-world use cases for object detection\n",
    "\n",
    "Object detection with Nova models can be applied to numerous industry applications:\n",
    "\n",
    "1. **Retail and E-commerce**\n",
    "   - Product identification in shelf images\n",
    "   - Inventory management and out-of-stock detection\n",
    "   - Visual search and product recommendations\n",
    "\n",
    "2. **Manufacturing and Quality Control**\n",
    "   - Defect detection in production lines\n",
    "   - Component identification and verification\n",
    "   - Assembly verification and quality assurance\n",
    "\n",
    "3. **Security and Surveillance**\n",
    "   - Person and vehicle detection\n",
    "   - Suspicious object identification\n",
    "   - Intrusion detection systems\n",
    "\n",
    "4. **Healthcare and Medical Imaging**\n",
    "   - Anomaly detection in medical scans\n",
    "   - Cell and tissue identification\n",
    "   - Medical device positioning verification\n",
    "\n",
    "5. **Agriculture**\n",
    "   - Crop disease detection\n",
    "   - Ripeness assessment\n",
    "   - Weed identification\n",
    "\n",
    "6. **Smart Cities**\n",
    "   - Traffic monitoring and analysis\n",
    "   - Parking space management\n",
    "   - Infrastructure inspection\n",
    "\n",
    "## Technical details\n",
    "\n",
    "The output bounding box coordinates are in scale [0, 1000), which you need to rescale to the original image size. This notebook demonstrates the full pipeline from image input to visualized detection output.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install boto3 Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import boto3\n",
    "import io\n",
    "import json\n",
    "import re\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "\n",
    "\n",
    "modelId = \"us.amazon.nova-lite-v1:0\"\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "bedrock_rt = boto3.client(\"bedrock-runtime\", region_name=\"us-west-2\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a helper function for better loading model output as json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def safe_json_load(json_string):\n",
    "    try:\n",
    "        json_string = re.sub(r\"\\s\", \"\", json_string)\n",
    "        json_string = re.sub(r\"\\(\", \"[\", json_string)\n",
    "        json_string = re.sub(r\"\\)\", \"]\", json_string)\n",
    "        bbox_set = {}\n",
    "        for b in re.finditer(r\"\\[\\d+,\\d+,\\d+,\\d+\\]\", json_string):\n",
    "            if b.group(0) in bbox_set:\n",
    "                json_string = json_string[:bbox_set[b.group(0)][1]] + \"}]\"\n",
    "                break\n",
    "            bbox_set[b.group(0)] = (b.start(), b.end())\n",
    "        else:\n",
    "            json_string = json_string[:bbox_set[b.group(0)][1]] + \"}]\"\n",
    "        json_string = re.sub(r\"\\]\\},\\]$\", \"]}]\", json_string)\n",
    "        json_string = re.sub(r\"\\]\\],\\[\\\"\", \"]},{\\\"\", json_string)\n",
    "        json_string = re.sub(r\"\\]\\],\\[\\{\\\"\", \"]},{\\\"\", json_string)\n",
    "        return json.loads(json_string)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoke Amazon Nova for image detection, you need to define the detection task by prompt. Here is the prompt for specific object detection, and you can define you own prompt based on your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection(image_path, category_list, image_short_size=360):\n",
    "    image_pil = Image.open(image_path)\n",
    "    width, height = image_pil.size\n",
    "\n",
    "    ratio = image_short_size/ min(width, height)\n",
    "    width = round(ratio * width)\n",
    "    height = round(ratio * height)\n",
    "\n",
    "    image_pil = image_pil.resize((width, height), resample=Image.Resampling.LANCZOS)\n",
    "    buffer = io.BytesIO()\n",
    "    image_pil.save(buffer, format=\"webp\", quality=90)\n",
    "    image_data = buffer.getvalue()\n",
    "\n",
    "\n",
    "    category_str = \",\".join([f'\"{category}\"' for category in category_list])\n",
    "    \n",
    "    prompts = \"\"\"\n",
    "Detect bounding box of objects in the image, only detect %s category objects with high confidence, output in a list of bounding box format.\n",
    "Output example:\n",
    "[\n",
    "    {\"%s\": [x1, y1, x2, y2]},\n",
    "    ...\n",
    "]\n",
    "\"\"\" % (category_str, category_list[0])\n",
    "    prefill=\"\"\"[\n",
    "    {\"\n",
    "\"\"\"\n",
    "\n",
    "    print(\"Input Prompt:\\n\", prompts)\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"image\": {\n",
    "                        \"format\": 'webp',\n",
    "                        \"source\": {\n",
    "                            \"bytes\": image_data,\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"text\": prompts\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"text\": prefill\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = bedrock_rt.converse(\n",
    "        modelId=modelId, messages=messages,\n",
    "        inferenceConfig={\n",
    "            \"temperature\": 0.0,\n",
    "            \"maxTokens\": 1024,\n",
    "        },\n",
    "    )\n",
    "    output = prefill + response.get('output')[\"message\"][\"content\"][0][\"text\"]\n",
    "\n",
    "    result = safe_json_load(output)\n",
    "\n",
    "    color_list = [\n",
    "        'blue',\n",
    "        'green',\n",
    "        'yellow',\n",
    "        'red',\n",
    "        'orange',\n",
    "        'pink',\n",
    "        'purple',\n",
    "    ]\n",
    "\n",
    "    print(\"Result:\\n\")\n",
    "    for idx, item in enumerate(result):\n",
    "        label = next(iter(item))\n",
    "        bbox = item[label]\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        if x1 >= x2 or y1 >= y2:\n",
    "            continue\n",
    "        w, h = image_pil.size\n",
    "        x1 = x1 / 1000 * w\n",
    "        x2 = x2 / 1000 * w\n",
    "        y1 = y1 / 1000 * h\n",
    "        y2 = y2 / 1000 * h\n",
    "        bbox = (x1, y1, x2, y2)\n",
    "        bbox = list(map(round, bbox))\n",
    "        print(f\"Detect <{label}> in {bbox}\")\n",
    "        # draw bounding box\n",
    "        draw = ImageDraw.Draw(image_pil)\n",
    "        color = color_list[idx % len(color_list)]\n",
    "        draw.rectangle(bbox, outline=color, width=2)\n",
    "        draw.text((x1 + 4, y1 + 2), label, fill=color)\n",
    "    return image_pil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection(\n",
    "    \"./image/bottle.webp\", \n",
    "    category_list=[\"bottle\"], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection(\n",
    "    \"./image/cat_dog_car.webp\", \n",
    "    category_list=[\"car\", \"dog\", \"cat\"], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection(\n",
    "    \"./image/cakes.webp\", \n",
    "    category_list=[\"cake\"], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection(\n",
    "    \"./image/unripe_strawberry.webp\", \n",
    "    category_list=[\"unripe_strawberry\"], \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this notebook, we explored how to use Amazon Nova models for object detection and bounding box annotation. Here's what we learned:\n",
    "\n",
    "1. Nova models can detect objects in images with high accuracy\n",
    "2. We can customize detection by specifying which categories to look for\n",
    "3. The models return coordinates that we need to scale to the original image size\n",
    "4. We can visualize detections by drawing bounding boxes and labels\n",
    "5. This approach works for different types of images and object categories"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
