{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe8d615b-fa47-485b-9dc3-13fe1937d04f",
   "metadata": {},
   "source": [
    "# Video Temporal Understanding with Amazon Nova Premier\n",
    "\n",
    "This notebook demonstrates the powerful video analysis capabilities of Amazon Nova Premier, focusing on temporal understanding - the model's ability to identify sequences of events, understand timing relationships, and extract meaningful insights from video content over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a1c8d4-c1d1-412e-ad89-984066da48bc",
   "metadata": {},
   "source": [
    "## What You'll Learn\n",
    "\n",
    "In this notebook, you will explore how Amazon Nova Premier analyzes video content to extract temporal information, identify key events, and understand sequences of actions. The notebook uses:\n",
    "\n",
    "1. **Amazon S3** - For storing and accessing video files\n",
    "2. **Amazon Bedrock** - For invoking Amazon Nova Premier via the API\n",
    "\n",
    "You'll learn how to:\n",
    "- Process video content using S3 URI references\n",
    "- Extract precise temporal information from videos\n",
    "- Create structured outputs from video analysis\n",
    "- Identify actions and events at specific timestamps\n",
    "- Generate comprehensive action timelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f5e4ef-f296-48cd-943b-6b2b3701daf8",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Let's begin by setting up our environment with the necessary dependencies and configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d75138-3ed9-4650-9f72-d41f9072e83a",
   "metadata": {},
   "source": [
    "### Install Required Packages\n",
    "\n",
    "First, let's install the necessary Python packages for handling video and AWS services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7379a75-52e9-4a0b-b77c-14aba49c623b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T19:17:15.016675Z",
     "iopub.status.busy": "2025-07-25T19:17:15.016371Z",
     "iopub.status.idle": "2025-07-25T19:17:15.020406Z",
     "shell.execute_reply": "2025-07-25T19:17:15.019655Z",
     "shell.execute_reply.started": "2025-07-25T19:17:15.016644Z"
    }
   },
   "outputs": [],
   "source": [
    "# All dependencies are installed from requirements.txt in module 1\n",
    "# No need to install them again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b563d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T19:17:15.579403Z",
     "iopub.status.busy": "2025-07-25T19:17:15.578609Z",
     "iopub.status.idle": "2025-07-25T19:17:15.584406Z",
     "shell.execute_reply": "2025-07-25T19:17:15.583580Z",
     "shell.execute_reply.started": "2025-07-25T19:17:15.579376Z"
    }
   },
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65b3b23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T19:17:16.183863Z",
     "iopub.status.busy": "2025-07-25T19:17:16.183241Z",
     "iopub.status.idle": "2025-07-25T19:17:16.703692Z",
     "shell.execute_reply": "2025-07-25T19:17:16.703016Z",
     "shell.execute_reply.started": "2025-07-25T19:17:16.183836Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from IPython.display import Video\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Set up AWS clients using stored region name\n",
    "boto3.setup_default_session(region_name=region_name)\n",
    "\n",
    "# Initialize AWS service clients\n",
    "account_id = boto3.client(\"sts\").get_caller_identity().get(\"Account\")\n",
    "s3_client = boto3.client(\"s3\")\n",
    "bedrock_client = boto3.client(\"bedrock-runtime\", region_name=\"us-west-2\") \n",
    "\n",
    "# Define bucket name and video path\n",
    "bucket_name = f\"mmu-workshop-{account_id}\"\n",
    "video_path = \"video/Meridian_Clip.mp4\"\n",
    "\n",
    "# Check if bucket exists and create video folder if needed\n",
    "r = s3_client.list_buckets(Prefix=bucket_name)\n",
    "if r[\"Buckets\"][0][\"Name\"].startswith(bucket_name):\n",
    "    bucket_name = r[\"Buckets\"][0][\"Name\"]\n",
    "    s3_client.put_object(Bucket=bucket_name, Key=\"video/\")\n",
    "    print(f\"Successfully created video/ folder in {bucket_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210d4061-c854-45f2-bf9f-89c59650d80a",
   "metadata": {},
   "source": [
    "### Upload Video to Amazon S3\n",
    "\n",
    "Next, we'll upload our sample video to S3 so that Nova Premier can access it via S3 URI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe2e69f-13e2-4f26-ab9d-98e88735181d",
   "metadata": {},
   "source": [
    "### About Our Sample Video\n",
    "\n",
    "For this demonstration, we'll use a clip from \"Meridian,\" a short film from Netflix Open Content. This video contains several interesting temporal elements:\n",
    "\n",
    "- A vintage car driving on a winding mountain road\n",
    "- Rain beginning to fall partway through the clip\n",
    "- A character appearing in the rearview mirror\n",
    "- Various camera angle changes\n",
    "\n",
    "The video file `Meridian_Clip.mp4` will be uploaded to your S3 bucket for processing by Amazon Nova Premier. The notebook includes code to handle this upload process automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27524616-2864-4d92-86be-b999e7d47ccf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T19:17:18.331811Z",
     "iopub.status.busy": "2025-07-25T19:17:18.331401Z",
     "iopub.status.idle": "2025-07-25T19:17:18.464524Z",
     "shell.execute_reply": "2025-07-25T19:17:18.460929Z",
     "shell.execute_reply.started": "2025-07-25T19:17:18.331786Z"
    }
   },
   "outputs": [],
   "source": [
    "def interactive_sleep(seconds: int):\n",
    "    \"\"\"Display an interactive progress indicator with dots.\"\"\"\n",
    "    dots = \"\"\n",
    "    for _ in range(seconds):\n",
    "        dots += \".\"\n",
    "        print(dots, end=\"\\r\")\n",
    "        time.sleep(1)\n",
    "\n",
    "\n",
    "def upload_directory(path, bucket_name, s3_path):\n",
    "    \"\"\"\n",
    "    Upload all files from a local directory to an S3 bucket.\n",
    "    \n",
    "    Args:\n",
    "        path (str): Local directory path to upload\n",
    "        bucket_name (str): S3 bucket name\n",
    "        s3_path (str): Target path in S3 bucket\n",
    "    \"\"\"\n",
    "    for root, _, files in os.walk(path):\n",
    "        for file in files:\n",
    "            local_file_path = os.path.join(root, file)\n",
    "            print(local_file_path)\n",
    "            s3_key = os.path.join(s3_path, os.path.relpath(local_file_path, path))\n",
    "            # Upload the file with the new S3 key\n",
    "            s3_client.upload_file(local_file_path, bucket_name, s3_key)\n",
    "\n",
    "\n",
    "# Upload video directory contents to S3\n",
    "upload_directory(\"video\", bucket_name, \"video\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bea5e7d-8385-464c-8501-679d146ffa61",
   "metadata": {},
   "source": [
    "### Preview the Video\n",
    "\n",
    "Let's view the video clip to get familiar with its content before analyzing it with Nova Premier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d063f2fb-f3d1-4335-ab90-fc6f08026ef6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T19:17:19.531538Z",
     "iopub.status.busy": "2025-07-25T19:17:19.530914Z",
     "iopub.status.idle": "2025-07-25T19:17:19.538940Z",
     "shell.execute_reply": "2025-07-25T19:17:19.538319Z",
     "shell.execute_reply.started": "2025-07-25T19:17:19.531511Z"
    }
   },
   "outputs": [],
   "source": [
    "#View the video within the notebook\n",
    "\n",
    "Video(video_path, width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf70c8c-493b-4700-910f-cde4527601e7",
   "metadata": {},
   "source": [
    "## Video Analysis with Amazon Nova Premier\n",
    "\n",
    "Amazon Nova Premier offers sophisticated capabilities for analyzing video content. Unlike simpler approaches that might just extract frames and process them individually, Nova Premier can understand the temporal relationships between events and the narrative flow of video content.\n",
    "\n",
    "The model can process videos via S3 URIs, which allows it to analyze videos of significant size (up to 1GB) without running into payload size limitations. This approach is particularly valuable for real-world applications where videos may be lengthy or high resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a073c334-37a8-4fdc-9c65-c54a47496e75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T19:17:20.549540Z",
     "iopub.status.busy": "2025-07-25T19:17:20.548708Z",
     "iopub.status.idle": "2025-07-25T19:17:20.552532Z",
     "shell.execute_reply": "2025-07-25T19:17:20.551866Z",
     "shell.execute_reply.started": "2025-07-25T19:17:20.549510Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the model ID for Amazon Nova Premier\n",
    "PREMIER_MODEL_ID = \"us.amazon.nova-premier-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be92bfd5-b5d7-4248-bf8d-8a25dfbe5254",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T19:17:21.262979Z",
     "iopub.status.busy": "2025-07-25T19:17:21.262291Z",
     "iopub.status.idle": "2025-07-25T19:17:21.266965Z",
     "shell.execute_reply": "2025-07-25T19:17:21.266010Z",
     "shell.execute_reply.started": "2025-07-25T19:17:21.262950Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the S3 URI for the video\n",
    "# Nova Premier can access videos directly from S3 using this format\n",
    "uri = f\"s3://{bucket_name}/{video_path}\"\n",
    "print(f\"Video S3 URI: {uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58e2aa2-2f12-4516-a511-9d63d183a903",
   "metadata": {},
   "source": [
    "### Task 1: Summarizing Video Content\n",
    "\n",
    "First, let's ask Amazon Nova Premier to create a concise summary of the video, identifying key moments and elements in the scene. This demonstrates the model's ability to understand the overall narrative structure of video content.\n",
    "\n",
    "Video summarization has many practical applications:\n",
    "- Content cataloging and indexing\n",
    "- Creating accessible descriptions for visually impaired users\n",
    "- Generating metadata for search and recommendation systems\n",
    "- Quick content previews for users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56193da1-7096-4982-925f-98992b5d52a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T19:17:23.082615Z",
     "iopub.status.busy": "2025-07-25T19:17:23.082261Z",
     "iopub.status.idle": "2025-07-25T19:17:33.561252Z",
     "shell.execute_reply": "2025-07-25T19:17:33.560447Z",
     "shell.execute_reply.started": "2025-07-25T19:17:23.082593Z"
    }
   },
   "outputs": [],
   "source": [
    "def invoke_nova_video(prompt, system_message=None, temperature=0.3):\n",
    "    \"\"\"\n",
    "    Send a video to Amazon Nova Premier with a specific prompt.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The prompt to send to the model\n",
    "        system_message (str, optional): System message for context\n",
    "        temperature (float, optional): Temperature for model inference\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Full model response and the text content\n",
    "    \"\"\"\n",
    "    # Default system message if none provided\n",
    "    if system_message is None:\n",
    "        system_message = \"\"\"\n",
    "        You are an expert video and media analyst. You analyze video \n",
    "        to extract detailed fact based insights accurately.\n",
    "        \"\"\"\n",
    "    \n",
    "    # Format system message\n",
    "    system_list = [{\"text\": system_message}]\n",
    "    \n",
    "    # Format user message with video and prompt\n",
    "    message_list = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"video\": {\n",
    "                        \"format\": \"mp4\",\n",
    "                        \"source\": {\n",
    "                            \"s3Location\": {\n",
    "                                \"uri\": uri\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                {\"text\": prompt}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Set inference parameters\n",
    "    inf_params = {\n",
    "        \"maxTokens\": 1024, \n",
    "        \"topP\": 0.1, \n",
    "        \"topK\": 20, \n",
    "        \"temperature\": temperature\n",
    "    }\n",
    "    \n",
    "    # Prepare the request\n",
    "    native_request = {\n",
    "        \"schemaVersion\": \"messages-v1\",\n",
    "        \"messages\": message_list,\n",
    "        \"system\": system_list,\n",
    "        \"inferenceConfig\": inf_params,\n",
    "    }\n",
    "    \n",
    "    # Invoke the model\n",
    "    response = bedrock_client.invoke_model(\n",
    "        modelId=PREMIER_MODEL_ID, \n",
    "        body=json.dumps(native_request)\n",
    "    )\n",
    "    \n",
    "    # Parse the response\n",
    "    model_response = json.loads(response[\"body\"].read())\n",
    "    \n",
    "    # Extract the text content\n",
    "    content_text = model_response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "    \n",
    "    return model_response, content_text\n",
    "\n",
    "\n",
    "# Define expert video analyst system message\n",
    "system_message = \"\"\"\n",
    "You are an expert video and media analyst. You analyze video to extract detailed fact based insights accurately.\n",
    "\"\"\"\n",
    "\n",
    "# Ask for a concise summary of the video\n",
    "prompt = \"Create a concise summary of this video. Identify and describe the key moments or events, limiting your summary to 5 main points in bullet points.\"\n",
    "\n",
    "# Invoke the model\n",
    "model_response, content_text = invoke_nova_video(prompt, system_message)\n",
    "\n",
    "# Display the results\n",
    "print(\"[Full Response]\")\n",
    "print(json.dumps(model_response, indent=2))\n",
    "print(\"\\n[Response Content Text]\")\n",
    "print(content_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e84cfd-e71d-4786-980f-8f24d29f36b2",
   "metadata": {},
   "source": [
    "### Task 2: Temporal Event Detection\n",
    "\n",
    "A key capability of Amazon Nova Premier is identifying precisely when specific events occur in a video. This temporal understanding is crucial for many applications:\n",
    "\n",
    "- **Content Moderation**: Identifying when potentially problematic content appears\n",
    "- **Highlight Extraction**: Pinpointing exciting moments in sports or entertainment content\n",
    "- **Video Indexing**: Creating searchable timestamps for specific actions or events\n",
    "- **Scene Detection**: Identifying transitions between different scenes or settings\n",
    "- **Behavioral Analysis**: Tracking when specific actions or behaviors occur\n",
    "\n",
    "Let's explore this capability through several examples, asking the model to identify when specific events happen in our sample video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4185fd9c-f512-4432-a252-e8744dc214af",
   "metadata": {},
   "source": [
    "#### Example 1: Weather Event Detection\n",
    "\n",
    "Let's ask Nova Premier to identify exactly when it begins to rain in the video. This tests the model's ability to detect subtle environmental changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf70c33d-167b-4217-b2f1-c0b94c299651",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T19:17:33.562705Z",
     "iopub.status.busy": "2025-07-25T19:17:33.562470Z",
     "iopub.status.idle": "2025-07-25T19:18:05.249203Z",
     "shell.execute_reply": "2025-07-25T19:18:05.248294Z",
     "shell.execute_reply.started": "2025-07-25T19:17:33.562686Z"
    }
   },
   "outputs": [],
   "source": [
    "# Detect when rain begins in the video\n",
    "prompt = \"Identify when it begins to rain in the video. Output your response as a timestamp with the format MM:SS\"\n",
    "\n",
    "# Invoke the model\n",
    "model_response, content_text = invoke_nova_video(prompt, system_message)\n",
    "\n",
    "# Display the results\n",
    "print(\"[Full Response]\")\n",
    "print(json.dumps(model_response, indent=2))\n",
    "print(\"\\n[Response Content Text]\")\n",
    "print(content_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8a1bd8-92c5-4e46-9fb7-30102525cea5",
   "metadata": {},
   "source": [
    "#### Example 2: Character Appearance Detection\n",
    "\n",
    "Now let's ask when a specific character first appears in the video. This demonstrates the model's ability to track characters throughout a video sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61666906-f51a-4299-ab8d-4b65687fc934",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T19:18:05.251099Z",
     "iopub.status.busy": "2025-07-25T19:18:05.250476Z",
     "iopub.status.idle": "2025-07-25T19:18:13.175727Z",
     "shell.execute_reply": "2025-07-25T19:18:13.174748Z",
     "shell.execute_reply.started": "2025-07-25T19:18:05.251065Z"
    }
   },
   "outputs": [],
   "source": [
    "# Detect when a woman first appears in the video\n",
    "prompt = \"At what point in the video does a women first appear. Output your response as a timestamp with the format MM:SS\"\n",
    "\n",
    "# Invoke the model\n",
    "model_response, content_text = invoke_nova_video(prompt, system_message)\n",
    "\n",
    "# Display the results\n",
    "print(\"[Full Response]\")\n",
    "print(json.dumps(model_response, indent=2))\n",
    "print(\"\\n[Response Content Text]\")\n",
    "print(content_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb44957-cc65-4e88-9d3d-5b38f10b5976",
   "metadata": {},
   "source": [
    "#### Example 3: Cinematography Analysis\n",
    "\n",
    "Let's explore the model's understanding of cinematography by asking it to identify when a specific type of camera shot appears in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfed9903-d5db-4a93-be93-d691644dbf11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T19:18:13.177852Z",
     "iopub.status.busy": "2025-07-25T19:18:13.177567Z",
     "iopub.status.idle": "2025-07-25T19:18:21.033768Z",
     "shell.execute_reply": "2025-07-25T19:18:21.032726Z",
     "shell.execute_reply.started": "2025-07-25T19:18:13.177830Z"
    }
   },
   "outputs": [],
   "source": [
    "# Detect when we see a close-up shot of the man\n",
    "prompt = \"At what point in the video do we see a close up shot of the man in the video. Output your response as a timestamp with the format MM:SS\"\n",
    "\n",
    "# Invoke the model\n",
    "model_response, content_text = invoke_nova_video(prompt, system_message)\n",
    "\n",
    "# Display the results\n",
    "print(\"[Full Response]\")\n",
    "print(json.dumps(model_response, indent=2))\n",
    "print(\"\\n[Response Content Text]\")\n",
    "print(content_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa95b67-b407-4a9c-b61e-4e467e2caec7",
   "metadata": {},
   "source": [
    "### Task 3: Comprehensive Action Mapping\n",
    "\n",
    "For sophisticated video analysis applications, we often need to map all actions across an entire video. This creates a complete temporal understanding of the content, enabling:\n",
    "\n",
    "- **Video Search**: Making video content searchable by action or event\n",
    "- **Content Navigation**: Allowing users to jump to specific events\n",
    "- **Automated Summarization**: Creating timestamped summaries of key moments\n",
    "- **Accessibility Features**: Generating enhanced descriptions with timing information\n",
    "- **Behavioral Analysis**: Understanding sequences and patterns of actions\n",
    "\n",
    "Amazon Nova Premier can generate structured outputs that identify actions throughout a video's duration, creating a complete temporal map of events."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549b4693-541d-4b4b-9f78-4d3955362864",
   "metadata": {},
   "source": [
    "#### Structured Action Timeline Generation\n",
    "\n",
    "Let's ask Amazon Nova Premier to create a comprehensive timeline of all human actions occurring throughout the video, with precise timestamps. \n",
    "\n",
    "For this example, we'll demonstrate how to guide the model to produce a structured JSON output format that could be easily consumed by downstream applications. This approach is particularly valuable for creating programmatically accessible video analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaa0e6d-698e-4acf-948d-5fd0ff6279d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T19:18:21.034938Z",
     "iopub.status.busy": "2025-07-25T19:18:21.034641Z",
     "iopub.status.idle": "2025-07-25T19:18:43.455105Z",
     "shell.execute_reply": "2025-07-25T19:18:43.454327Z",
     "shell.execute_reply.started": "2025-07-25T19:18:21.034912Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a prompt for generating a structured timeline of actions\n",
    "prompt = \"\"\"\n",
    "Analyze the video and identify all human actions or activities occurring throughout its duration. \n",
    "\n",
    "Follow these guidelines for your task:\n",
    "1. List each action with its corresponding timestamp range.\n",
    "2. Describe each action succinctly\n",
    "3. Output the timestamp in MM:SS format.\n",
    "4. DO NOT list identical actions consecutively in your output\n",
    "5. Your output should be in the following sample json schema:\n",
    "    {\n",
    "    \"actions\": [\n",
    "        {\n",
    "            \"action\": \"the teacher enters the room\",\n",
    "            \"timestamp\": \"00:15\"\n",
    "        },\n",
    "        {\n",
    "            \"action\": \"the students sit down\", \n",
    "            \"timestamp\": \"00:32\"\n",
    "\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Invoke the model with structured output request\n",
    "model_response, content_text = invoke_nova_video(prompt, system_message)\n",
    "\n",
    "# Display the results\n",
    "print(\"[Full Response]\")\n",
    "print(json.dumps(model_response, indent=2))\n",
    "print(\"\\n[Response Content Text]\")\n",
    "print(content_text)\n",
    "\n",
    "# Optional: Parse the JSON response to work with it programmatically\n",
    "try:\n",
    "    # Extract the JSON part from the response (removing code block markers if present)\n",
    "    json_text = content_text.strip()\n",
    "    if json_text.startswith(\"```json\"):\n",
    "        json_text = json_text.replace(\"```json\", \"\", 1)\n",
    "    if json_text.endswith(\"```\"):\n",
    "        json_text = json_text.replace(\"```\", \"\", 1)\n",
    "    \n",
    "    actions_data = json.loads(json_text)\n",
    "    print(\"\\n[Parsed Action Count]\")\n",
    "    print(f\"Successfully parsed {len(actions_data['actions'])} actions from the timeline\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError parsing JSON output: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c160cfa-d973-40f1-8e7f-ba2cd3d7a610",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this notebook, we've explored the powerful video analysis capabilities of Amazon Nova Premier, with a particular focus on temporal understanding. These capabilities enable a wide range of applications that require understanding when and how events unfold in video content.\n",
    "\n",
    "## Key Capabilities Demonstrated\n",
    "\n",
    "### 1. Comprehensive Video Content Understanding\n",
    "Amazon Nova Premier demonstrated sophisticated understanding of video content including:\n",
    "- Scene recognition and narrative comprehension\n",
    "- Character identification and relationships\n",
    "- Environmental context and setting details\n",
    "- Cinematographic elements and techniques\n",
    "\n",
    "### 2. Precise Temporal Localization\n",
    "The model showed remarkable ability to pinpoint specific events with accurate timestamps:\n",
    "- Environmental changes (rain starting)\n",
    "- Character appearances and actions\n",
    "- Camera technique transitions\n",
    "- Narrative developments\n",
    "\n",
    "### 3. Structured Output Generation\n",
    "We demonstrated how to guide the model to produce structured outputs that:\n",
    "- Follow specific JSON formats\n",
    "- Include precise timing information\n",
    "- Organize events chronologically\n",
    "- Describe actions concisely and consistently\n",
    "\n",
    "## Potential Applications\n",
    "\n",
    "The capabilities demonstrated in this notebook can be applied to many real-world scenarios:\n",
    "\n",
    "1. **Content Moderation**\n",
    "   - Identifying timestamps of potentially problematic content\n",
    "   - Flagging specific moments for human review\n",
    "\n",
    "2. **Media Production**\n",
    "   - Automated scene indexing and cataloging\n",
    "   - Finding specific shots or camera angles\n",
    "\n",
    "3. **Educational Content**\n",
    "   - Creating navigation points for instructional videos\n",
    "   - Generating timestamped summaries of presentations\n",
    "\n",
    "4. **Accessibility**\n",
    "   - Enhanced audio descriptions with precise timing\n",
    "   - Better navigation for users with visual impairments\n",
    "\n",
    "5. **Content Discovery**\n",
    "   - Making video content searchable by specific actions or events\n",
    "   - Generating preview highlights automatically\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "For more information on video understanding with Amazon Nova models, refer to the [AWS Video Understanding documentation](https://docs.aws.amazon.com/nova/latest/userguide/prompting-video-understanding.html). This resource provides additional guidance on prompt engineering for optimal video analysis results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
