{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd77c861",
   "metadata": {},
   "source": [
    "# Skills examples \n",
    "\n",
    "This notebook is intended to highlight the different capabilities and skills of our models. This is not an exhaustive list, and the examples are meant to be simple so it's easy to understand what's going on. Note we are mostly using Lite across the examples, because of this.\n",
    "\n",
    "We will not focus on the details around how to invoke the models and what is supported, for that please refer to the Getting Started notebook.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30db7cc6-9a4f-4f6b-89a8-bcf48e094842",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Please make sure you followed the steps outlines in the Quick Start first. Namely, that you have the model enabled on your account and region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987c033b-9f13-466e-8712-6cbf82544443",
   "metadata": {},
   "source": [
    "**Note**: _Below Examples are Text Understanding use cases and can be used with Micro, Lite, Pro, Premier models. You can try other models changing the `DEFAULT_MODEL_ID`_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d7f1ae",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Run the cells in this section to install the required packages.  \n",
    "\n",
    "_IGNORE ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3905f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q --force-reinstall \\\n",
    "    \"botocore>=1.40.26\" \\\n",
    "    \"awscli>=1.29.57\" \\\n",
    "    \"boto3>=1.40.26\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4c7b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc302ce2-7ee6-48b8-819c-5bd45d7e64cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.client import Config\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "LITE_MODEL_ID = \"us.amazon.nova-2-lite-v1:0\"\n",
    "\n",
    "DEFAULT_MODEL_ID = LITE_MODEL_ID\n",
    "\n",
    "client = boto3.client(\"bedrock-runtime\", \n",
    "                      region_name=\"us-east-1\",\n",
    "                      config=Config(read_timeout=10000)\n",
    "                    )\n",
    "\n",
    "def invoke(prompt, model_id=DEFAULT_MODEL_ID, maxtokens=1000,reasoning=\"high\"):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": [{\"text\": prompt}]},\n",
    "    ]\n",
    "\n",
    "    if reasoning == \"high\":\n",
    "        inference_config = {\n",
    "            \"reasoningConfig\": {\n",
    "                \"type\": \"enabled\",\n",
    "                \"maxReasoningEffort\": reasoning\n",
    "            }\n",
    "        } \n",
    "    else:\n",
    "        inference_config = {\n",
    "            \"maxTokens\": maxtokens, \n",
    "            \"topP\": 0.9, \n",
    "            \"temperature\": 0.7,\n",
    "            \"reasoningConfig\": {\n",
    "                \"type\": \"enabled\",\n",
    "                \"maxReasoningEffort\": reasoning\n",
    "            }\n",
    "        } \n",
    "   \n",
    "    request = {\n",
    "        \"messages\": messages,\n",
    "        \"inferenceConfig\": inference_config,\n",
    "    }\n",
    "\n",
    "    response = client.invoke_model(modelId=model_id, body=json.dumps(request))\n",
    "    model_response = json.loads(response['body'].read().decode('utf-8'))\n",
    "    if len(model_response[\"output\"][\"message\"][\"content\"]) > 1:\n",
    "        return model_response[\"output\"][\"message\"][\"content\"][1][\"text\"]\n",
    "    else:\n",
    "        print(model_response[\"output\"][\"message\"][\"content\"])\n",
    "        return \"Unexpected error occurred\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d608ef",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Examples of skills\n",
    "\n",
    "### Text Summarization\n",
    "\n",
    "In this example, we download the full book Alice in Wonderland by Lewis Carroll, and ask the model to summarize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10e9b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell may take 1-2 minute to run\n",
    "import urllib.request\n",
    "BOOK_LEN = 3200000\n",
    "\n",
    "def download_url(url):\n",
    "    try:\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            content = response.read().decode(\"utf-8\")\n",
    "            return content\n",
    "    except urllib.error.URLError as e:\n",
    "        print(f\"Error downloading URL: {e.reason}\")\n",
    "        return None\n",
    "\n",
    "## download the book war and peace\n",
    "book_content = download_url(\"https://www.gutenberg.org/cache/epub/2600/pg2600.txt\")\n",
    "print(f\"The book contains roughly {len(book_content)} characters\")\n",
    "## Summarize the main events in the book. Nova Lite has a context window of 1MM tokens\n",
    "pprint(invoke(f\"Summarize the main events in following book in less than 500 words: {book_content[:BOOK_LEN]}\", maxtokens=4096))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1953840f",
   "metadata": {},
   "source": [
    "### Question Answering\n",
    "\n",
    "This example show how the model can respond to questions about content of the book summarized in the previous cell. We will ask few questions that willbe answered from the book 'War and Peace' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ad23c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell may take a bit longer to run (1-2 Mins)\n",
    "## Question 1 \n",
    "print(\n",
    "    invoke(f\"\"\"\n",
    "**Question:**\n",
    "Prince Bolkonsky’s pride keeps him from stooping to the politicking and self-promotion of other\n",
    "staff officers and court officials—yet it also poisons his relationship with his wife, Lise, with his\n",
    "sister, Marya, and, for much of the book, with his one-time fiancée, Natasha. How does a terrible\n",
    "wound and a lingering illness change his attitude toward Marya, Natasha, and life in general?\n",
    "DO NOT USE INFORMATION THAT IS NOT IN REFERENCE TEXTS!\n",
    "\n",
    "**Reference Text:**\n",
    "{book_content[:BOOK_LEN]}\n",
    "\"\"\",\n",
    "maxtokens=8092\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043d9bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell may take a bit longer to run (1-2 Mins)\n",
    "## Question 2\n",
    "print(\n",
    "    invoke(f\"\"\"\n",
    "**Question:** \n",
    "What are the main events described in the book in Reference text below?\n",
    "DO NOT USE INFORMATION THAT IS NOT IN REFERENCE TEXTS!\n",
    "\n",
    "**Reference Text:**\n",
    "{book_content[:BOOK_LEN]}\n",
    "\"\"\",\n",
    "reasoning=\"high\"\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df54c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell may take a bit longer to run (1-2 Mins)\n",
    "## Question 3\n",
    "print(\n",
    "    invoke(f\"\"\"\n",
    "**Question:** \n",
    "Pierre’s passionate attachment to the world of ideas takes him from one enthusiasm to another—\n",
    "from free-thinking Francophile to philanthropic Freemason to would-be assassin of the Antichrist,\n",
    "Napoleon. What do you think Pierre is searching for? Why is he invariably ineffective when trying\n",
    "to translate his enthusiasms into practical results? And how has he changed by the end of the\n",
    "book\n",
    "DO NOT USE INFORMATION THAT IS NOT IN REFERENCE TEXTS!\n",
    "\n",
    "**Reference Text:**\n",
    "{book_content[:BOOK_LEN]}\n",
    "\"\"\",\n",
    "reasoning=\"high\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d902eeac",
   "metadata": {},
   "source": [
    "### Content Generation\n",
    "\n",
    "This example shows how the model can generate creative text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef15b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(invoke(f\"Write an ode to the commuting to work in less than 200 words\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678ffe2f",
   "metadata": {},
   "source": [
    "### Text Translation\n",
    "\n",
    "Below we have a passage from Le Petit Prince by Antoine de Saint-Exupéry. We will ask model to identify the language, ask it (in english) to identify the book, ask it about the narrative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab880011",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"J'ai sauté sur mes pieds comme si j'avais été frappé par la foudre. \n",
    "          J'ai bien frotté mes yeux. J'ai bien regardé. \n",
    "          Et j'ai vu un petit bonhomme tout à fait extraordinaire qui me considérait gravement. \n",
    "          Voilà le meilleur portrait que, plus tard, j'ai réussi à faire de lui. \n",
    "          Mais mon dessin, bien sûr, est beaucoup moins ravissant que le modèle. \n",
    "          Ce n'est pas ma faute. J'avais été découragé dans ma carrière de peintre par les grandes personnes, \n",
    "          à l'age de six ans, et je n'avais rien appris à dessiner, sauf les boas fermés et les boas ouverts. \"\"\"\n",
    "print(invoke(f\"What language is this passage in: {text}\"))\n",
    "print(invoke(f\"What book contains this passage: {text}\"))\n",
    "print(invoke(f\"What did the character in this passage saw: {text}\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd698821",
   "metadata": {},
   "source": [
    "### Text Analysis & Recommendations\n",
    "\n",
    "In this example we show model's capability to understand text and sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e22275",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"\"\"First off, the price alone probably led you here to start inquiring about reviews of quality. Fear not, \n",
    "            you get a lot more bag than the price suggests. Right out of the box, soft leather without much of that \n",
    "            leather smell. Medium brown color is classic and goes with plenty of styles. Overall, well made and provides \n",
    "            a lot of space for storage on your travels.\n",
    "            I've noticed that the leather scent starts to increase with wear, which is quite pleasant. \n",
    "            The feel remains soft and durability seems to be quite good.\n",
    "\n",
    "            Overall, great bag for the price considering you are getting a leather bag, \n",
    "            from a known solid brand name, all for under $100.00. The single only negative I have found with this bag is the latches \n",
    "            used to open and close the bag. They look nice and do their job, however they are a bit cheap and aren't \n",
    "            exactly quick and easy to use. They click into place just fine, but opening them is a fumbling challenge \n",
    "            as they do not have much give in the spring used to release the clip. I've gotten use to it, but don't \n",
    "            expect to quickly grab a business card at a moments notice as you'll be standing there till tomorrow \n",
    "            fumbling with the darn clip. A bit of an exaggeration that will change from user to user, but nonetheless \n",
    "            something worth mentioning.\n",
    "            \n",
    "            Don't over think this purchase. If you have the budget for a $500.00 bag, then by all means \n",
    "            keep searching as I do believe in getting what you pay for. However, the manufacture \n",
    "            retail price is $300, so you won't be scraping the bottom of the barrel. Grab this one while you can!\"\"\"\n",
    "print(\n",
    "    invoke(\n",
    "        f\"Answer with positive or negative, based on the sentiment on this review: {review}\"\n",
    "    )\n",
    ")\n",
    "print(invoke(f\"List the things liked in this product review: {review}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faa3145",
   "metadata": {},
   "source": [
    "### Dialogue and Conversation \n",
    "\n",
    "The following example shows how to use messages to create a back and forth chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d288a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_turn_messages = []\n",
    "\n",
    "\n",
    "def turn(prompt):\n",
    "    multi_turn_messages.append({\"role\": \"user\", \"content\": [{\"text\": prompt}]})\n",
    "\n",
    "    inference_config = {\n",
    "        \"maxTokens\": 1000, \n",
    "        \"topP\": 0.9, \n",
    "        \"temperature\": 0.7,\n",
    "        \"reasoningConfig\": {\n",
    "            \"type\": \"enabled\",\n",
    "            \"maxReasoningEffort\": \"low\"\n",
    "        }\n",
    "    } \n",
    "\n",
    "    request = {\n",
    "        \"messages\": multi_turn_messages,\n",
    "        \"system\": [{ \"text\": \"Respond with short, concise answers\" }],\n",
    "        \"inferenceConfig\": inference_config,\n",
    "    }\n",
    "\n",
    "    response = client.invoke_model(modelId=DEFAULT_MODEL_ID, body=json.dumps(request))\n",
    "    model_response = json.loads(response[\"body\"].read())\n",
    "    output_message = model_response[\"output\"][\"message\"]\n",
    "    multi_turn_messages.append(output_message)\n",
    "    assistant_resp = output_message[\"content\"][1][\"text\"]\n",
    "    print(f\"User: {prompt}\")\n",
    "    print(f\"Assistant: {assistant_resp}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "\n",
    "pprint(turn(\"My name is Alice, I'm 30 years old, I moved to Seattle 9 years ago\"))\n",
    "pprint(turn(\"What's my name?\"))\n",
    "pprint(turn(\"Where do I live?\"))\n",
    "pprint(turn(\"At what age did I move to Seattle?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc472f17",
   "metadata": {},
   "source": [
    "### Code Explanation & Generation\n",
    "\n",
    "In the following example ask the model to generate code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ae61ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate source code for a specified problem \n",
    "solution_response = invoke(\n",
    "        \"\"\"Write a 'odd_even' function in Python that takes in a list of numbers, and return a tuple with (odd numbers, even numbers).\n",
    "        Do not explain your Approach or explanation in your response \"\"\",\n",
    "        maxtokens=2048\n",
    "    )\n",
    "print(solution_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8957430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nova Lite executes the source code to validate the code and results\n",
    "response = invoke(f\"\"\"Run the code enclosed between ```python and ``` in a sandbox environment using code interpreter \n",
    "                      and show execution results\n",
    "                      {solution_response}\"\"\",\n",
    "                      maxtokens=4096)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8f88f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions to converse with Nova models with streaming option\n",
    "\n",
    "def converse_with_nova_with_streaming(client, native_request, show_full_response=False):\n",
    "\n",
    "    # Invoke the model and extract the response body.\n",
    "    model_response = client.converse_stream(**native_request)\n",
    "    # change the show_full_response flag to True to see full response\n",
    "    if show_full_response:\n",
    "        print(\"\\n[Full Response]\")\n",
    "        print(json.dumps(model_response, indent=2))\n",
    "    # Process the response stream\n",
    "    stream = model_response.get(\"stream\")\n",
    "    if stream:\n",
    "        for event in stream:\n",
    "            if 'messageStart' in event:\n",
    "                pass\n",
    "            elif 'contentBlockDelta' in event:\n",
    "                content_block_delta = event[\"contentBlockDelta\"]\n",
    "                if content_block_delta:\n",
    "                    print(content_block_delta.get(\"delta\").get(\"text\"), end=\"\")\n",
    "    else:\n",
    "        print(\"No response stream received.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f275858a",
   "metadata": {},
   "source": [
    "### Multi-turn classification tasks - Example 1\n",
    "\n",
    "The following example shows how to use  multi-turns for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c714f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "  {\"role\": \"user\", \"content\": [{\"text\": \"\"\"Your task is to classify the following texts into the appropriate categories: \n",
    "                                            Food, Entertainment, Health, Wealth, Other.\"\"\",}]},\n",
    "  {\"role\": \"user\", \"content\": [{\"text\": \"I love peperoni pizza.\"}]},\n",
    "  {\"role\": \"assistant\", \"content\": [{\"text\": \"Category: Food\"}]},\n",
    "  {\"role\": \"user\", \"content\": [{\"text\": \"I enjoy watching movies.\"}]},\n",
    "  {\"role\": \"assistant\", \"content\": [{\"text\": \"Category: Entertainment\"}]},\n",
    "  {\"role\": \"user\", \"content\": [{\"text\": \"I am going to the gym after this.\"}]},\n",
    "  {\"role\": \"assistant\", \"content\": [{\"text\": \"Category: Health\"}]},\n",
    "  {\"role\": \"user\", \"content\": [{\"text\": \"I have $20 in my pocket.\"}]},\n",
    "  {\"role\": \"assistant\", \"content\": [{\"text\": \"Category: Wealth\"}]},\n",
    "  {\"role\": \"user\", \"content\": [{\"text\": \"I may win a lottery today\"}]}\n",
    "]\n",
    "\n",
    "inf_params = {\n",
    "                \"maxTokens\": 10000, \n",
    "                \"topP\": 0.9, \n",
    "                \"temperature\": 0.7,\n",
    "            } \n",
    "\n",
    "native_request = {\n",
    "    \"modelId\": DEFAULT_MODEL_ID,\n",
    "    \"messages\": messages,\n",
    "    \"inferenceConfig\": inf_params,\n",
    "    # define reasoning configuration \n",
    "    \"additionalModelRequestFields\": {\n",
    "        \"reasoningConfig\": {\n",
    "        \"type\": \"enabled\",\n",
    "        \"maxReasoningEffort\": \"low\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "converse_with_nova_with_streaming(client, native_request)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9794ecc",
   "metadata": {},
   "source": [
    "### Multi-turn classification tasks - Example 2\n",
    "\n",
    "The following cell shows example of Not spam classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a32d0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Examples are taken from opensource email-spam-classification database on huggingface \n",
    "## https://huggingface.co/datasets/UniqueData/email-spam-classification   \n",
    "\n",
    "messages = [\n",
    "  {\"role\": \"user\", \"content\": [{\"text\": \"\"\"Your task is to classify the following email texts into the appropriate categories: \n",
    "                                            Spam, Not_Spam.\n",
    "\n",
    "                                            You also explain your rationale briefly.\"\"\",}]},\n",
    "  {\"role\": \"user\", \"content\": [{\"text\": \"\"\"Hi James,  Have you claim your complimentary gift yet?  \n",
    "                                           I've compiled in here a special astrology gift that predicts everything about you in the future?  \n",
    "                                           This is your enabler to take the correct actions now.  \n",
    "                                           >> Click here to claim your copy now >>  \n",
    "                                           Claim yours now, and thank me later.   Love, Heather\"\"\"}]},\n",
    "  {\"role\": \"assistant\", \"content\": [{\"text\": \"Category: Spam\"}]},\n",
    "\n",
    "  {\"role\": \"user\", \"content\": [{\"text\": \"\"\"Here's your GitHub launch code, @Mortyj420!  \n",
    "                                           an octocat standing next to a rocket Continue signing up for GitHub by \n",
    "                                           entering the code below: 63024610  Open GitHub\"\"\"}]},\n",
    "  {\"role\": \"assistant\", \"content\": [{\"text\": \"Category: Not_Spam\"}]},\n",
    "\n",
    "  {\"role\": \"user\", \"content\": [{\"text\": \"\"\"Hello Walid,  Do you have $7?  \n",
    "                                           I ask because I'm about to do something STUPID.  \n",
    "                                           The thing is, what I'm about to offer you isn't just amazing, \n",
    "                                           it's totally CRAZY.  Here's the deal:  Pay $7 and I'll give you $177 back.  \n",
    "                                           Seriously, as if that wasn't good enough value, the products you'll \n",
    "                                           get have the potential to create you a $7000 a month income!  \n",
    "                                           See exactly what you get for you $7 HERE.  Regards,  Charlie\"\"\"}]},\n",
    "  {\"role\": \"assistant\", \"content\": [{\"text\": \"Category: Spam\"}]},\n",
    "\n",
    "  {\"role\": \"user\", \"content\": [{\"text\": \"\"\" Model Casting Call Thank you for taking the time to register for the \n",
    "                                            Anambra Fashion Expo 2023 Model Call. We are thrilled to have received your information and \n",
    "                                            are excited to review your submission.  Our team will be carefully reviewing all \n",
    "                                            of the applications we receive over the next few weeks  Have you followed us on \n",
    "                                            our social media handles?  Remember, one of the prerequisites for qualification \n",
    "                                            is to follow all our social media accounts and share all our content using the \n",
    "                                            hashtag #AFE2023  You can follow us on Facebook, Instagram, and Twitter.  \n",
    "                                            Facebook: https://facebook.com/AnambraFashionExpo2023 \n",
    "                                            Instagram: https://instagram.com/anambrafashionexpo \n",
    "                                            Twitter: https://twitter.com/anambrafashion  In the meantime, we encourage you to \n",
    "                                            stay connected and keep an eye out for updates about the event. We will be posting! \n",
    "                                             Note: Create your personalized profile picture (DP) for the Model Casting of the \n",
    "                                             Anambra Fashion Expo 2023  You can create your DP using the following \n",
    "                                             link: https://getdp.co/afe2023  Best Regards,  Anambra Fashion Expo 2023 Team\"\"\"}]},\n",
    "  {\"role\": \"assistant\", \"content\": [{\"text\": \"Category: Not_Spam\"}]},\n",
    "\n",
    "  {\"role\": \"user\", \"content\": [{\"text\": \"\"\"RE: Sales Executive  Dear Hiring Professional  I am contacting you to express my interest in \n",
    "                                           the Sales Executive position. After reviewing the position requirements, \n",
    "                                           I believe that my education and experience are a great match for this position.  \n",
    "                                           I am an energetic and decisive negotiator with skills in goal-setting, sales and recommending \n",
    "                                           products. I have a natural talent for building immediate rapport with people and cultivating \n",
    "                                           productive connections. Likewise, I am fully capable of working with strong personalities and \n",
    "                                           navigating through high-pressure situations.  For more details, please review my attached resume. \n",
    "                                           I believe that I can be the Sales Executive you're looking for and welcome the opportunity to \n",
    "                                           speak with you at your earliest convenience.  Sincerely,  Zandi Tamane\"\"\"}]}\n",
    "]\n",
    "\n",
    "inf_params = {\n",
    "                \"maxTokens\": 10000, \"topP\": 0.9, \"temperature\": 0.7,\n",
    "            } \n",
    "\n",
    "native_request = {\n",
    "    \"modelId\": DEFAULT_MODEL_ID,\n",
    "    \"messages\": messages,\n",
    "    \"inferenceConfig\": inf_params,\n",
    "    # define reasoning configuration \n",
    "    \"additionalModelRequestFields\": {\n",
    "        \"reasoningConfig\": {\n",
    "        \"type\": \"enabled\",\n",
    "        \"maxReasoningEffort\": \"low\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "converse_with_nova_with_streaming(client, native_request)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3049148",
   "metadata": {},
   "source": [
    "### Multi-turn classification tasks - Example 3\n",
    "\n",
    "The following cell shows example of spam classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9f9892",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Examples are taken from opensource email-spam-classification database on huggingface \n",
    "## https://huggingface.co/datasets/UniqueData/email-spam-classification   \n",
    "\n",
    "messages = [\n",
    "  {\"role\": \"user\", \"content\": [{\"text\": \"\"\"Your task is to classify the following email texts into the appropriate categories: \n",
    "                                            Spam, Not_Spam.\n",
    "\n",
    "                                            You also explain your rationale briefly.\"\"\",}]},\n",
    "  {\"role\": \"user\", \"content\": [{\"text\": \"\"\"Hi James,  Have you claim your complimentary gift yet?  \n",
    "                                           I've compiled in here a special astrology gift that predicts everything about you in the future?  \n",
    "                                           This is your enabler to take the correct actions now.  \n",
    "                                           >> Click here to claim your copy now >>  \n",
    "                                           Claim yours now, and thank me later.   Love, Heather\"\"\"}]},\n",
    "  {\"role\": \"assistant\", \"content\": [{\"text\": \"Category: Spam\"}]},\n",
    "\n",
    "  {\"role\": \"user\", \"content\": [{\"text\": \"\"\"Here's your GitHub launch code, @Mortyj420!  \n",
    "                                           an octocat standing next to a rocket Continue signing up for GitHub by \n",
    "                                           entering the code below: 63024610  Open GitHub\"\"\"}]},\n",
    "  {\"role\": \"assistant\", \"content\": [{\"text\": \"Category: Not_Spam\"}]},\n",
    "\n",
    "  {\"role\": \"user\", \"content\": [{\"text\": \"\"\"Hello Walid,  Do you have $7?  \n",
    "                                           I ask because I'm about to do something STUPID.  \n",
    "                                           The thing is, what I'm about to offer you isn't just amazing, \n",
    "                                           it's totally CRAZY.  Here's the deal:  Pay $7 and I'll give you $177 back.  \n",
    "                                           Seriously, as if that wasn't good enough value, the products you'll \n",
    "                                           get have the potential to create you a $7000 a month income!  \n",
    "                                           See exactly what you get for you $7 HERE.  Regards,  Charlie\"\"\"}]},\n",
    "  {\"role\": \"assistant\", \"content\": [{\"text\": \"Category: Spam\"}]},\n",
    "\n",
    "  {\"role\": \"user\", \"content\": [{\"text\": \"\"\" Model Casting Call Thank you for taking the time to register for the \n",
    "                                            Anambra Fashion Expo 2023 Model Call. We are thrilled to have received your information and \n",
    "                                            are excited to review your submission.  Our team will be carefully reviewing all \n",
    "                                            of the applications we receive over the next few weeks  Have you followed us on \n",
    "                                            our social media handles?  Remember, one of the prerequisites for qualification \n",
    "                                            is to follow all our social media accounts and share all our content using the \n",
    "                                            hashtag #AFE2023  You can follow us on Facebook, Instagram, and Twitter.  \n",
    "                                            Facebook: https://facebook.com/AnambraFashionExpo2023 \n",
    "                                            Instagram: https://instagram.com/anambrafashionexpo \n",
    "                                            Twitter: https://twitter.com/anambrafashion  In the meantime, we encourage you to \n",
    "                                            stay connected and keep an eye out for updates about the event. We will be posting! \n",
    "                                             Note: Create your personalized profile picture (DP) for the Model Casting of the \n",
    "                                             Anambra Fashion Expo 2023  You can create your DP using the following \n",
    "                                             link: https://getdp.co/afe2023  Best Regards,  Anambra Fashion Expo 2023 Team\"\"\"}]},\n",
    "  {\"role\": \"assistant\", \"content\": [{\"text\": \"Category: Not_Spam\"}]},\n",
    "\n",
    "  {\"role\": \"user\", \"content\": [{\"text\": \"\"\"Hi Walid,  Do you listen to music on Spotify, YouTube, Amazon or Apple?  \n",
    "                                           If you do - you qualify!  You could be making $50 for every song you stream...  \n",
    "                                           All it takes is 3 steps...  Step 1: Create Your Account Create your account here  \n",
    "                                           Step 2: Pick Your Favourite Artist Select from thousands of artists and vibe to the music  \n",
    "                                           Step 3: Get Paid That's it, for every song you stream...  \n",
    "                                           => Click here right now to start instantly  \n",
    "                                           Regards,  Alex  --- ?? \n",
    "                                           Connect with us on Telegram: https://t.me/moneymakingcentral\"\"\"}]}\n",
    "]\n",
    "\n",
    "inf_params = {\n",
    "                \"maxTokens\": 10000, \"topP\": 0.9, \"temperature\": 0.7,\n",
    "            } \n",
    "\n",
    "native_request = {\n",
    "    \"modelId\": DEFAULT_MODEL_ID,\n",
    "    \"messages\": messages,\n",
    "    \"inferenceConfig\": inf_params,\n",
    "    # define reasoning configuration \n",
    "    \"additionalModelRequestFields\": {\n",
    "        \"reasoningConfig\": {\n",
    "        \"type\": \"enabled\",\n",
    "        \"maxReasoningEffort\": \"low\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "converse_with_nova_with_streaming(client, native_request)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".nova-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
