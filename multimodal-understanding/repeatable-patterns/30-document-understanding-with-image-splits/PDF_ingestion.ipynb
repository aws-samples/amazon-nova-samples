{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ba517d7-a6f0-4d6b-bd2b-d6b786635c0a",
   "metadata": {},
   "source": [
    "### PDF Document Ingestion\n",
    "\n",
    "The following example shows using the convert_pdf_to_png_images method to convert a multi-page pdf to an array of images which have been resized to the optimal resolution for PDF documents. This can be used in cases where current Nova Docuemnt Understanding does not support different images that might be present in the document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be690c99-2d4e-4185-bcee-99b2f9115806",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcf869d-9081-4f34-8680-f01969658f71",
   "metadata": {},
   "source": [
    "We are using a python package - [pdf2image](https://pypi.org/project/pdf2image/) that is an extremely powerful tool to convert pdfs.\n",
    "\n",
    "This package is dependent on Poppler and needs to be installed first (for other ways to install you can refer to the link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487ef136-521e-455f-83c0-5619bc5adad9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%conda install -y -c conda-forge poppler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71eaa052-e597-448d-b5ca-6f9d8728d013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.python.org/simple\n",
      "Collecting pdf2image\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: Pillow in /Users/dewanup/.pyenv/versions/3.13.3/lib/python3.13/site-packages (11.2.1)\n",
      "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pdf2image\n",
      "Successfully installed pdf2image-1.17.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pdf2image Pillow "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28bf69b-c2e7-4977-a7bc-b0eecddc389f",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cffb548-bdd4-449e-80bf-209d5bed0fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed page 1\n",
      "Processed page 2\n",
      "[Full Response]\n",
      "{\n",
      "  \"output\": {\n",
      "    \"message\": {\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"text\": \"The document outlines the agenda for the \\\"Observability Immersion Day\\\" event, which is part of the AWS Immersion Days v2.0. The event is scheduled for September 5, 2023, and is focused on various AWS observability services. Here is a detailed summary of the agenda:\\n\\n1. **Introduction to Observability (8:00 AM - 8:10 AM)**\\n   - Overview of observability and AWS Observability services.\\n\\n2. **AWS Observability Options (8:10 AM - 8:20 AM)**\\n   - Introduction to the AWS observability suite of services.\\n\\n3. **CloudWatch Container Insights (8:20 AM - 8:30 AM)**\\n   - Use CloudWatch Container Insights to collect, aggregate, and summarize metrics and logs from containerized applications and microservices. Available for Amazon Elastic Container Service (ECS), Amazon Elastic Kubernetes Service (EKS), and Kubernetes on Amazon EC2.\\n\\n4. **CloudWatch Container Insights Lab (8:30 AM - 9:00 AM)**\\n   - Hands-on lab to learn how to use Container Insights with Elastic Container Service and Elastic Kubernetes Service.\\n\\n5. **CloudWatch Logs Insights (9:00 AM - 9:10 AM)**\\n   - CloudWatch Logs Insights enables interactive search and analysis of log data in Amazon CloudWatch Logs. It helps in performing queries to respond to operational\"\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\"\n",
      "    }\n",
      "  },\n",
      "  \"stopReason\": \"max_tokens\",\n",
      "  \"usage\": {\n",
      "    \"inputTokens\": 3246,\n",
      "    \"outputTokens\": 300,\n",
      "    \"totalTokens\": 3546,\n",
      "    \"cacheReadInputTokenCount\": 0,\n",
      "    \"cacheWriteInputTokenCount\": 0\n",
      "  }\n",
      "}\n",
      "\n",
      "[Response Content Text]\n",
      "The document outlines the agenda for the \"Observability Immersion Day\" event, which is part of the AWS Immersion Days v2.0. The event is scheduled for September 5, 2023, and is focused on various AWS observability services. Here is a detailed summary of the agenda:\n",
      "\n",
      "1. **Introduction to Observability (8:00 AM - 8:10 AM)**\n",
      "   - Overview of observability and AWS Observability services.\n",
      "\n",
      "2. **AWS Observability Options (8:10 AM - 8:20 AM)**\n",
      "   - Introduction to the AWS observability suite of services.\n",
      "\n",
      "3. **CloudWatch Container Insights (8:20 AM - 8:30 AM)**\n",
      "   - Use CloudWatch Container Insights to collect, aggregate, and summarize metrics and logs from containerized applications and microservices. Available for Amazon Elastic Container Service (ECS), Amazon Elastic Kubernetes Service (EKS), and Kubernetes on Amazon EC2.\n",
      "\n",
      "4. **CloudWatch Container Insights Lab (8:30 AM - 9:00 AM)**\n",
      "   - Hands-on lab to learn how to use Container Insights with Elastic Container Service and Elastic Kubernetes Service.\n",
      "\n",
      "5. **CloudWatch Logs Insights (9:00 AM - 9:10 AM)**\n",
      "   - CloudWatch Logs Insights enables interactive search and analysis of log data in Amazon CloudWatch Logs. It helps in performing queries to respond to operational\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "from lib.pdf_to_image import convert_pdf_to_png_images\n",
    "\n",
    "# Create a Bedrock Runtime client in the AWS Region of your choice.\n",
    "client = boto3.client(\n",
    "    \"bedrock-runtime\",\n",
    "    region_name=\"us-east-1\",\n",
    ")\n",
    "\n",
    "LITE_MODEL_ID = \"us.amazon.nova-lite-v1:0\"\n",
    "\n",
    "# Convert your PDF to images\n",
    "\n",
    "base64_images = convert_pdf_to_png_images('./immersion_day.pdf')\n",
    "\n",
    "# Define your system prompt(s).\n",
    "system_list = [\n",
    "    {\n",
    "        \"type\": \"system\",\n",
    "        \"content\": [{\"text\": \"You will be given images of a document.\"}],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create user content block\n",
    "content = sum([[{\"text\": f\"Image {idx+1}:\"}, {\"image\": {\"format\": \"png\", \"source\": {\"bytes\": img}}}] for idx, img in enumerate(base64_images)], [])\n",
    "\n",
    "content.append({\n",
    "    \"text\": \"Provide a summary of the provided document\"\n",
    "})\n",
    "\n",
    "\n",
    "# Define a \"user\" message including both the image and a text prompt.\n",
    "message_list = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": content\n",
    "    }\n",
    "]\n",
    "\n",
    "# Configure the inference parameters.\n",
    "inf_params = {\"max_new_tokens\": 300, \"top_p\": 0.1, \"top_k\": 20, \"temperature\": 0.3}\n",
    "\n",
    "native_request = {\n",
    "    \"schemaVersion\": \"messages-v1\",\n",
    "    \"messages\": message_list,\n",
    "    \"system\": system_list,\n",
    "    \"inferenceConfig\": inf_params,\n",
    "}\n",
    "\n",
    "# Invoke the model and extract the response body.\n",
    "response = client.invoke_model(modelId=LITE_MODEL_ID, body=json.dumps(native_request))\n",
    "model_response = json.loads(response[\"body\"].read())\n",
    "\n",
    "# Pretty print the response JSON.\n",
    "print(\"[Full Response]\")\n",
    "print(json.dumps(model_response, indent=2))\n",
    "\n",
    "# Print the text content for easy readability.\n",
    "content_text = model_response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "print(\"\\n[Response Content Text]\")\n",
    "print(content_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0199f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
