{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe8d615b-fa47-485b-9dc3-13fe1937d04f",
   "metadata": {},
   "source": [
    "# Amazon Nova Premier - Temporal Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a1c8d4-c1d1-412e-ad89-984066da48bc",
   "metadata": {},
   "source": [
    "##### In this notebook, you will interact with Amazon Nova Premier to complete some temporal understanding tasks using a video. You will need following services to complete the notebook:\n",
    "\n",
    "1. Amazon S3 - You will store your video in Amazon S3.\n",
    "\n",
    "2. Amazon Bedrock - You will access Amazon Nova Premier using the Amazon Bedrock Invoke Model API.\n",
    "\n",
    "3. Amazon Trancribe - You will use Amazon Transcribe to extract the video transcript for video Q&A where Nova will use the video's visual and transcript to answer questions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f5e4ef-f296-48cd-943b-6b2b3701daf8",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d75138-3ed9-4650-9f72-d41f9072e83a",
   "metadata": {},
   "source": [
    "##### Install the Python packages that this notebook uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7379a75-52e9-4a0b-b77c-14aba49c623b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install webvtt-py boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981822a3-b6ca-4b58-8d13-d5122204d892",
   "metadata": {},
   "source": [
    "##### Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9ec419-e1c9-45f3-a223-9537af3b3421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "#Amazon Bedrock imports\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "#Transcript extraction import\n",
    "import webvtt\n",
    "\n",
    "#Helper utilities\n",
    "from IPython.display import  Video\n",
    "import pprint\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "import json \n",
    "import base64\n",
    "import logging\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210d4061-c854-45f2-bf9f-89c59650d80a",
   "metadata": {},
   "source": [
    "##### Upload your video to Amazon S3 and update the variables below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe2e69f-13e2-4f26-ab9d-98e88735181d",
   "metadata": {},
   "source": [
    "\n",
    "You will use a clip from Meridian, a film from Netflix Open Content, for this notebook.\n",
    "In the 'Video' folder, locate the video 'Meridian_Clip.mp4.' Download the video and store it in an Amazon S3 bucket of your choice. Create a new bucket if needed and create a folder within the bucket to store the video. Also, create another folder within the bucket to store the transcript for the video (we will extract the transcript in this notebook, simply create an empty transcript folder for now)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489e3fdc-9616-4422-ac1d-ee8b7877f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket= \"{bucket-name}\"  #update with the name of your bucket\n",
    "video_path= \"{video-folder-name}\"  #update with the folder you created to store the video\n",
    "transcription_output_path= \"{transcript-folder-name}\" #update with the folder you created to store the transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b003cc-bd69-4d34-a50d-355b9d0a2d1a",
   "metadata": {},
   "source": [
    " Create the boto3 clients for services used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27524616-2864-4d92-86be-b999e7d47ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#credentials and clients\n",
    "aws_account_id  = boto3.client('sts').get_caller_identity()['Account']  \n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "print(sess)\n",
    "print(role)\n",
    "\n",
    "\n",
    "region = boto3.Session().region_name \n",
    "print(region)\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "bedrock_client = boto3.client(service_name='bedrock-runtime', \n",
    "                              region_name=region)\n",
    "transcribe_client = boto3.client('transcribe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20e6e08-0333-4999-94b9-f99c0d4ba927",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "Ensure the IAM role you are using for your notebook, which is shown in the cell ouptut above as '(arn:aws:iam::{account ID}:role/{role name}' has the required permissions to access Amazon Bedrock, Amazon Transcribe, and read from your Amazon S3 bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bea5e7d-8385-464c-8501-679d146ffa61",
   "metadata": {},
   "source": [
    "Now, we'll define a function to list all videos in your bucket so that you can select the Meridian video clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66563f7-6744-4854-8579-8fd527c1054b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos(prefix):\n",
    "    all_videos = []\n",
    "    paginator = s3_client.get_paginator('list_objects_v2')\n",
    "    pages = paginator.paginate(Bucket=bucket, Prefix=prefix)\n",
    "    for page in pages:\n",
    "        for obj in page.get('Contents', []):\n",
    "            all_videos.append(obj['Key'])\n",
    "    return all_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3b1b44-010b-4543-905b-2df9f8c8045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for and select the Meridian video from your Amazon S3 bucket\n",
    "\n",
    "videos=get_videos(video_path)\n",
    "selected_video=videos[1] #change the index number to find Meridian_Clip.mp4\n",
    "print(selected_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c23050-8c91-495c-a0f2-9da9d6b506a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a local path for the video \n",
    "\n",
    "local_path =selected_video.split('/')[-1]\n",
    "print(local_path)\n",
    "\n",
    "#download the video locally \n",
    "\n",
    "try:\n",
    "    s3_client.download_file(bucket, selected_video, local_path)\n",
    "    print(f\"Successfully downloaded to {local_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error downloading file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d063f2fb-f3d1-4335-ab90-fc6f08026ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the video within the notebook\n",
    "\n",
    "Video(local_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf70c8c-493b-4700-910f-cde4527601e7",
   "metadata": {},
   "source": [
    "### Analyze video with Nova Premier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a073c334-37a8-4fdc-9c65-c54a47496e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the variable for Amazon Nova Premier\n",
    "\n",
    "PREMIER_MODEL_ID= \"us.amazon.nova-premier-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be92bfd5-b5d7-4248-bf8d-8a25dfbe5254",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the Amazon S3 uri in a variable to use in the payload to Nova\n",
    "\n",
    "uri = \"s3://{0}/{1}\".format(bucket, selected_video)\n",
    "print(uri)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58e2aa2-2f12-4516-a511-9d63d183a903",
   "metadata": {},
   "source": [
    "#### Task 1: Summarize the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56193da1-7096-4982-925f-98992b5d52a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a system role \n",
    "\n",
    "system_message= \"\"\"\n",
    "\n",
    "You are an expert video and media analyst. You analyze video to extract detailed fact based insights accurately.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#Send video using Amazon S3 location to Amazon Nova with InvokeModel API.\n",
    "\n",
    "system_list = [\n",
    "    {\n",
    "        \"text\": system_message\n",
    "    }\n",
    "]\n",
    "\n",
    "message_list = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"video\": {\n",
    "                    \"format\": \"mp4\",\n",
    "                    \"source\": {\n",
    "                        \"s3Location\": {\n",
    "                            \"uri\": uri\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"Create a concise summary of this video. Identify and describe the key moments or events, limiting your summary to 5 main points in bullet points.\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "inf_params = {\"maxTokens\": 1024, \"topP\": 0.1, \"topK\": 20, \"temperature\": 0.3}\n",
    "\n",
    "\n",
    "native_request = {\n",
    "    \"schemaVersion\": \"messages-v1\",\n",
    "    \"messages\": message_list,\n",
    "    \"system\": system_list,\n",
    "    \"inferenceConfig\": inf_params,\n",
    "}\n",
    "\n",
    "# Invoke the model and extract the response body.\n",
    "response = bedrock_client.invoke_model(modelId=PREMIER_MODEL_ID, body=json.dumps(native_request))\n",
    "model_response = json.loads(response[\"body\"].read())\n",
    "# Pretty print the response JSON.\n",
    "print(\"[Full Response]\")\n",
    "print(json.dumps(model_response, indent=2))\n",
    "# Print the text content for easy readability.\n",
    "content_text = model_response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "print(\"\\n[Response Content Text]\")\n",
    "print(content_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e84cfd-e71d-4786-980f-8f24d29f36b2",
   "metadata": {},
   "source": [
    "#### Task 2: Identify events or items of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4185fd9c-f512-4432-a252-e8744dc214af",
   "metadata": {},
   "source": [
    "Prompt Amazon Nova Premier to identify when it begins to rain in the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf70c33d-167b-4217-b2f1-c0b94c299651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Send video using Amazon S3 location to Amazon Nova with InvokeModel.\n",
    "\n",
    "system_list = [\n",
    "    {\n",
    "        \"text\": system_message\n",
    "    }\n",
    "]\n",
    "\n",
    "message_list = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"video\": {\n",
    "                    \"format\": \"mp4\",\n",
    "                    \"source\": {\n",
    "                        \"s3Location\": {\n",
    "                            \"uri\": uri\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"Identify when it begins to rain in the video. Output your response as a timestamp with the format MM:SS\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "inf_params = {\"maxTokens\": 1024, \"topP\": 0.1, \"topK\": 20, \"temperature\": 0.3}\n",
    "\n",
    "\n",
    "native_request = {\n",
    "    \"schemaVersion\": \"messages-v1\",\n",
    "    \"messages\": message_list,\n",
    "    \"system\": system_list,\n",
    "    \"inferenceConfig\": inf_params,\n",
    "}\n",
    "\n",
    "# Invoke the model and extract the response body.\n",
    "response = bedrock_client.invoke_model(modelId=PREMIER_MODEL_ID, body=json.dumps(native_request))\n",
    "model_response = json.loads(response[\"body\"].read())\n",
    "# Pretty print the response JSON.\n",
    "print(\"[Full Response]\")\n",
    "print(json.dumps(model_response, indent=2))\n",
    "# Print the text content for easy readability.\n",
    "content_text = model_response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "print(\"\\n[Response Content Text]\")\n",
    "print(content_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8a1bd8-92c5-4e46-9fb7-30102525cea5",
   "metadata": {},
   "source": [
    "Prompt Amazon Nova Premier to identify when a character appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61666906-f51a-4299-ab8d-4b65687fc934",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Send video using Amazon S3 location to Amazon Nova with InvokeModel.\n",
    "\n",
    "system_list = [\n",
    "    {\n",
    "        \"text\": system_message\n",
    "    }\n",
    "]\n",
    "\n",
    "message_list = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"video\": {\n",
    "                    \"format\": \"mp4\",\n",
    "                    \"source\": {\n",
    "                        \"s3Location\": {\n",
    "                            \"uri\": uri\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"At what point in the video does a women first appear. Output your response as a timestamp with the format MM:SS\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "inf_params = {\"maxTokens\": 1024, \"topP\": 0.1, \"topK\": 20, \"temperature\": 0.3}\n",
    "\n",
    "\n",
    "native_request = {\n",
    "    \"schemaVersion\": \"messages-v1\",\n",
    "    \"messages\": message_list,\n",
    "    \"system\": system_list,\n",
    "    \"inferenceConfig\": inf_params,\n",
    "}\n",
    "\n",
    "# Invoke the model and extract the response body.\n",
    "response = bedrock_client.invoke_model(modelId=PREMIER_MODEL_ID, body=json.dumps(native_request))\n",
    "model_response = json.loads(response[\"body\"].read())\n",
    "# Pretty print the response JSON.\n",
    "print(\"[Full Response]\")\n",
    "print(json.dumps(model_response, indent=2))\n",
    "# Print the text content for easy readability.\n",
    "content_text = model_response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "print(\"\\n[Response Content Text]\")\n",
    "print(content_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb44957-cc65-4e88-9d3d-5b38f10b5976",
   "metadata": {},
   "source": [
    "Prompt Amazon Nova Premier to identify specific type of camera shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfed9903-d5db-4a93-be93-d691644dbf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Send video using Amazon S3 location to Amazon Nova with InvokeModel.\n",
    "\n",
    "system_list = [\n",
    "    {\n",
    "        \"text\": system_message\n",
    "    }\n",
    "]\n",
    "\n",
    "message_list = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"video\": {\n",
    "                    \"format\": \"mp4\",\n",
    "                    \"source\": {\n",
    "                        \"s3Location\": {\n",
    "                            \"uri\": uri\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"At what point in the video do we see a close up shot of the man in the video. Output your response as a timestamp with the format MM:SS\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "inf_params = {\"maxTokens\": 1024, \"topP\": 0.1, \"topK\": 20, \"temperature\": 0.3}\n",
    "\n",
    "\n",
    "native_request = {\n",
    "    \"schemaVersion\": \"messages-v1\",\n",
    "    \"messages\": message_list,\n",
    "    \"system\": system_list,\n",
    "    \"inferenceConfig\": inf_params,\n",
    "}\n",
    "\n",
    "# Invoke the model and extract the response body.\n",
    "response = bedrock_client.invoke_model(modelId=PREMIER_MODEL_ID, body=json.dumps(native_request))\n",
    "model_response = json.loads(response[\"body\"].read())\n",
    "# Pretty print the response JSON.\n",
    "print(\"[Full Response]\")\n",
    "print(json.dumps(model_response, indent=2))\n",
    "# Print the text content for easy readability.\n",
    "content_text = model_response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "print(\"\\n[Response Content Text]\")\n",
    "print(content_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa95b67-b407-4a9c-b61e-4e467e2caec7",
   "metadata": {},
   "source": [
    "#### Task 3: Identify possible segments in the video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549b4693-541d-4b4b-9f78-4d3955362864",
   "metadata": {},
   "source": [
    "Prompt Amazon Nova Premier to identify segments by actions across the video duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaa0e6d-698e-4acf-948d-5fd0ff6279d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Analyze the video and identify all human actions or activities occurring throughout its duration. \n",
    "\n",
    "Follow these guidelines for your task:\n",
    "1. List each action with its corresponding timestamp range.\n",
    "2. Describe each action succinctly\n",
    "3. Output the timestamp in MM:SS format.\n",
    "4. DO NOT list identical actions consecutively in your output\n",
    "5. Your output should be in the following sample json schema:\n",
    "    {\n",
    "    \"actions\": [\n",
    "        {\n",
    "            \"action\": \"the teacher enters the room\",\n",
    "            \"timestamp\": \"00:15\"\n",
    "        },\n",
    "        {\n",
    "            \"action\": \"the students sit down\", \n",
    "            \"timestamp\": \"00:32\"\n",
    "\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "system_list = [\n",
    "    {\n",
    "        \"text\": system_message\n",
    "    }\n",
    "]\n",
    "\n",
    "message_list = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"video\": {\n",
    "                    \"format\": \"mp4\",\n",
    "                    \"source\": {\n",
    "                        \"s3Location\": {\n",
    "                            \"uri\": uri\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"text\": prompt\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "inf_params = {\"maxTokens\": 1024, \"topP\": 0.1, \"topK\": 20, \"temperature\": 0.3}\n",
    "\n",
    "\n",
    "native_request = {\n",
    "    \"schemaVersion\": \"messages-v1\",\n",
    "    \"messages\": message_list,\n",
    "    \"system\": system_list,\n",
    "    \"inferenceConfig\": inf_params,\n",
    "}\n",
    "\n",
    "# Invoke the model and extract the response body.\n",
    "response = bedrock_client.invoke_model(modelId=PREMIER_MODEL_ID, body=json.dumps(native_request))\n",
    "model_response = json.loads(response[\"body\"].read())\n",
    "# Pretty print the response JSON.\n",
    "print(\"[Full Response]\")\n",
    "print(json.dumps(model_response, indent=2))\n",
    "# Print the text content for easy readability.\n",
    "content_text = model_response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "print(\"\\n[Response Content Text]\")\n",
    "print(content_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c541c93f-7ac1-46d0-8664-ed5e3c93bd1d",
   "metadata": {},
   "source": [
    "#### Task 4: Analyze the video with its transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddee4397-607b-4e8f-840e-246717c89d1d",
   "metadata": {},
   "source": [
    "For some tasks you will need to analyze a video along with the speech heard in the video. For example, a task that requires Amazon Nova to answer questions about actions and intentions in video content can use the video transcript. For this task we will use Amazon Transcribe to extract the video's dialogue. Then, we pass the dialogue and the video to Amazon Nova Premier for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0cef0b-62c3-41fa-b180-255f6cde7952",
   "metadata": {},
   "source": [
    "First, we define a function to analyze the video with Amazon Transcribe and download the transcipt as a webvtt file locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0b9ad0-9235-456b-b358-f57446c4db5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTranscript(videoFile):\n",
    "    file_name_parsed=videoFile.rsplit('/', 1)[-1]\n",
    "    job_name = \"transcription-{0}-{1}\".format(file_name_parsed,round(time.time()))\n",
    "    job_uri = \"s3://{0}/{1}/{2}\".format(bucket, video_path, file_name_parsed)\n",
    "\n",
    "    transcribe_client.start_transcription_job(\n",
    "        TranscriptionJobName = job_name,\n",
    "        Media = {\n",
    "            'MediaFileUri': job_uri\n",
    "        },\n",
    "        OutputBucketName = bucket,\n",
    "        OutputKey = \"{0}/{1}/\".format(transcription_output_path, file_name_parsed),\n",
    "        LanguageCode = 'en-US', \n",
    "        Subtitles = {\n",
    "            'Formats': [\n",
    "                'vtt'\n",
    "            ]\n",
    "       }\n",
    "    )\n",
    "\n",
    "    while True:\n",
    "        status = transcribe_client.get_transcription_job(TranscriptionJobName = job_name)\n",
    "        if status['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
    "            print('transcription for {0} complete'.format(videoFile))\n",
    "            break\n",
    "        print(\"processing {0}\".format(videoFile))\n",
    "        time.sleep(5)\n",
    "    outputVTT = str(status[\"TranscriptionJob\"].get(\"Subtitles\").get('SubtitleFileUris')[0].split('/')[-1])\n",
    "\n",
    "    #download vtt file locally\n",
    "    with open(outputVTT, 'wb') as f:\n",
    "        s3_client.download_fileobj(bucket,'{}/{}/{}'.format(transcription_output_path,file_name_parsed,outputVTT), f)\n",
    "    return outputVTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aa9126-67cd-4903-98c0-332ac7313473",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the previously define function to extract the video transcript and store it  locally\n",
    "transcript_vtt = getTranscript(selected_video)\n",
    "print(transcript_vtt)\n",
    "\n",
    "#read the video transcript as a vtt file and store in a variable to be used in your prompt\n",
    "with open(transcript_vtt, 'r', encoding='utf-8') as file:\n",
    "            vtt_transcript = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2244a8da-dfbf-43b0-8fd0-9a893a1e3404",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a new system prompt to give Nova Premier context\n",
    "\n",
    "system_message= \"\"\"\n",
    "\n",
    "You are an expert video and media analyst. You analyze videos and their transcripts in WEBVTT format to extract detailed insights accurately based on user queries.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#define your Q&A prompt with the transcript VTT file include in the prompt \n",
    "prompt = \"\"\"\n",
    "\n",
    "Transcript:\n",
    "\n",
    "\"\"\" + vtt_transcript + \"\"\"\n",
    "\n",
    "What is the man in the video determined to do? Explain your answer\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581add93-008a-476b-a20c-bc4218cbc39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view your prompt\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d6820e-dd27-4f3b-afe4-95ee51f120b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_list = [\n",
    "    {\n",
    "        \"text\": system_message\n",
    "    }\n",
    "]\n",
    "\n",
    "message_list = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"video\": {\n",
    "                    \"format\": \"mp4\",\n",
    "                    \"source\": {\n",
    "                        \"s3Location\": {\n",
    "                            \"uri\": uri\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"text\": prompt\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "inf_params = {\"maxTokens\": 1024, \"topP\": 0.1, \"topK\": 20, \"temperature\": 0.3}\n",
    "\n",
    "\n",
    "native_request = {\n",
    "    \"schemaVersion\": \"messages-v1\",\n",
    "    \"messages\": message_list,\n",
    "    \"system\": system_list,\n",
    "    \"inferenceConfig\": inf_params,\n",
    "}\n",
    "\n",
    "# Invoke the model and extract the response body.\n",
    "response = bedrock_client.invoke_model(modelId=PREMIER_MODEL_ID, body=json.dumps(native_request))\n",
    "model_response = json.loads(response[\"body\"].read())\n",
    "# Pretty print the response JSON.\n",
    "print(\"[Full Response]\")\n",
    "print(json.dumps(model_response, indent=2))\n",
    "# Print the text content for easy readability.\n",
    "content_text = model_response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "print(\"\\n[Response Content Text]\")\n",
    "print(content_text)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3a5dca-e603-41c4-8f69-084f634ba8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "\n",
    "Transcript:\n",
    "\n",
    "\"\"\" + vtt_transcript + \"\"\"\n",
    "\n",
    "At what points in the video is the man thinking about the details of the case he is investigating?\n",
    "\n",
    "\n",
    "\n",
    "Follow these guidelines for your task:\n",
    "1. Use both the video above and the captions in the prompt \n",
    "2. Format timestamps with minute and seconds as follows: \"MM:SS\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa8a7e0-e204-4f92-b4e1-8201a421ecc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_list = [\n",
    "    {\n",
    "        \"text\": system_message\n",
    "    }\n",
    "]\n",
    "\n",
    "message_list = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"video\": {\n",
    "                    \"format\": \"mp4\",\n",
    "                    \"source\": {\n",
    "                        \"s3Location\": {\n",
    "                            \"uri\": uri\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"text\": prompt\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "inf_params = {\"maxTokens\": 1024, \"topP\": 0.1, \"topK\": 20, \"temperature\": 0.3}\n",
    "\n",
    "\n",
    "native_request = {\n",
    "    \"schemaVersion\": \"messages-v1\",\n",
    "    \"messages\": message_list,\n",
    "    \"system\": system_list,\n",
    "    \"inferenceConfig\": inf_params,\n",
    "}\n",
    "\n",
    "# Invoke the model and extract the response body.\n",
    "response = bedrock_client.invoke_model(modelId=PREMIER_MODEL_ID, body=json.dumps(native_request))\n",
    "model_response = json.loads(response[\"body\"].read())\n",
    "# Pretty print the response JSON.\n",
    "print(\"[Full Response]\")\n",
    "print(json.dumps(model_response, indent=2))\n",
    "# Print the text content for easy readability.\n",
    "content_text = model_response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "print(\"\\n[Response Content Text]\")\n",
    "print(content_text)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c160cfa-d973-40f1-8e7f-ba2cd3d7a610",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758baab5-40f6-410e-9209-9ae2ae76efc2",
   "metadata": {},
   "source": [
    "You've successfully tested some video understanding capabilities using Amazon Nova Premier. \n",
    "\n",
    "What you've accomplished:\n",
    "- Tested prompts for temporal understanding tasks\n",
    "- Explored video analysis capabilities\n",
    "- Learned prompt patterns for video understanding\n",
    "\n",
    "Build on these examples for your specific use cases. Also reference the [AWS Video Understanding documentation](https://docs.aws.amazon.com/nova/latest/userguide/prompting-video-understanding.html) for advanced prompting\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
