{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Nova Meta Prompter\n",
    "\n",
    "Transform any prompt to align with Amazon Nova guidelines.\n",
    "\n",
    "This tool analyzes your existing prompts and adapts them for Amazon Nova capabilities including:\n",
    "- Up to 1M token context\n",
    "- Structured output formatting\n",
    "- Chain-of-thought reasoning\n",
    "- Clear section-based organization\n",
    "\n",
    "## New: Intent-Based Pipeline\n",
    "\n",
    "The meta prompter now includes automatic intent classification:\n",
    "1. **Intent Classification** - Detects what your prompt needs (image understanding, RAG, tool use, etc.)\n",
    "2. **Targeted Guidance Loading** - Only loads relevant prompt guidance for detected intents\n",
    "3. **Optimized Transformation** - Transforms your prompt with focused best practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Configure AWS credentials via environment variables (recommended) or AWS CLI configuration.\n",
    "\n",
    "**Option 1: Environment Variables (Recommended)**\n",
    "```bash\n",
    "import os\n",
    "os.environ[\"AWS_PROFILE\"]=\"your-profile-name\"\n",
    "os.environ[\"AWS_REGION\"]=\"your-aws-region\"\n",
    "```\n",
    "\n",
    "**Option 2: AWS CLI Configuration**\n",
    "```bash\n",
    "aws configure\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the Metaprompter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install nova_metaprompter-0.1.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Credentials\n",
    "\n",
    "Test your AWS credentials and Bedrock access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T12:08:03.529497Z",
     "start_time": "2025-10-08T12:08:01.066644Z"
    },
    "execution": {
     "iopub.execute_input": "2025-10-08T12:22:07.963704Z",
     "iopub.status.busy": "2025-10-08T12:22:07.963476Z",
     "iopub.status.idle": "2025-10-08T12:22:09.232385Z",
     "shell.execute_reply": "2025-10-08T12:22:09.232052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ AWS credentials configured successfully\n",
      "   Region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from botocore.config import Config\n",
    "\n",
    "try:\n",
    "    # This will use AWS_PROFILE and AWS_REGION from environment\n",
    "    client = boto3.client('bedrock-runtime', config=Config(\n",
    "        connect_timeout=3600,  # 60 minutes\n",
    "        read_timeout=3600,     # 60 minutes\n",
    "        retries={'max_attempts': 1}\n",
    "    ))\n",
    "    print(\"‚úÖ AWS credentials configured successfully\")\n",
    "    print(f\"   Region: {client.meta.region_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå AWS credentials error: {e}\")\n",
    "    print(\"   Please set AWS_PROFILE and AWS_REGION environment variables\")\n",
    "    print(\"   Or configure using 'aws configure'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import the transform function and display utilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T12:08:03.547349Z",
     "start_time": "2025-10-08T12:08:03.540417Z"
    },
    "execution": {
     "iopub.execute_input": "2025-10-08T12:22:09.250397Z",
     "iopub.status.busy": "2025-10-08T12:22:09.250281Z",
     "iopub.status.idle": "2025-10-08T12:22:09.254974Z",
     "shell.execute_reply": "2025-10-08T12:22:09.254677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Setup complete!\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "from nova_metaprompter import transform_prompt\n",
    "\n",
    "# Display helper functions\n",
    "def display_section_header(title):\n",
    "    display(HTML(f'<h3 style=\"color: #2E86AB; border-bottom: 2px solid #2E86AB; padding-bottom: 10px;\">{title}</h3>'))\n",
    "\n",
    "def display_original_prompt(prompt, title=\"Original Prompt\"):\n",
    "    display_section_header(title)\n",
    "    display(HTML(f'<div style=\"background-color: #f8f9fa; padding: 15px; border-radius: 5px; border-left: 4px solid #6c757d;\"><pre style=\"white-space: pre-wrap; font-family: monospace;\">{prompt.strip()}</pre></div>'))\n",
    "\n",
    "def display_intent_results(result):\n",
    "    \"\"\"Display intent classification and guidance loading results.\"\"\"\n",
    "    if 'intents' in result:\n",
    "        intents_html = ', '.join([f'<span style=\"background-color: #e3f2fd; padding: 2px 8px; border-radius: 12px; margin: 2px;\">{i}</span>' for i in result['intents']]) or '<em>None detected</em>'\n",
    "        display(HTML(f'<h4 style=\"color: #1565C0;\">üéØ Detected Intents</h4>'))\n",
    "        display(HTML(f'<div style=\"background-color: #e3f2fd; padding: 15px; border-radius: 5px; margin-bottom: 10px;\">{intents_html}</div>'))\n",
    "    \n",
    "    if 'api_capabilities' in result:\n",
    "        enabled = [k for k, v in result['api_capabilities'].items() if v]\n",
    "        if enabled:\n",
    "            caps_html = ', '.join([f'<span style=\"background-color: #e8f5e9; padding: 2px 8px; border-radius: 12px; margin: 2px;\">{c}</span>' for c in enabled])\n",
    "            display(HTML(f'<h4 style=\"color: #2E7D32;\">‚öôÔ∏è API Capabilities Enabled</h4>'))\n",
    "            display(HTML(f'<div style=\"background-color: #e8f5e9; padding: 15px; border-radius: 5px; margin-bottom: 10px;\">{caps_html}</div>'))\n",
    "    \n",
    "    if 'intent_reasoning' in result and result['intent_reasoning']:\n",
    "        display(HTML(f'<div style=\"background-color: #f5f5f5; padding: 10px; border-radius: 5px; margin-bottom: 10px; font-size: 0.9em;\"><strong>Reasoning:</strong> {result[\"intent_reasoning\"]}</div>'))\n",
    "    \n",
    "    if 'guidance_files' in result:\n",
    "        files_html = ', '.join([f'<code>{f}</code>' for f in result['guidance_files']])\n",
    "        display(HTML(f'<div style=\"background-color: #fff3e0; padding: 10px; border-radius: 5px; margin-bottom: 20px;\"><strong>üìö Guidance Loaded:</strong> {files_html}</div>'))\n",
    "\n",
    "def display_nova_migration_results(result):\n",
    "    if \"error\" in result:\n",
    "        display(HTML(f'<div style=\"color: red; padding: 10px; border: 1px solid red; border-radius: 5px;\"><strong>Error:</strong> {result[\"error\"]}</div>'))\n",
    "        return\n",
    "    \n",
    "    # Show intent results if present\n",
    "    if 'intents' in result:\n",
    "        display_intent_results(result)\n",
    "    \n",
    "    if 'thinking' in result:\n",
    "        display(HTML('<h4 style=\"color: #2E86AB;\">üß† Analysis & Thinking</h4>'))\n",
    "        display(HTML(f'<div style=\"background-color: #f8f9fa; padding: 15px; border-radius: 5px; margin-bottom: 20px;\">{result[\"steps\"].replace(chr(10), \"<br>\")}</div>'))\n",
    "    \n",
    "    if 'nova_draft' in result:\n",
    "        display(HTML('<h4 style=\"color: #A23B72;\">üìù Nova-Aligned Draft</h4>'))\n",
    "        display(HTML(f'<div style=\"background-color: #fff3e0; padding: 15px; border-radius: 5px; margin-bottom: 20px; border-left: 4px solid #A23B72;\"><pre style=\"white-space: pre-wrap; font-family: monospace;\">{result[\"nova_draft\"]}</pre></div>'))\n",
    "    \n",
    "    if 'reflection' in result:\n",
    "        display(HTML('<h4 style=\"color: #F18F01;\">ü§î Reflection</h4>'))\n",
    "        display(HTML(f'<div style=\"background-color: #fff8e1; padding: 15px; border-radius: 5px; margin-bottom: 20px;\">{result[\"reflection\"].replace(chr(10), \"<br>\")}</div>'))\n",
    "    \n",
    "    if 'nova_final' in result:\n",
    "        display(HTML('<h4 style=\"color: #C73E1D;\">‚ú® Final Nova-Aligned Prompt</h4>'))\n",
    "        display(HTML(f'<div style=\"background-color: #e8f5e8; padding: 15px; border-radius: 5px; border-left: 4px solid #C73E1D;\"><pre style=\"white-space: pre-wrap; font-family: monospace; font-weight: bold;\">{result[\"nova_final\"]}</pre></div>'))\n",
    "\n",
    "def display_error(error_message, note=None):\n",
    "    display(HTML(f'<div style=\"color: red; padding: 10px; border: 1px solid red; border-radius: 5px;\"><strong>Error:</strong> {error_message}</div>'))\n",
    "    if note:\n",
    "        print(f\"\\nNote: {note}\")\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Transform a Prompt\n",
    "\n",
    "The pipeline automatically:\n",
    "1. Classifies your prompt's intents using Nova Lite\n",
    "2. Loads only the relevant guidance files\n",
    "3. Generates multiple candidate transformations and picks the best one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T12:08:03.554388Z",
     "start_time": "2025-10-08T12:08:03.550257Z"
    },
    "execution": {
     "iopub.execute_input": "2025-10-08T12:22:09.256306Z",
     "iopub.status.busy": "2025-10-08T12:22:09.256228Z",
     "iopub.status.idle": "2025-10-08T12:22:09.259498Z",
     "shell.execute_reply": "2025-10-08T12:22:09.259264Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3 style=\"color: #2E86AB; border-bottom: 2px solid #2E86AB; padding-bottom: 10px;\">Example: Image + Structured Output</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"background-color: #f8f9fa; padding: 15px; border-radius: 5px; border-left: 4px solid #6c757d;\"><pre style=\"white-space: pre-wrap; font-family: monospace;\">Analyze this image and return a JSON object with all detected objects, \n",
       "their locations, and confidence scores</pre></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Running intent-based pipeline...\n"
     ]
    }
   ],
   "source": [
    "# Example: Image understanding with structured output\n",
    "example_prompt = \"\"\"\n",
    "Analyze this image and return a JSON object with all detected objects, \n",
    "their locations, and confidence scores\n",
    "\"\"\"\n",
    "\n",
    "display_original_prompt(example_prompt, \"Example: Image + Structured Output\")\n",
    "print(\"\\nüîÑ Running intent-based pipeline...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T12:08:05.600243Z",
     "start_time": "2025-10-08T12:08:03.565777Z"
    },
    "execution": {
     "iopub.execute_input": "2025-10-08T12:22:09.260605Z",
     "iopub.status.busy": "2025-10-08T12:22:09.260537Z",
     "iopub.status.idle": "2025-10-08T12:22:41.662034Z",
     "shell.execute_reply": "2025-10-08T12:22:41.661349Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4 style=\"color: #1565C0;\">üéØ Detected Intents</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"background-color: #e3f2fd; padding: 15px; border-radius: 5px; margin-bottom: 10px;\"><span style=\"background-color: #e3f2fd; padding: 2px 8px; border-radius: 12px; margin: 2px;\">image_understanding</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"background-color: #f5f5f5; padding: 10px; border-radius: 5px; margin-bottom: 10px; font-size: 0.9em;\"><strong>Reasoning:</strong> The prompt requires analyzing a screenshot of a Windows desktop to identify where a user clicked based on a red circle marker. This involves visual content analysis of an image (screenshot) to describe UI elements. The key signals are: \"screenshot\", \"red circle marker\", and \"identify where the user clicked\" which all point to image analysis. There is no mention of videos, documents, tools, structured output formats, retrieval-augmented generation, multilingual requirements, or autonomous behavior. Therefore, the primary intent is image_understanding.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"background-color: #fff3e0; padding: 10px; border-radius: 5px; margin-bottom: 20px;\"><strong>üìö Guidance Loaded:</strong> <code>bring_focus_to_sections</code>, <code>chain_of_thought_prompting</code>, <code>creating_precise_prompts</code>, <code>few_shot_prompting</code>, <code>image_understanding</code>, <code>system_role</code></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4 style=\"color: #A23B72;\">üìù Nova-Aligned Draft</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"background-color: #fff3e0; padding: 15px; border-radius: 5px; margin-bottom: 20px; border-left: 4px solid #A23B72;\"><pre style=\"white-space: pre-wrap; font-family: monospace;\">##Role##\n",
       "You are a screen analyzer bot specialized in interpreting Windows desktop screenshots.\n",
       "\n",
       "##Task##\n",
       "A screenshot of a Windows desktop is provided. It contains a red circle marker overlaid on the screen. Your task is to identify where the user clicked and describe the UI element at that location.\n",
       "\n",
       "##Context##\n",
       "- The red circle in the image marks the exact location of a mouse click.\n",
       "- The screenshot is of a Windows desktop environment.\n",
       "\n",
       "##Instructions##\n",
       "Using the ##Context## and the image provided:\n",
       "1. Locate the red circle marker in the screenshot.\n",
       "2. Identify the UI element positioned at the red circle's location.\n",
       "3. Describe that UI element clearly.\n",
       "\n",
       "##Response##\n",
       "Provide a clear description of the UI element the user clicked on, as indicated by the red circle marker in the screenshot.</pre></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4 style=\"color: #F18F01;\">ü§î Reflection</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"background-color: #fff8e1; padding: 15px; border-radius: 5px; margin-bottom: 20px;\">**Content completeness:**<br>- ‚úÖ Persona (screen analyzer bot) ‚Äî present in ##Role##<br>- ‚úÖ Input type (Windows desktop screenshot with red circle) ‚Äî present in ##Task## and ##Context##<br>- ‚úÖ Red circle = mouse click location ‚Äî explicitly preserved in ##Context##<br>- ‚úÖ Primary task (identify where user clicked) ‚Äî present in ##Task## and ##Instructions##<br>- ‚úÖ Output requirement (describe UI element clicked) ‚Äî present in ##Instructions## step 3 and ##Response##<br><br>**Functional equivalence:**<br>Both prompts would produce the same output for identical inputs. The Nova version is more structured but carries the same semantic meaning and all original task requirements. No content has been lost.<br><br>**Nova compatibility:**<br>- \"Act like you are\" replaced with \"You are\" in a dedicated ##Role## section ‚úÖ<br>- Section headers use ## format ‚úÖ<br>- Instructions reference ##Context## explicitly, per Nova section referencing guidance ‚úÖ<br>- No XML tags used ‚úÖ<br><br>**Formatting and structure:**<br>The draft is well-organized with clear, distinct sections. Length is proportional to the original (slightly expanded for clarity, not padded). One minor improvement: the ##Response## section could be merged or made slightly more specific about format (e.g., single description vs. multi-part). Since the original doesn't specify a particular output format (like JSON), keeping it as a plain description requirement is correct. The draft looks good overall ‚Äî no changes needed beyond minor tightening of wording.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4 style=\"color: #C73E1D;\">‚ú® Final Nova-Aligned Prompt</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"background-color: #e8f5e8; padding: 15px; border-radius: 5px; border-left: 4px solid #C73E1D;\"><pre style=\"white-space: pre-wrap; font-family: monospace; font-weight: bold;\">##Role##\n",
       "You are a screen analyzer bot specialized in interpreting Windows desktop screenshots.\n",
       "\n",
       "##Task##\n",
       "A screenshot of a Windows desktop is provided. It contains a red circle marker overlaid on the screen. Your task is to identify where the user clicked and describe the UI element at that location.\n",
       "\n",
       "##Context##\n",
       "- The red circle in the image marks the exact location of a mouse click.\n",
       "- The screenshot is of a Windows desktop environment.\n",
       "\n",
       "##Instructions##\n",
       "Using the information in ##Context## and the provided image:\n",
       "1. Locate the red circle marker in the screenshot.\n",
       "2. Identify the UI element positioned at the red circle's location.\n",
       "3. Describe that UI element clearly.\n",
       "\n",
       "##Response Format##\n",
       "Provide a clear, concise description of the UI element the user clicked on, as indicated by the red circle marker in the screenshot.</pre></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Transform using the full pipeline\n",
    "try:\n",
    "    result = transform_prompt(\n",
    "        \"Act like you are a screen analyzer bot. Given a screenshot of a Windows \"\n",
    "        \"desktop with a red circle marker, your task is to identify where the user \"\n",
    "        \"clicked. The red circle indicates the location of a mouse click. Describe \"\n",
    "        \"what UI element the user clicked on.\",\n",
    "    )\n",
    "    display_nova_migration_results(result)\n",
    "except Exception as e:\n",
    "    display_error(str(e), \"This requires AWS credentials and access to Bedrock service.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T12:08:05.718597Z",
     "start_time": "2025-10-08T12:08:05.715418Z"
    },
    "execution": {
     "iopub.execute_input": "2025-10-08T12:22:41.666735Z",
     "iopub.status.busy": "2025-10-08T12:22:41.666558Z",
     "iopub.status.idle": "2025-10-08T12:22:41.671116Z",
     "shell.execute_reply": "2025-10-08T12:22:41.670812Z"
    }
   },
   "source": [
    "---\n",
    "\n",
    "# Try Your Own Prompt\n",
    "\n",
    "Enter your prompt below and run the cell to transform it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your custom prompt here\n",
    "your_prompt = \"\"\"\n",
    "Summarize the following Document: {document_text}\n",
    "\"\"\"\n",
    "\n",
    "display_original_prompt(your_prompt, \"Your Prompt\")\n",
    "print(\"\\nüîÑ Running intent-based pipeline...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T12:08:06.747292Z",
     "start_time": "2025-10-08T12:08:05.728513Z"
    },
    "execution": {
     "iopub.execute_input": "2025-10-08T12:22:41.672783Z",
     "iopub.status.busy": "2025-10-08T12:22:41.672658Z",
     "iopub.status.idle": "2025-10-08T12:23:07.109940Z",
     "shell.execute_reply": "2025-10-08T12:23:07.108656Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transform your prompt\n",
    "try:\n",
    "    your_result = transform_prompt(your_prompt.strip())\n",
    "    display_nova_migration_results(your_result)\n",
    "except Exception as e:\n",
    "    display_error(str(e), \"This requires AWS credentials and access to Bedrock service.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Batch Transform\n",
    "\n",
    "Transform multiple prompts from a JSONL file. Each line should be a JSON object with a `\"prompt\"` field:\n",
    "\n",
    "```json\n",
    "{\"id\": \"summarize\", \"prompt\": \"Summarize this document: {text}\"}\n",
    "{\"id\": \"classify\", \"prompt\": \"Classify the sentiment of: {review}\"}\n",
    "```\n",
    "\n",
    "**Candidates:** The `candidates` setting controls how many candidate transformations are generated per prompt. A judge then picks the best one. Set `candidates = 1` to skip candidate generation and judging (faster, cheaper). Higher values (e.g. 4) produce better results at the cost of more API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from nova_metaprompter.batch_transform import load_prompts, save_results, transform_single\n",
    "\n",
    "# -- Configure --\n",
    "input_file = Path(\"prompts.jsonl\")   # your input file\n",
    "output_file = Path(\"results.jsonl\")  # where to save results\n",
    "candidates = 4                        # number of candidate transforms per prompt (1 = fastest)\n",
    "\n",
    "# -- Load prompts --\n",
    "prompts = load_prompts(input_file)\n",
    "print(f\"Loaded {len(prompts)} prompts\")\n",
    "\n",
    "# -- Transform each prompt --\n",
    "results = []\n",
    "for i, item in enumerate(prompts, 1):\n",
    "    print(f\"[{i}/{len(prompts)}] Transforming: {item['id']}...\")\n",
    "    result = transform_single(item, n=candidates)\n",
    "    results.append(result)\n",
    "    print(f\"  Status: {result['status']}\")\n",
    "\n",
    "# -- Save results --\n",
    "save_results(results, output_file)\n",
    "print(f\"\\nSaved {len(results)} results to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flintflex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
